# 负载均衡器的高级细节
了解负载均衡器及其在系统中的使用。
本课程将着重介绍本地负载均衡器中使用的一些知名算法。我们也将了解负载均衡器如何相互连接以形成一个层次结构，跨不同层级的LB共享工作。

## 负载均衡器的算法
负载均衡器按照算法分配客户端请求。以下是一些知名算法：

- **轮询调度**：在此算法中，每个请求以重复顺序的方式转发到池中的服务器。
- **加权轮询**：如果某些服务器具有更高的服务客户请求的能力，则应使用加权轮询算法。在加权轮询算法中，每个节点被分配一个权重。LB根据节点的权重转发客户请求。权重越高，分配的数量越多。
- **最少连接**：在某些情况下，即使所有服务器都具有相同的服务客户的能力，某些服务器上的不均衡负载仍然是可能的。例如，某些客户端可能具有需要更长时间服务的请求。或者某些客户端可能在同一连接上有随后的请求。在这种情况下，我们可以使用最小连接数等算法，其中新到达的请求分配给具有较少现有连接的服务器。在这种情况下，LB保持现有连接数量和映射的状态。我们将在本课程后面讨论更多状态维护的内容。
- **最短响应时间**：在对性能敏感的服务中，需要使用最短响应时间等算法。该算法确保请求最短响应时间的服务器用于服务客户。
- **IP哈希**：某些应用程序根据用户的IP地址提供不同级别的服务。在这种情况下，执行哈希IP地址以将用户请求分配给服务器。
- **URL哈希**：可能某些应用程序中的一些服务仅由特定服务器提供。在这种情况下，从URL请求服务的客户端被分配给某个集群或一组服务器。URL哈希算法在这些情况下使用。

还有其他算法，例如随机或加权最少连接算法。

### 静态和动态算法
算法可以是静态或动态的，具体取决于机器的状态。让我们分别看看每个类别：

**静态算法** 不考虑服务器的变化状态。因此，任务分配是基于现有对服务器配置的了解进行的。当然，这些算法并不复杂，并且在所有请求到达的单个路由器或商品机上实现。

**动态算法** 是考虑服务器当前或最近状态的算法。动态算法通过与服务器通信来维护状态，这增加了通信开销。状态维护使算法的设计更加复杂。动态算法需要不同的负载平衡服务器彼此通信以交换信息。因此，动态算法可以是模块化的，因为没有单个实体会做出决策。尽管这增加了动态算法的复杂性，但它导致了更好的转发决策。最后，动态算法监视服务器的健康状况，并仅将请求转发到活动服务器。

> **注意：** 实际上，动态算法提供的结果要好得多，因为它们维护了提供主机的状态，因此值得付出努力和复杂性。

### 有状态与无状态LB
尽管静态和动态算法要考虑托管服务器的健康状况，但需要维护状态以存储不同客户端与托管服务器的会话信息。如果会话信息没有保留在更低层（分布式缓存或数据库），负载均衡器将用于保持会话信息。下面，我们描述了两种通过LB处理会话维护的方法：- 有状态- 无状态
#### 有状态负载均衡
如名称所示，“有状态负载平衡”涉及维护客户端和主机服务器之间建立的会话的状态。有状态LB在算法中合并状态信息以执行负载平衡。基本上，有状态LB保留一个将传入的客户端映射到主机服务器的数据结构。有状态LB增加了复杂性并限制了可扩展性，因为所有客户端的会话信息都在所有负载平衡器中维护。也就是说，负载均衡器彼此共享它们的状态信息以做出转发决策。
![QQ截图20230406211853](/img/08-Load Balancers/QQ截图20230406211853.png)
有状态负载均衡
#### 无状态负载均衡
“无状态负载平衡”不维护任何状态，因此速度更快，轻量级。无状态LB使用一致性哈希来做出转发决策。然而，如果基础架构发生变化（例如，新的应用服务器加入），无状态LB可能不如有状态LB具有弹性，因为仅使用一致性哈希无法将请求路由到正确的应用服务器。因此，本地状态仍可能需要与一致性哈希一起使用。
![QQ截图20230406211904](/img/08-Load Balancers/QQ截图20230406211904.png)
无状态负载均衡器使用哈希桶将请求映射到最终的服务器
因此，跨不同负载平衡器维护的状态被视为有状态负载平衡。而在负载均衡器内部维护的状态用于内部使用，则被认为是无状态负载平衡。
## 负载均衡器类型
根据要求，负载平衡可以在开放系统互连（OSI）模型的网络/传输层和应用层执行。
- **第四层负载均衡器**：第四层是基于传输协议如TCP和UDP执行的负载均衡。这些类型的LB会与客户端维持连接/会话，并确保相同（TCP / UDP）通信最终被转发到相同的后端服务器。虽然TLS终止在第七层LB上执行，但某些第四层LB也支持它。
- **第七层负载均衡器**：第七层负载均衡器基于应用层协议的数据。可以根据HTTP头，URL，Cookie和其他应用程序特定数据（例如用户ID）做出应用程序感知的转发决策。除了执行TLS终止之外，这些LB还可以承担限制用户流量，HTTP路由和标头重写等任务。
> **注意：**第七层负载均衡器在检查方面很聪明。但是，第四层负载均衡器在处理方面更快。
## 负载均衡器部署
我们讨论了在不同OSI层上执行负载平衡的权衡。然而，在实践中，单个层次的LB对于大型数据中心是不够的。实际上，多层负载平衡器协调进行明智的转发决策。传统数据中心可能会有一个按下面所示的三层LB：
![QQ截图20230406211917](/img/08-Load Balancers/QQ截图20230406211917.png)
典型数据中心中的三层负载均衡器
###Tier-0和Tier-1 LB
如果将DNS视为Tier-0负载均衡器，则ECMP路由器就是Tier-1负载均衡器。从ECMP的名称可以看出，这个层次是根据IP或一些其他算法（如轮询或加权轮询）分割传入的流量的。Tier-1 LB将负载平衡到不同路径上的更高层负载平衡器。ECMP路由器在更高层LB的水平可扩展性方面起着重要作用。
###Tier-2 LBsLB的第二层包括第四层负载均衡器。第二层LB确保对于任何连接，所有输入数据包都被转发到相同的第三层LB。为了实现这个目标，可以使用一种技术，如一致性哈希。但是，在基础设施发生任何更改的情况下，一致哈希可能不足够。因此，我们必须保持本地或全局状态，正如本课程即将介绍的那样。Tier-2负载均衡器可以被看作是Tier-1和Tier-3 LB之间的粘合剂。排除第二层LB可能会导致在失败或动态缩放LB时出现错误的转发决策。### Tier-3 LBsLayer 7 LB提供第3层的服务。由于这些LB直接与后端服务器接触，它们在HTTP级别执行服务器健康监测。这一层通过将请求均匀地分配给一组健康的后端服务器实现可扩展性，并通过直接监测服务器的健康状况提供高可用性。该层还通过处理TCP拥塞控制协议、发现Path MTU（最大传输单位）的差异、客户端和后端服务器之间的应用程序协议的差异等低级细节，减轻了端服务器的负担。其想法是将计算和数据服务留给应用程序服务器，并有效地利用负载均衡商品机器进行微不足道的任务。在某些情况下，层7 LB与服务主机处于同一层。> 总之，第1层在负载均衡器之间平衡负载。第二层在失败的情况下平稳地从第1层过渡到第3层，而第3层则在后端服务器之间执行实际的负载平衡。每一层都执行其他任务，以减轻端服务器的负担。### 实际例子让我们看一个例子，客户端的请求根据客户端网络数据包中的应用程序数据被转发到不同的应用程序服务器。![QQ截图20230406211950](/img/08-Load Balancers/QQ截图20230406211950.png)请求R1被路由到Slides服务器![QQ截图20230406212017](/img/08-Load Balancers/QQ截图20230406212017.png)请求R2被路由到文档服务器让我们按以下步骤查看上面的插图：```指示请求1通过其中一个路由器之一转发到任何三个可用的层使用轮询算法带有源IP地址的散列，将数据包转发到下一层LB。收到数据包后，卸载TLS并读取HTTP（S）数据。通过观察所请求的URL，将请求转发到处理Slides请求的服务器。采用相同的路径，但是使用不同的目标服务器，因为所请求的URL包含文档而不是幻灯片。 Tier-3 LB已经预配置为根据应用程序数据将请求转发到应用程序服务器。例如，典型的HAProxy服务器可以在Tier-3 LB中拥有以下配置：```![QQ截图20230406212445](/img/08-Load Balancers/QQ截图20230406212445.png)```javamode HTTP            //定义LB的工作模式，Tier-2 LB的TCP则不用acl SlidesApp path_end -i /presentation //如果路径以/ presentation结尾，则定义应用程序类别。use_backend SlidesServers if SlidesApp //如果请求到达SlidesApp，则使用一组后端服务器。 backend SlidesServers        //列出为SlidesApp提供服务的服务器。 server Slides1 192.168.12.1:80          //使用Slides1服务器为SlidesApp提供服务。 ```层7负载均衡器的HAProxy样本配置测验###### 问题1当请求到达后端服务器时，响应是否应该通过每个负载均衡器层路由回去？隐藏答案不应该，服务器可以通过Tier-3 LB直接将响应发送回路由器（Tier-1 LB），Tier-3 LB可以从数据中心转发响应。这样的响应称为直接路由（DR）或直接服务器返回（DSR）。###### 问题2为什么服务器不直接将响应发送给路由器（三层负载均衡器），而不是二层负载均衡器？

三层负载均衡器维护连接的某些状态，例如 SSL 加密/解密。这是为了给客户提供无缝的体验。

问题3

你认为哪一层负载均衡器更容易出现错误？

三层具有更大的复杂性，这使其更容易出现错误。

问题4

上面的图显示了比层-2负载均衡器更多的层-3负载均衡器。你认为这样的呈现有什么原因？

三层执行应用程序特定的分析和更复杂的计算。因此，处理与二层相同数量的查询需要更多的机器。此外，三层负载均衡器维护大量应用服务器的状态，这可能不可能使用与二层相同数量的负载均衡器。

## 负载均衡器的实现

根据传入请求的数量、组织和应用程序特定的要求，可以实现不同种类的负载均衡器：

### 硬件负载均衡器

负载均衡器在1990年代作为硬件设备引入。硬件负载均衡器作为独立设备工作，价格相当昂贵。尽管如此，它们具有性能上的优点，并且能够处理大量的并发用户。基于硬件的解决方案的配置存在问题，因为它需要额外的人力资源。因此，即使是负担得起它们的大型企业也不会首先选择它们。硬件负载平衡器可用性可能是一个问题，因为在发生故障的情况下需要额外的硬件进行故障转移。最后，硬件负载均衡器的维护/操作成本可能更高，而且具有兼容性问题，使其不够灵活。更不用说硬件均衡器也具有供应商锁定。

### 软件负载均衡器

由于其灵活性、可编程性和成本效益，软件负载均衡器越来越受到欢迎。这一切都可能发生，因为它们是在通用硬件上实施的。软件均衡器随着要求的增长而扩展得很好。使用软件均衡器不会存在可用性问题，因为需要在通用硬件上实现影子负载均衡器的一些小额外成本。此外，软件负载均衡器可以提供预测性分析，以帮助准备未来的流量模式。

### 云负载均衡器

随着云计算领域的出现，引入了负载均衡器作为服务（LBaaS）。这是云所有者提供负载均衡服务的地方。用户根据其使用情况或与云提供商的服务级别协议（SLA）付款。基于云的负载均衡器不一定会替换本地的本地负载均衡设施，但它们可以在不同区域之间执行全局流量管理。这种负载均衡器的主要优点包括易于使用、管理、计量成本、使用灵活性、审计以及提供监视服务，以改善业务决策。下面演示了基于云的 LBs 如何提供 GSLB：

![QQ截图20230406212042](/img/08-Load Balancers/QQ截图20230406212042.png)

通过 LBaaS 获得 GSLB，而该区域包含应用程序提供商所拥有的数据中心

> **注：** 负载均衡器的另一个有趣实现形式是客户端负载均衡器。客户端负载均衡器适用于有许多服务的情况，每个服务都有许多实例（例如 Twitter 中的负载均衡）。然而，我们的重点是传统负载均衡器，因为大多数三层应用程序都采用这种设计。

## 结论LB在云计算方面已经发展了很长一段路程，起初是以硬件的形式提供服务。它们是任何企业级服务的关键组成部分。托管服务器的水平可伸缩性总是需要一个良好的负载均衡层，能够提供负载均衡、会话维护、TLS卸载、服务发现等功能。