# 负载均衡器的高级细节了解负载均衡器及其在系统中的使用。本课程将重点介绍本地负载均衡器中使用的一些著名算法。我们还将了解负载均衡器如何连接以形成层次结构，在不同层的LB之间共享工作。## 负载均衡器算法负载均衡器根据算法分配客户端请求。下面给出一些著名的算法：- **轮询调度**：在该算法中，每个请求都以重复顺序方式转发到池中的一个服务器。- **加权轮询**：如果某些服务器具有更高的客户请求服务能力，则最好使用加权轮询算法。在加权轮询算法中，每个节点都分配了一个权重。 LB根据节点的权重转发客户请求。权重越高，分配的数量就越多。- **最少连接**：在某些情况下，即使所有服务器具有相同的客户端服务容量，特定服务器上的不均衡负载仍有可能发生。例如，某些客户端可能会请求需要更长时间的请求。或者某些客户端可能会在同一连接上有后续请求。在这种情况下，可以使用最少连接等算法，其中将新到达的请求分配给现有连接较少的服务器。在这种情况下，LB保持现有连接数量和映射的状态。我们将在本课程后面讨论有关状态维护的更多信息。- **最小响应时间**：在性能敏感的服务中，需要使用最小响应时间等算法。该算法确保请求具有最小响应时间的服务器为客户端提供服务。- **IP哈希**：某些应用根据用户的IP地址提供不同的服务级别。在这种情况下，对IP地址进行哈希以将用户请求分配给服务器。- **URL哈希**：可能有一些服务仅由特定的服务器提供。在这种情况下，将请求特定服务器集群或集合的客户端分配给特定的服务器。URL哈希算法在这些情况下使用。还有其他算法，例如随机或加权最少连接算法。### 静态与动态算法算法可以是静态或动态的，具体取决于机器的状态。让我们分别查看每个类别：**静态算法**不考虑服务器的变化状态。因此，基于对服务器配置的现有知识来执行任务分配。自然地，这些算法不复杂，并在所有请求到达的单个路由器或商品机器中实现。**动态算法**是考虑服务器的当前或最近状态的算法。动态算法通过与服务器通信来维护状态，这增加了通信开销。状态维护使算法的设计变得更加复杂。动态算法需要不同的负载平衡服务器彼此通信以交换信息。因此，动态算法可以是模块化的，因为没有单个实体会做决策。虽然这增加了动态算法的复杂性，但它导致了更好的转发决策。最后，动态算法监视服务器的健康状况，并仅将请求转发到活动服务器。> **注意：**在实践中，动态算法提供了更好的结果，因为它们维护服务主机的状态，因此值得付出努力和复杂性。### 有状态与无状态LBs虽然静态和动态算法需要考虑托管服务器的健康状况，但状态仍然保持以保存与托管服务器的不同客户端的会话信息。如果会话信息没有在较低层（分布式缓存或数据库）保留，则会使用负载平衡器来保持会话信息。下面，我们描述了两种通过LB处理会话维护的方式：- 有状态的- 无状态的#### 有状态的负载均衡正如名称所示，**有状态的负载均衡**涉及维持客户机和托管服务器之间建立的会话状态。有状态的LB在其算法中包含状态信息以执行负载平衡。基本上，有状态的LB保留一个数据结构，将传入的客户机映射到托管服务器。有状态的LB增加了复杂度并限制了扩展性，因为所有客户机的会话信息都在所有负载平衡器之间维护。也就是说，负载平衡器彼此共享其状态信息以做出转发决策。![QQ截图20230406211853](/img/08-Load Balancers/QQ截图20230406211853.png)有状态的负载均衡#### 无状态的负载均衡**无状态的负载均衡**不保留状态，因此速度更快且轻量。无状态的LB使用一致的哈希来做出转发决策。但是，如果基础架构发生更改（例如，新的应用服务器加入），则无状态的LB可能不像有状态的LB那样具有弹性，因为仅使用一致的哈希不能将请求路由到正确的应用服务器。因此，可能仍需要本地状态以及一致的哈希。![QQ截图20230406211904](/img/08-Load Balancers/QQ截图20230406211904.png)使用哈希桶将请求映射到终端服务器的无状态负载均衡器因此，在不同负载平衡器之间保持的状态被认为是有状态的负载均衡。然而，在负载平衡器内部维护用于内部使用的状态被认为是无状态的负载均衡。## 负载均衡器的类型根据要求，负载平衡可以在开放系统互连（OSI）层的网络/传输和应用层执行。- **第4层负载均衡器**：第4层是基于传输协议（如TCP和UDP）执行负载平衡。这些类型的LB与客户端维护连接/会话，并确保相同的（TCP/UDP）通信最终转发到相同的后端服务器。即使在第7层LB执行TLS终止，有些第4层LB也支持它。- **第7层负载均衡器**：第7层的负载均衡器基于应用程序层协议的数据。可以根据HTTP标头、URL、Cookie和其他特定于应用程序的数据（例如用户ID）做出应用程序感知的转发决策。除了执行TLS终止外，这些LB还可以承担诸如限制用户速率、HTTP路由和标头重写等职责。> **注意**：第7层的负载均衡器在检查方面很聪明。但是第4层的负载均衡器在处理方面更快。## 负载均衡器部署我们讨论了在不同OSI层上执行负载平衡的权衡。然而，在实践中，单个层次的LB对于大型数据中心是不够的。实际上，多层负载平衡器协调进行有信息的转发决策。传统数据中心可能具有三层LB，如下所示：![QQ截图20230406211917](/img/08-Load Balancers/QQ截图20230406211917.png)典型数据中心中的三层负载均衡器### 层0和层1的LBs如果DNS可以被视为层0负载均衡器，则等价成本多路径（ECMP）路由器是层1负载均衡器。从ECMP的名称可以看出，该层基于IP或其他算法（如轮询或加权轮询）将传入流量分成多个部分。层1 LB将负载平衡分配到更高层的负载平衡器的不同路径上。ECMP路由器在更高层LB的水平扩展中发挥着至关重要的作用。### 层2的LBsLB的第二个层次包括第4层负载均衡器。第2层LB可以确保对于任何连接，所有传入的数据包都被转发到同一层3 LB。为了实现这个目标，可以使用一种技术，如一致性哈希。但是，在基础架构发生任何变化的情况下，一致性哈希可能不足以满足需求。因此，我们必须在课程的后续部分保持本地或全局状态。第2层负载均衡器可以被认为是第1层和第3层LB之间的粘合剂。如果不包括第2层LB，则可能会导致在故障或动态伸缩LB的情况下出现错误的转发决策。### 第3层LB层7 LB在第3层提供服务。由于这些LB直接与后端服务器接触，它们在HTTP级别执行服务器的健康监控。这层通过平均分配请求到一组健康的后端服务器来实现可扩展性，并通过直接监控服务器的健康状况实现高可用性。这个层次还通过处理TCP拥塞控制协议、发现路径MTU（最大传输单元）、客户端和后端服务器之间的应用程序协议的差异等低级细节减轻了端服务器的负担。这个层次的想法是将计算和数据服务留给应用服务器，并有效地利用负载平衡商品机器来处理琐碎的任务。在某些情况下，层7 LB与服务主机处于同一层级。> 总之，第1层在负载均衡器之间平衡负载。第2层使得在故障情况下从第1层到第3层的过渡平稳，而第3层实际上在后端服务器之间进行负载均衡。每个层次执行其他任务以减轻端服务器的负担。### 实际示例让我们看一个例子，客户端的请求基于客户端网络数据包中的应用程序数据被转发到不同的应用程序服务器。![QQ截图20230406211950](/img/08-Load Balancers/QQ截图20230406211950.png)请求 R1 被路由到幻灯片服务器![QQ截图20230406212017](/img/08-Load Balancers/QQ截图20230406212017.png)请求 R2 被路由到文档服务器让我们按以下步骤查看上面的插图：![QQ截图20230406212445](/img/08-Load Balancers/QQ截图20230406212445.png)```javamode HTTP //定义LB将在哪个模式下工作，tier-2 LB的模式为TCPacl slidesApp path_end -i /presentation //定义应用程序类别，如果路径以 /presentation 结尾，则定义为 slidesAppuse_backend slidesServers if slidesApp //如果请求到达 slidesApp，则使用一组后端服务器backend slidesServers //列出服务 slidesApp 的服务器server slides1 192.168.12.1:80 //使用 slides1 服务器以服务 slidesApp。```HAProxy层7负载均衡器的示例配置测验###### 问题 1当请求到达后端服务器时，响应是否应该通过负载均衡器的每个层次进行路由？Hide AnswerNo，服务器可以直接通过第3层LB将响应返回给路由器（第1层LB），该层可以从数据中心转发响应。这样的响应称为直接路由（DR）或直接服务器返回（DSR）。##负载均衡器的实现根据传入请求的数量，组织和应用程序特定要求可以实现不同类型的负载均衡器：### 硬件负载平衡器# 负载均衡器

## 硬件负载均衡器

负载均衡器最初是在1990年代作为硬件设备引入的。硬件负载均衡器作为独立设备运行，但价格相当昂贵。尽管如此，它们具有卓越的性能表现，并能同时处理大量的用户请求。硬件负载均衡器的配置问题在于它需要额外的人力资源。因此，即使对于有经济实力的大型企业来说，硬件解决方案也不是首选方案。硬件负载均衡器的可用性可能成为问题，因为在故障的情况下，需要额外的硬件进行故障转移。最后，硬件负载均衡器可能具有较高的维护/运营成本和兼容性问题，使其不够灵活。更不用说硬件负载均衡器还有供应商锁定的问题。

## 软件负载均衡器

由于它们具有灵活性、可编程性和成本效益，软件负载均衡器变得越来越受欢迎。这一切都是由于它们实现在通用硬件上。随着需求的增长，软件负载均衡器的可扩展性很好。使用软件负载均衡器不会出现可用性问题，因为只需要在通用硬件上实现影子负载均衡器，需要付出的成本不大。此外，软件负载均衡器可以提供预测分析，帮助准备未来的流量模式。

## 云负载均衡器

随着云计算领域的迅速发展，引入了作为服务提供的负载均衡器（LBaaS）。这是云所有者提供负载均衡服务的地方。用户根据其使用情况或与云提供商的服务级别协议（SLA）支付费用。云负载均衡器可能并不一定取代本地的负载均衡设施，但它们可以在不同区域之间执行全局流量管理。这类负载均衡器的主要优点包括易于使用、管理、计量成本、使用的灵活性、审计和监视服务，以改进业务决策。下面是云负载均衡器如何提供全局负载均衡的示例：

![QQ截图20230406212042](/img/08-Load Balancers/QQ截图20230406212042.png)

全局负载均衡通过LBaaS获得，区域包含应用程序提供者的数据中心

### 客户端负载均衡

另一种有趣的负载均衡实现是客户端负载均衡。客户端负载均衡适用于有许多服务的情况，每个服务都有许多实例（例如，[Twitter中的负载均衡](https://www.educative.io/collection/page/10370001/4941429335392256/5379128533975040)）。然而，我们的重点仍然是传统的负载均衡器，因为大多数三层应用程序都采用这种设计。

## 结论

负载均衡器已经走过了漫长的历程，从硬件设备发展成为云中提供的服务。它们是任何企业级服务的关键组件。托管服务器的水平扩展将始终需要一个能够提供负载均衡、会话维护、TLS卸载、服务发现等功能的良好负载均衡器层。