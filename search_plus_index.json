{"./":{"url":"./","title":"教程导读","keywords":"","body":"现代系统设计课程    北美著名系统设计教程, 深受广大留学生喜爱 通过本书, 您将获得： 深入了解项目要求和约束的能力 深入了解各种流行的大规模网络服务是如何构建的 以现代的视角使用微服务架构中的各种构建块设计复杂系统的能力 一个高度自适应的框架, 可供工程师和管理人员用来解决现代系统设计问题 在本课程的指导下, 使用稳健的系统设计方法解决任何新问题的能力 本书大纲 本课程由四十章组成。这些章节可以分为以下四个不同的部分。 引言 引言部分由五章组成。 介绍课程及其主要特点。 指导如何准备系统设计面试。 讨论了不同类型的抽象。 讨论每个大型系统都应该具备的一些不可或缺的非功能性特征, 在本章最后我们将介绍粗略的计算，这些计算使我们能够在设计问题期间估算资源。 构建块 一章以介绍 16 种不同构建块的介绍性课程开始。这些构建块中的每一个都在一个独立的章节中进行了解释。以一章结束本节，该章也作为对下一节的介绍。 设计问题 这部分是课程的核心，由十三个设计问题精心打造而成。 结语 部分对本课程进行了总结，由两章组成: 惊人的失败 这些失败表明在现实世界中，即使是一个小错误也会导致一个大型的稳定的应用程序崩溃。此类失败甚至可能是不可避免的，但我们强调了一些减轻此类失败的措施。 结束语 本书详细介绍参见现代系统设计课程结构 安装 使用 gitBook 构建/发布, 具体安装流程如下: # 安装 nodeJs v10.x版本 # 全局安装 gitbook-cli npm install -g gitbook-cli # 安装 gitBook gitBook -V # 克隆本仓库 执行命令 gitBook build 如何贡献 非常欢迎你的加入！提一个 Issue 或者提交一个 Pull Request。 联系我们, 认领自己想要整理的章节. 贡献者 感谢以下参与项目的人： 使用许可 MIT © Richard Littauer Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"简介/介绍.html":{"url":"简介/介绍.html","title":"介绍","keywords":"","body":"介绍 本节由两小节组成 现代系统设计导论 现代系统设计课程结构 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"简介/现代系统设计导论.html":{"url":"简介/现代系统设计导论.html","title":"现代系统设计导论","keywords":"","body":"现代系统设计导论 本节目标:从整体上把握本课程 什么是系统设计？ 系统设计是定义组件及其集成方式、API 和数据模型以构建满足一组特定功能和非功能需求的大型系统的过程。 系统设计使用计算机网络、并行计算和分布式系统的概念来设计可扩展且高性能的系统。 分布式系统天生就可以很好地扩展。但分布式系统会提升系统复杂度。 系统设计的定理可以帮助我们驯服 复杂性并完成设计工作。 系统设计旨在构建可靠、有效和可维护等特性的系统。 可靠的系统会处理故障和错误,并拥有完备可靠的报警/日志系统。 有效的系统满足所有用户需求和业务要求。 可维护的系统是灵活的，可以随意掌握部署规模, 并支持扩展新功能 基于构建块的现代系统设计 我们已经分离出常用的设计元素，例如负载均衡器; 作为高级系统设计的基本构建块。这有两个目的。 首先，它允许我们详细讨论所有构建块并讨论它们有趣的微型设计问题。 其次，当我们解决设计问题时，我们可以专注于问题的特定方面，添加我们将使用的构建块以及我们将如何使用它。这有助于我们消除对常见设计元素的重复讨论。(组件复用) 本课程共涵盖了 16个对设计现代系统至关重要的构建块 将在后面依次介绍 关于本课程 本课程是关于设计随用户增加而扩展的系统，即使在不同的故障下也保持可用，并以良好的性能满足功能目标。 真实世界的系统构建是一个迭代过程，我们也采用这种方式，以一个优秀的设计为开始, 衡量它的性能，并在下一次迭代中改进设计。 本课程的重点是让我们自己沉浸在精心选择的系统设计工作中，使我们能够解决任何新颖的设计问题，无论是在系统设计面试中还是在办公室的任务中。本课程旨在教授概念而不是提供样板设计。下面列出了本课程旨在填补的一些空白。 下面列出了本课程旨在填补的一些空白。 重新审视系统设计：许多系统设计课程提供了解决特定问题的公式。这在面试等高压力情况下似乎很有吸引力，但它可能会鼓励记住设计解决方案，而不是真正理解问题并设计适当的解决方案。如果系统设计是公式化的，那么我们可能不需要人来进行系统设计。 [!NOTE] 系统设计既是一门艺术，也是一门科学，从第一原则出发解决设计问题会给人一种新鲜感。 深入和广泛：在课程中, 我们会解决一些传统问题，并对它们进行了深入的讨论。我们会给出适当的理由，说明我们为什么使用某些组件，该组件可能是一种折中方案(基于现实问题不得不做出的取舍). 在接下来的章节中, 您将更具体的体会到方案设计. 我们还解决了一些新的设计问题，这些问题不仅涉及可伸缩性，还涉及可用性、可维护性、一致性和容错性。总的来说，传统问题和新问题涵盖了现代系统设计活动的所有方面。我们希望本课程能让读者有效地解决他们遇到的任何新设计问题。 [!NOTE] 真实的系统是复杂的，而且通常我们可能需要做出适当的假设来正确地确定问题的范围。我们将更详细地介绍问题以正确掌握现实世界的系统。 迭代过程：实际上，系统通过迭代进行改进。我们通常从简单的事情开始，但是当系统的一个或多个部分出现瓶颈时，就需要进行新的设计。 在一些设计问题上，我们做一个设计，找出瓶颈，然后改进。在时间限制下工作可能不允许对设计进行迭代。但是，我们仍然建议进行两次迭代 尽最大努力提出设计（这会占用我们大约 80% 的时间）,作为第一次迭代 随着系统的扩展,我们将花更多的时间解决问题，这会让我们发现更多设计上的细节, 根据这些细节对设计进行迭代, 从而完善整个系统 交互式学习：我们提供充足的机会供读者获得系统设计经验。并安排了一些设计问题引导读者通过特定的步骤来设计系统。 我们还提供了一些实例，让读者在没有任何指导步骤的情况下端到端地设计完整的系统。并通过问题和测验来强化重要概念。 谁应该学习这门课程？ 系统设计适用于任何想要在职业生涯中更上一层楼的软件工程师。 面试准备：最近，系统设计正成为软件开发面试的重要组成部分。本课程帮助软件工程师准备面试。我们在本课程的第二章为有兴趣的读者提供了准备系统设计面试的详细指南。 软件开发人员：系统设计主要面向旨在成为 首席工程师 或 解决方案架构师 的后端开发人员。这些工程师需要处理实际的用户数据。保证一旦前端将数据提交到后端系统，该数据一定可以被系统正确处理。除此之外, 全栈或前端开发人员可能也想学习系统设计以改进他们的工作。与此同时， 在生产环境中随叫随到的支持工程师（也称为SRE, 国内称为运营）每天都要处理各种问题, 系统设计理念可以帮助 SRE 更高效地找到复杂问题的根源。 产品/项目经理：产品/项目管理中的一大挑战是构建能够随着时间的推移扩展并有效执行的系统。了解系统设计的经理可以指导大规模高性能系统的设计。因此，产品/项目经理必须了解系统设计概念，以成功指导应用程序的设计和开发。 系统设计读者：系统设计是一门有趣的学科，技术领域的人可以从学习系统设计中受益匪浅。本课程帮助读者了解大型科技公司如何从头开始设计和构建成功的应用程序，并随着时间的推移对其进行改进。其他读者可能希望通过学习本课程将他们的想法发展成一个大型应用程序。 本课程的先决条件 我们假设您了解分布式系统的基本概念。 对计算机网络/操作系统有基础的理解. Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"简介/现代系统设计课程结构.html":{"url":"简介/现代系统设计课程结构.html","title":"现代系统设计课程结构","keywords":"","body":"现代系统设计的课程结构 本节目标: 概览本系统设计课程的结构和优势。 课程结构 本课程由四十章组成。这些章节可以分为以下四个不同的部分。 引言：引言部分由五章组成。 介绍课程及其主要特点。 指导如何准备系统设计面试。 讨论了不同类型的抽象。 讨论每个大型系统都应该具备的一些不可或缺的非功能性特征, 在本章最后我们将介绍粗略的计算，这些计算使我们能够在设计问题期间估算资源。 构建块： 构建块 一章以介绍 16 种不同构建块的介绍性课程开始。这些构建块中的每一个都在一个独立的章节中进行了解释。以一章结束本节，该章也作为对下一节的介绍。 设计问题：这部分是课程的核心，由十三个设计问题精心打造而成。 结语：结语部分对本课程进行了总结，由两章组成: 惊人的失败 这些失败表明在现实世界中，即使是一个小错误也会导致一个大型的稳定的应用程序崩溃。此类失败甚至可能是不可避免的，但我们强调了一些减轻此类失败的措施。 结束语 [!NOTE] 尽管我们尽力保持各章的独立性，但读者会发现按给定顺序阅读它们很有用。 课程的优势 作为一份优秀的课程, 当然有其独树一帜的方面, 本课程优势如下: 优势 说明 构建块(组件) 这是一种现代的系统设计方法，我们使用较小的构建块构建更大的工程。 设计构建块 我们将把我们的每一个构建块都视为一个独立的小型设计问题。 逐步改进设计 模拟业务量提升过程,逐步修改设计方案，为复杂系统设计简单和渐进的解决方案。 评估设计 设计过程中充分考虑现实问题(资金/规模等), 考虑性能高低。 用更新的设计解决传统问题 本课程与最新的行业需求保持同步。 添加新的设计问题 对已经流传数十年的设计方案进行更新, 新角度看问题 精心设计的设计问题 每个问题在解决和设计方面都有其独到的地方。 FAANG 专家贡献 向最好的人学习。 让我们开始我们的系统设计之旅吧！ Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"系统设计面试/系统设计面试.html":{"url":"系统设计面试/系统设计面试.html","title":"系统设计面试","keywords":"","body":"系统设计面试 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"系统设计面试/什么是系统设计面试.html":{"url":"系统设计面试/什么是系统设计面试.html","title":"什么是系统设计面试","keywords":"","body":"什么是系统设计面试 本节目标:了解系统设计访谈 (SDI) 并战略性地处理它们 我们的系统设计课程对已经工作的人和准备面试的人同样有用。在本章中，我们重点介绍系统设计面试 (SDI System Design Interviews) 的不同方面，并给予面试者有用的提示。我们鼓励读者阅读本章，即使他们没有准备面试，相信本章会带给你别样的思考。 SDI 与其他面试有何不同？ 就像任何其他面试一样，我们需要战略性地进行系统设计面试。SDI 不同于编程面试。这次面试几乎不需要任何编码。 SDI 发生在更高的抽象层次上。我们找出需求并将它们映射到连接这些子系统的计算组件和高级通信协议。 最后的答案并不重要。重要的是面试者带领面试官经历的过程和旅程。 注意：与面试中的编码问题相比，系统设计更符合我们将在工作中完成的任务。 我们如何解决设计问题？ 设计问题一般是开放的/模糊的, 这种模糊模仿了现代商业的现实(没人一开始就能规划所有需求)。 面试官经常问一个众所周知的问题. 例如，设计 WhatsApp。现实中, 一个真正的 WhatsApp 应用程序具有很多功能，将所有这些功能都作为我们 WhatsApp 的需求不是一个明智的主意： 首先，我们的采访时间有限。 其次，使用系统的一些核心功能足以展示我们解决问题的能力。 我们可以告诉面试官，真正的 WhatsApp 还可以做很多其他我们不打算包含在设计中的事情。如果面试官有异议，我们可以相应地改变我们的行动计划。 以下是我们在系统设计面试中应该遵循的最佳实践： 系统设计面试的最佳实践 申请人应该提出正确的问题来巩固要求。 申请人还需要确定问题的范围，以便他们能够在有限的面试时间内做出很好的尝试来解决问题。SDI 通常为 35 至 40 分钟。 与面试官的沟通至关重要。默默地进行设计工作并不是一个好主意。相反，我们应该与面试官互动，以确保他们了解我们的思维过程。 展示高级设计 在高层次上，组件可以是前端、负载均衡器、缓存、数据处理等。系统设计告诉我们这些组件如何组合在一起。 架构设计通常将组件表示为框。这些框之间的箭头表示谁与谁数据交流以及这些框或组件如何组合在一起。 我们可以针对给定的问题绘制如上图所示的图表，并将其呈现给面试官。 SDI可能包含的问题 SDI 通常包含与设计如何随时间演变相关的问题，因为系统的某些方面增加了某个数量级——例如，用户数量、每秒查询数量等。系统社区普遍认为，当系统的某些方面增加十倍或更多时，原先的设计可能不适用并且需要更改。 设计和运行更大的系统需要仔细考虑，因为设计通常不会随着系统需求的增加而线性扩展。 面试官可能会问: \"为什么我们不设计一个已经能够处理比必要或预期拥有更强性能的系统?\" [!NOTE] 复杂系统需要的 dollar 成本, 是我们不得不这样做的主要原因 Google 的设计演变 早期版本的 Google 搜索在今天看来可能过于简单，但在当时却相当复杂。为了维持生计, 初创公司Google还降低了成本。从结果来看，无论我们作为设计师做什么，都会对企业及其客户产生影响。因此我们需要通过有效利用资源来满足或超越客户的需求。 设计挑战 业务会改变，业务会随着时间的推移而不可用，原因如下： 对于设计问题，没有单一的正确方法或解决方案。(没有银弹) 很多设计条件都是基于我们所做的假设。 设计师的责任 作为设计师，我们需要在设计层面提供容错能力. 要知道, 几乎所有的现代系统都使用现成的组件，并且有数以百万计的此类组件。运行过程中不可避免的会发生各种各样的错误, 我们需要向客户隐藏这种错误, 优化用户体验. 谁应该准备系统设计面试？ 正常来说，具有两年以上经验的中高级开发者至少会参加一次系统设计面试。对于更资深的申请者来说，一次求职过程中出现两到三次系统设计面试是很常见的。 近期，大公司也向一些初级应聘者提出了系统设计题. 所谓\"有备无患\", 早早的学习准备系统设计面试, 只会带来好处 (●'◡'●) 理论与实践 大多数系统设计理论都来自分布式系统领域。复习/学习分布式系统相关概念, 有助于我们学习本课程知识. 分布式系统为我们提供了成熟软件原则的路标。其中包括： 稳健性（在危机期间维持运营的能力） 可扩展性 可用性 表现 可扩展性 弹性（在中断后可接受的时间段内恢复正常操作的能力） 这些术语也充当面试官和应聘者之间的通用语。 例如，我们可能会说当网络组件发生故障时我们需要在可用性和一致性之间进行权衡，因为 CAP 定理表明我们不能在网络分区下同时顾全这两个方面。这种共同语言有助于沟通，也间接表明我们精通理论知识并具有相应实践经验。 请记住：向面试官展示他们的技能是候选人的工作。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"系统设计面试/如何为成功准备.html":{"url":"系统设计面试/如何为成功准备.html","title":"如何为成功做准备","keywords":"","body":"如何为成功做准备 本节目标: 明确面试准备路径与相关学习方法。 为了获得我们所申请的工作, 大量的准备是必要的。 根据候选人的资历和熟练程度，不同的候选人需要不同的面试准备时间。 对于普通候选人来说，准备系统设计面试可能需要三到四个月的时间。 本课程目标 本课程帮助读者学习或温习他们的系统设计技能。我们精心策划了一些传统的/新颖的设计问题，期望涵盖系统设计的深度和广度。 接下来介绍一些可以增加您知识的多样性和深度的内容。 技术博客 许多公司定期以技术博客的形式发布其重要工作的技术细节。 为什么公司急于分享他们工作的技术细节？ 向外界表明 本公司是一个 技术公司, 增加在社区中的话语权,激励更多人加入他们的公司。 有助于向 B2B 客户宣传公司产品。 有助于公司间接培训潜在的未来员工。 笔者的话: 关注阿里云/腾讯云/华为云, 有机会参加一些开源产品发布会, 可以更直观的感受到, 技术公司对开源社区的关注 (有种恨不得你们都来帮忙的感觉). 注意： 公司为了保证自己的技术优势, 开源的内容与实际生产的内容会存在细微的差别, 照搬并不可取. 我们可以研究这些博客，从而深入了解公司面临的挑战或问题以及他们在设计中实际应用了哪些修改来应对这些挑战。 注意：随时了解这些创新对专业人士很重要，对面试者来说更重要。 国外技术博客网站 Engineering at Meta、Meta Research、AWS Architecture Blog、Amazon Science Blog、Netflix TechBlog、Google Research、Engineering at Quora、Uber Engineering Blog、Databricks Blog、Pinterest Engineering、BlackRock Engineering、Lyft Engineering Salesforce Engineering。 国内技术博客网站 美团技术团队\\腾讯技术团队\\阿里云栖社区\\各大中间件中文网 注意：我们应该始终对未经同行评审的材料持保留态度。以批判的眼光并带着技术敏锐度思考博客所说的内容，确定他们所说的内容是否有意义。如果它没有意义，积极的讨论它, 这将是最好的进步方式。 [!NOTE] 笔者的话: 20年 Virtual app 项目公司开源了其工具框架, 许多开源作者以该框架为基础, 开发出 black Box 安卓沙盒; 随后这些开源作者收到了该公司的 '侵权威胁'; Black Box 询问系统为何有效 知其然知其所以然 通过问自己正确的问题，读者可以更深入的明白设计的理由, 掌握设计的原理。 了解流行的应用程序如何在较高层次上工作——例如 Instagram、Twitter 等。 开始理解并询问为什么使用某些组件而不是其他组件——例如，Firebase 与 SQL。 建立商业化标准的副项目。从一个简单的产品开始做起，慢慢演化/改进它。 从零开始构建一个系统，并熟悉其构建的所有过程和细节。 最终目标是: 做到可以在没有教程的情况下, 克隆一个流行的应用程序. 正确的方向 系统设计涉及更高层次的组件，我们需要避免进入战壕。(不需深入前线,稳坐中军帐) 我们应该少关注机制，多关注权衡取舍。 例如，讨论使用 Room 库还是原始 SQLite 是没有帮助的，因为 Room 库只是 SQLite 的包装器。更好的讨论是关于使用 MySQL 等传统数据库还是使用 MongoDB 等 NoSQL 存储。分析两种选择的利弊,得到正确答案. 我们应该从高层次的东西开始，低层次的细节会自动出现。 模拟面试 模拟面试是准备系统设计面试的好方法。读者可以与朋友配对并允许他们提问。当然，如果你没有朋友的话(嘿,小丑, 说滴就是你) 可以自己扮演采访者和受访者的角色。 通过这种方法，我们可以自我批评并向知识渊博的朋友寻求反馈, 更好的进步。 注意：没有模拟面试可以完全模拟实际面试，因此最好在公司进行真实面试。在我们完成了一两次面试后，就能更好地评估哪些是对的，哪些是不对的。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"系统设计面试/如何表现出色.html":{"url":"系统设计面试/如何表现出色.html","title":"如何表现出色","keywords":"","body":"如何表现出色 本节目标: 学会如何在系统设计面试中表现出色的技巧。 面试时要做什么 我们强调，候选人应该努力避免看起来毫无创意。面试官可能已经向许多候选人问过同样的问题。复制一个普通的设计可能不会给面试官留下深刻印象。 同时，面试可能是一个压力很大的场景。制定合理的解决问题的计划会是一个很好的策略。对于不同的候选人，可以有不同的策略来解决设计问题。我们建议采用以下策略。 制定战略，然后分而治之 面试过程中可以引导面试官, 按照如下方式进行: 提炼问题 我们需要了解设计问题及其要求。我们可以戴上产品经理的帽子，通过询问面试官细化的问题来确定相关功能的优先级。 我们的想法是与面试官一起去旅行，同时明白我们要怎么设计/为什么要这样设计。这些访谈旨在衡量我们是否能够从逻辑上从模糊的需求中推导出一个系统。 确保我们正在解决正确的问题。通常需要按照如下标准将需求分为两组： 客户直接需求——例如: 能够近乎实时地向朋友发送消息。 间接需求——例如: 消息服务性能不应随着用户负载的增加而降低。 注意：专业人士称这些为功能性和非功能性需求。 处理数据 我们需要识别和理解数据及其特征，以便为系统设计合适的数据存储系统和数据处理组件。 在寻找合适的系统和组件时可以参照下面的标准： 现在数据的大小是多少？ 随着时间的推移，数据预计会以什么速度增长？ 其他子系统或最终用户将如何使用这些数据？ 数据是重读还是重写？ 我们需要数据的严格一致性，还是最终一致性？ 数据的持久性目标是什么？ 存储或传输用户数据时有哪些隐私和监管要求？ 讨论组件 在某种程度上，我们的工作可以被视为: 明确将使用哪些组件 将它们放置在何处 组件之间如何相互交互。 eg: 数据库的类型——使用传统数据库还是 NoSQL 数据库？ 可能在某些情况下，我们有强烈的论据要使用 NoSQL 数据库，但我们的面试官可能会坚持我们使用传统数据库。遇到这种情况怎么办？ 可以考虑从理论上设计一个新组件, 既满足业务需求, 也满足面试官的想法, 这种交互是展示我们设计技能的绝佳机会。 注意：我们经常将组件的细节抽象为框，并使用箭头来显示它们之间的交互。它有助于在较高级别定义面向用户的 API，以进一步了解系统数据和交互需求。 讨论权衡 请记住，设计问题没有唯一的正确答案(没有银弹)。如果我们把同样的问题交给两个不同的小组，他们可能会想出不同的设计。 这是因为设计解决方案中存在多样性： 不同的组成有不同的优缺点。我们需要仔细权衡什么对我们有用。 不同的选择在金钱和技术复杂性方面有不同的成本。我们需要有效地利用我们的资源。 每个设计都有其弱点。作为设计师，我们应该意识到所有这些问题，并且我们有一个后续计划来解决它们。 我们应该向面试官指出我们设计中的弱点，并解释为什么我们还没有解决这些问题。 eg: 当前的设计无法处理十倍的负载，但可以预期到系统不会很快达到那个水平。 解决方案: 添加一个监控系统，密切关注负载随时间的增长情况，以便及时实施新设计。 这是一个例子，我们有意的选择牺牲性能的方式, 降低了系统成本。 在一个大系统中，总会有一些事情失败。 我们需要将容错和安全性集成到我们的设计中。 面试中不能做什么 以下是我们在系统设计面试中应该避免做的几件事： 不要在系统设计面试中编写代码。 不要在没有计划的情况下开始设计。 不要默默工作。 不要无缘无故地描述数字。我们必须框起来。 如果我们不知道某事，不要掩饰，也不要假装知道。 注意：如果面试官要求我们设计一个我们从未听说过的系统，我们应该诚实地告诉他们。面试官要么向我们解释，要么他们可能会改变问题。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"抽象/抽象.html":{"url":"抽象/抽象.html","title":"抽象","keywords":"","body":"抽象 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"抽象/为什么抽象很重要.html":{"url":"抽象/为什么抽象很重要.html","title":"为什么抽象很重要","keywords":"","body":"为什么抽象很重要 本节目标: 探索抽象的重要性。 什么是抽象？ 抽象是混淆我们不需要的细节的艺术。它使我们能够专注于大局。放眼大局是至关重要的，因为它隐藏了内在的复杂性，从而让我们对既定目标有更广泛的了解并始终专注于这些目标。下图是一个抽象的例子。 有了上面的抽象，我们就可以笼统地谈论鸟类，而不会被细节所困扰。 注意：如果我们画了一张特定鸟类或其特征的图片，我们将无法实现识别所有鸟类的目标。而只能识别一种特定类型的鸟。 在如今科学的背景下，我们都使用计算机来工作，我们不会从头开始制作硬件并开发操作系统。他们只是作为程序的基础环境, 我们的目标是专注手头的工作, 而不是深入构建系统. 开发人员使用大量库来开发大型系统。如果他们尝试从构建库入手(造轮子)，那他们就不能完成自己的工作。库为我们提供了一个简单的接口来使用函数并隐藏了它们的内部细节。一个好的抽象允许我们在具有相似需求的多个项目中重用它。 数据库抽象 事务是一种数据库抽象，它在并发用户读取、写入或更改数据时隐藏了许多有问题的结果，并提供一个简单的提交接口（如果成功）或中止（如果失败）。无论哪种方式，数据都会从一种一致状态移动到一种新的一致状态。事务使得用户不会被并发数据突变的微妙角落情况所困扰，而是专注于他们的业务逻辑。 分布式系统中的抽象 分布式系统中的抽象帮助工程师简化他们的工作，减轻他们处理分布式系统底层复杂性的负担。 随着亚马逊 AWS、谷歌云和微软 Azure 等许多大公司提供分布式服务，分布式系统的抽象越来越受欢迎。每项服务都提供不同级别的协议。 这些分布式服务背后的实现细节对用户来说是隐藏的，开发人员可以专注于应用程序，而不是深入研究通常非常复杂的分布式系统。 由于用户数量呈指数级增长，如果当今的应用程序基于单个节点，它们将无法保持响应/功能。分布式系统中的抽象帮助工程师快速转向分布式系统以扩展他们的应用程序。 注意：我们将在本章中看到抽象在通信、数据一致性和故障方面的使用。内容重点在于传达核心思想，但不一定要传达概念的所有细微之处。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"抽象/网络抽象远程过程调用.html":{"url":"抽象/网络抽象远程过程调用.html","title":"网络抽象:远程过程调用","keywords":"","body":"网络抽象：远程过程调用 本节目标: 从抽象的角度了解远程过程调用并理解它是如何帮助开发人员的 远程过程调用( RPC ) 通过隐藏打包和向远程服务器发送函数参数、接收返回值以及管理网络重试的复杂性，为开发人员提供抽象形式的 本地调用。 什么是 RPC？ RPC是一种广泛用于分布式系统的进程间通信协议。在网络通信的 OSI 模型中，RPC 跨越传输层和应用层。 程序调用的过程/子例程实际在单独的地址空间中执行, 这便是 RPC 机制. 注意：过程或子例程被编码为常规/本地过程调用，而无需程序员明确编码远程交互的细节, 具体细节由提供者管理。 RPC 是如何工作的？ 进行远程过程调用时，调用环境(服务请求者)暂停，过程参数通过网络发送到要执行过程的环境。 过程执行完成时，结果通过网络返回调用环境, 对于调用环境来说, 该结果如同本地调用获取的一样。 接下来我们参照 客户端-服务器程序 的例子。 一个基本的 RPC程序 主要涉及五个组件，如下图所示： 客户端、客户端Stub 和 RPC 运行上下文 的一个实例在客户端机器上运行。服务器、服务器Stub 和 RPC 运行上下文 的一个实例在服务器计算机上运行。 在 RPC 过程中，会发生以下步骤： 客户端通过正常提供参数来启动客户端Stub进程。客户端Stub存储在客户端的地址空间中。 客户端Stub 将参数转换成 标准化格式 并将它们 打包成消息 。将参数打包成消息后，客户端Stub 请求本地 RPC 运行上下文 将消息传递给服务器。 客户端的 RPC运行上下文 通过网络将消息传递给服务器。向服务器发送消息后，等待服务器的消息结果。 服务器上的 RPC 运行上下文接收消息并将其传递给服务器Stub。 注意： RPC 运行上下文负责通过网络在客户端和服务器之间传输消息。RPC 运行上下文的职责还包括重传、确认和加密。(实际上, RPC运行上下文保证消息被目标服务消费) 服务器Stub解压消息，从中取出参数，并使用本地过程调用调用所需的服务器例程来执行所需的操作。(笔者: 解压压缩消息, 实际上就是我们所说的序列化) 使用给定参数执行服务器例程后，结果将返回到服务器Stub。 服务器Stub将返回结果打包成消息，在传输层发送给服务器端的RPC运行上下文。 服务器的 RPC 运行上下文通过网络将打包结果返回给客户端的 RPC 运行上下文。 等待结果的客户端 RPC 运行上下文现在接收结果并将其发送到客户端Stub。 客户端Stub解包结果，执行过程此时返回给调用者。 注意： RPC 是一种通讯协议, 对应的是 HTTP HTTPS 金融通讯协议等 一些数据传输规范; TCP UDP 是具体的网络传输方式; 协议是具体实现方式的一种抽象 对于 RPC 协议调用过程 笔者推荐搜索 \"手写RPC协议实现\" 动手时间下, 手底下见真章 摘要 RPC 方法类似于调用本地过程，只不过被调用的过程通常在不同的进程和不同的计算机上执行。 RPC 允许开发人员在分布式系统之上构建应用程序。开发者可以在不知道网络通信细节的情况下使用RPC调用。有次便可以专注于设计方面，而不是机器和通信级别的细节。 (实际面试中, 具体细节是一定会问的, 一般精细到 TCP 与 UDP 的不同以及其实现特点即可, 至于实际传输中包的结构, 粘包如何处理等, 没有相应的项目经验便不做要求) Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"抽象/一致性模型.html":{"url":"抽象/一致性模型.html","title":"一致性模型","keywords":"","body":"一致性模型 本节目标: 掌握一致性模型, 做到根据需求确定应用程序的一致性模型。 什么是一致性？ 在分布式系统中，一致性可能意味着很多事情。 每个副本节点在给定时间点具有相同的数据视图。(zookeeper/主从备份等) 每次读请求获取最近写的值。(数据一致性) 这些并不是一致性的唯一定义，因为一致性有多种形式。 通常，一致性模型是用来推断分布式系统执行并发数据读取、写入和变更的正确性的抽象。 实际的系统设计过程中, 我们不可避免要用到 第三方存储系统 (eg: S3 / Cassandra)等, 这些第三方存储系统直接支持的 一致性模型, 是我们做取舍的关键因素 。 一致性范围的两端是： 最强一致性 最弱一致性 在这两端之间存在一致性模型，其中一些如下图所示: 谈到一致性, 就不得不谈到如下两个概念: 事务的 ACID 属性: 原子性(Atomicity) 一致性(Consistency) 隔离性(Isolation) 持久性(Durability) 数据库规则是ACID 一致性的核心。 如果模式指定值必须是唯一的，则一致的系统将确保该值在所有操作中都是唯一的。 如果外键指示删除一行也将删除关联的行，则一致的系统确保一旦基行被销毁，该行所有关联的数据都应被销毁。 CAP定理 一致性(Consistency)\\可用性(Availability)\\分区容错性(Partition tolerance) 分布式数据库系统中, 只能保持三个特性中的两个 (可以思考下为什么) CAP 一致性保证 在分布式系统中，相同逻辑值的每个副本始终具有相同的精确值。 值得注意的是，这是逻辑而非物理保证。 由于光速，在整个集群中复制数字需要一些时间。 实际操作中, 可以通过防止客户端访问存在正在变化的值，从逻辑上保证系统的一致性。 最终一致性 最终一致性是最弱的一致性模型。对顺序要求不严格. 可以简单理解为: 系统不额外对数据进行监管操作, 系统中此刻物理地址对应的值, 即是你获取的值. 最终一致性确保所有副本最终将相同的值返回给读取请求，但返回值并不意味着是最新值。该值最终将达到其最新状态。 - T1: 系统创建变量 x=2 - T2: 羊某发出写入请求, 预计在T4时刻将x修改为10 - T3: 羽某 高某 同时尝试读取变量 x, 系统将 x=2 返回给两人 - T4: 羽某 高某 再次读取变量x, 此刻及以后, 系统都将 x=10 返回给两人 最终一致性确保 高可用性。 实例 域名系统是一个高度可用的系统，基于域名系统, 我们可以通过 Internet 对一亿台设备进行名称查找。它使用最终一致性模型，不一定反映最新值。 注意： Cassandra 是一个高度可用的 NoSQL 数据库，提供最终一致性。 因果一致性 因果一致性 的工作原理是 将操作分为相关操作和独立操作。 相关操作也称为因果相关操作。 因果一致性保留因果相关操作的顺序。 假设有这样一段业务逻辑: x=a; b=x+5; y=b; 其中 x,y 两个变量分别由进程P1 P2 管理: 当P1进程对x进行赋值后, P2进程不能立刻对 y 进行赋值, 而是要先 read(x)a 在 write(y)b 这时, 我们称 read(x) 与 write(y) 之间有 因果一致性 此模型不确保对没有因果关系的操作进行排序。实际执行中, 未排序的操作可能出现在任何地方. 因果一致性总体上较弱，但强于最终一致性模型。它用于防止非直觉行为。 实例 因果一致性模型用于评论系统。例如，对于 Facebook 帖子上的评论进行回复，我们希望在其回复的评论之后显示评论。这是因为评论与其回复之间存在因果关系。 注意：除了本课讨论的四种一致性模型之外，还有许多一致性模型，并且仍有空间去定义新的一致性模型。研究人员开发了新的一致性模型。例如，Wyatt Lloyd 等人, 提出了因果+一致性模型来加速某些特定类型的交易。 因果+一致性模型论文 Wyatt Lloyd 普林斯顿大学名誉教授 顺序一致性 顺序一致性比因果一致性模型强。它保留每个客户端程序指定的顺序。然而，顺序一致性并不能确保写入是即时可见的，但可以确保写入的顺序是固定的。(保证了时钟顺序) 实例 在社交网络应用中，我们通常不关心一些朋友的帖子出现的顺序。但是，我们仍然希望单个朋友的帖子以正确的创建顺序出现）。同样，我们希望我们的朋友在帖子中的评论按照他们提交的顺序显示。顺序一致性模型捕获了所有这些特质。 严格一致性(线性化) 严格一致性/线性化是最强的一致性模型。此模型确保来自任何副本的读取请求将获得最新的写入值。一旦客户端收到写入操作已执行的确认，其他客户端就可以读取该值。 分布式系统天然不支持线性化, 思考这样一个场景: 我们的系统拥有三个响应节点 NodeA NodeB NodeC T1: 三个节点中拥有值: x = 2 T2: NodeA处理请求 x=10, 预计 T3时刻同步到NodeB T4时刻同步到NodeC T3: 羊某 羽某 分别请求 NodeB NodeC 尝试获取 x; 两人获取到了不同的结果 该系统不符合 严格一致性 笔者: 实际生产环境中, 可以通过锁/修改集群方式 解决该问题, 但这无疑增加了系统开销,降低了系统可用性, 对压力非常大的读写系统来说, 是不可忍受的 线性化影响系统的可用性，这就是为什么它并不总是被使用的原因。具有强一致性要求的应用程序使用基于复制/仲裁等技术来提高系统的可用性。 实例 更新帐户的密码需要严格的一致性。例如，如果我们怀疑我们的银行账户有可疑活动，我们会立即更改密码，这样未经授权的用户就无法访问我们的账户。如果由于缺乏严格的一致性而可以使用旧密码访问我们的帐户，那么更改密码将是无用的安全策略。 注意： Amazon Aurora 提供强一致性。 摘要 线性化的服务要求以顺序的/实时的顺序执行事务/操作。通过限制线性服务的步骤,降低交互次数, 我们可以更容易的在其之上创建应用程序. 线性化的服务比具有较弱一致性的服务具有更差的性能，但数据更为安全。 如果应用程序程序员使用具有强一致性模型的服务，则他们必须牺牲性能和可用性。这些模型可能会破坏基于它们构建的应用程序的不变性，以换取更高的性能。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"抽象/故障模型.html":{"url":"抽象/故障模型.html","title":"故障模型","keywords":"","body":"故障模型的范围 本节目标: 了解分布式系统中的故障并掌握处理故障的相关模型。 故障在分布式系统的世界中是常见的，它们可能以各种形式出现, 有时是偶尔复现, 有时会持续很长时间。 故障模型为我们提供了一个框架来推断故障的影响范围一级可能的处理故障的方法。 下图展示了一系列不同的故障模型： 失败停止 Fail-stop 本故障类型中: 分布式系统中的一个节点永久停止。但其他节点仍然可以通过与该节点通信来检测该节点。 从开发人员的角度看, fail-stop故障模型是最简单/方便进行处理的。 崩溃 本故障类型中: 分布式系统中的一个节点静默停止，其他节点无法检测到该节点已停止工作。 遗漏失败 本故障类型中: 节点无法发送或接收消息。 有两种类型的遗漏故障: 节点未能响应传入请求，则称为发送遗漏失败。 节点没有收到请求，这被称为接收遗漏失败。 笔者的话: 本故障类型对应 消息丢失/消息未消费等 临时失败 本故障类型中: 节点因为延迟等原因没有及时返回结果。 这种失败可能是由于糟糕的算法、糟糕的设计策略或处理器时钟之间失去同步造成的。 拜占庭失败 本故障类型中: 节点表现出随机行为，例如在任意时间传输任意消息、产生错误结果或中途停止。这主要是由于恶意实体或软件错误的攻击而发生的。拜占庭故障是最具挑战性的故障类型。 笔者的话: 指假如系统的某个模块发生故障, 不能返回正确结果的时候, 如何确保整个系统的准确性. Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"非功能性系统特征/非功能性系统特征.html":{"url":"非功能性系统特征/非功能性系统特征.html","title":"非功能性系统特征","keywords":"","body":"非功能性系统特征 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"非功能性系统特征/可用性.html":{"url":"非功能性系统特征/可用性.html","title":"可用性","keywords":"","body":"可用性 本节目标: 了解可用性、掌握衡量可用性的方法并明白其重要性。 什么是可用性？ 可用性是客户访问某些服务或基础设施并保持正常运行的时间的百分比。 eg: 一项服务具有 100% 的可用性，则意味着该服务在任意时刻都可以按预期运行和响应 衡量可用性 从数学上讲，可用性A是一个比率。值越高 A 越好。我们也可以把它写成一个公式： $$ A(百分比)=\\frac{总运行时间-服务不可用时间}{总运行时间}*100% $$ 一般情况下, 我们使用 '9' 作为评价系统可用性的标准 (就是日常常说的 三9标准) '九'可用性 可用性百分比与服务停机时间 可用性 ％ 每年停机时间 每月停机时间 每周停机时间 90%（一九） 36.5天 72小时 16.8小时 99%（2 个九） 3.65天 7.20小时 1.68小时 99.5%（2 个九） 1.83天 3.60小时 50.4分钟 99.9%（3 个九） 8.76小时 43.8分钟 10.1分钟 99.99%（4 个九） 52.56分钟 4.32分钟 1.01分钟 99.999%（5 个九） 5.26分钟 25.9 秒 6.05秒 99.9999%（6 个九） 31.5 秒 2.59 秒 0.605 秒 99.99999%（7 个九） 3.15秒 0.259 秒 0.0605 秒 可用性和服务提供商 不同的服务提供商可能会在不同的时间点开始测量可用性。 一些云提供商在首次提供服务时就开始对服务可用性进行测量，而有些则在特定客户开始使用该服务后才会对其进行测量。 一般情况下 服务没有对所有客户关闭，不计入宕机时间。 计划停机时间不计入可用性计算。 网络攻击导致的停机时间不计入可用性计算。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-15 "},"非功能性系统特征/可靠性.html":{"url":"非功能性系统特征/可靠性.html","title":"可靠性","keywords":"","body":"可靠性 了解可靠性、如何衡量它及其重要性。 什么是可靠性？ 可靠性, 是服务在指定时间内执行其功能的概率。可靠性衡量服务在不同操作条件下的表现。 我们经常使用平均无故障时间 (MTBF)和平均修复时间 (MTTR)作为衡量可靠性的指标。 $$ 平均无故障时间=\\frac{总时间-宕机时间}{总失败次数} $$ $$ 平均修复时间=\\frac{总维护时间}{总维修次数} $$ 可靠性和可用性 可靠性 和 可用性 是衡量服务是否符合商定的服务水平目标 (SLO)的两个重要指标。 可用性由时间驱动, 表示时间范围内服务是否可用 可靠性由故障驱动, 表示故障对服务造成的影响程度 两者用于评估服务的健康状况 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-14 "},"非功能性系统特征/可扩展性.html":{"url":"非功能性系统特征/可扩展性.html","title":"可扩展性","keywords":"","body":"可扩展性 本节目标: 了解可扩展性及其在系统设计中的重要性。 什么是可扩展性？ 可扩展性 是系统在不影响性能的情况下处理不断增加的工作负载的能力。 eg: 搜索引擎必须随其业务发展容纳越来越多的用户, 并增加索引的数据量。 工作负载可以有不同的类型： 请求工作量：系统处理的请求数。 数据/存储工作量：系统存储的数据量。 标准 以下是可扩展性的不同维度： 大小可扩展性：如果我们可以简单地向系统添加额外的用户和资源，则系统是大小可扩展的。 管理可扩展性：如果新的组织或用户轻松共享系统, 则系统是管理可扩展的 。 地理可扩展性：在部署成本不同的地理位置, 系统可以保持正常的性能, 则该系统是地理可扩展的。 不同的可扩展性方法 以下是实现可扩展性的不同方法。 垂直可扩展性——向上扩展 垂直扩展，也称为“向上扩展”，是指通过为现有设备提供额外功能（例如，额外的 CPU 或 RAM）来进行扩展。垂直扩展允许我们扩展当前的硬件或软件容量，但该扩展方案存在明显的瓶颈, 很容易达到性能上限。垂直扩展需要庞大的资金支持。 横向扩展——向外扩展 水平扩展，也称为“向外扩展”，是指增加网络中的机器数量。甚至, 我们可以使用一些商业节点(云服务器)，它们的成本相对更低。这要求我们构建一个系统, 使很多节点都可以在其中工作, 从整体上看, 它们就像一个服务器一样。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"非功能性系统特征/可维护性.html":{"url":"非功能性系统特征/可维护性.html","title":"可维护性","keywords":"","body":"可维护性 本节目标: 了解可维护性、掌握衡量标准并理解其与可靠性之间的关系。 什么是可维护性？ 完成系统开发/部署工作后，主要任务变为 通过查找和修复错误、添加新功能、保持系统平台更新以及确保系统平稳运行来保持系统的正常运行。 定义系统设计这方面的特征的指标是 可维护性。我们可以将可维护性的概念进一步划分为三个基本方面： 可操作性：保证系统在正常情况下能够顺利运行后，衡量在出现故障时能够达到正常状态的难易程度。 清晰度：这是指代码的简单性。代码库越简单，就越容易理解和维护，反之亦然。 可修改性：指系统能够毫不费力地集成修改后的、新的和不可预见的功能的能力。 衡量可维护性 可维护性, M, 是服务在故障发生的指定时间内恢复其功能的概率。M衡量服务恢复正常运行状态的便捷程度。 例如，假设某个组件定义半小时的可维护性值为 95%。在这种情况下，组件在半小时内恢复到完全激活状态的概率是 0.95。 注意：可维护性是对系统在运行时进行维修和修改能力的表达。 使用（平均修复时间）MTTR 作为衡量M的标准。 $$ 平均修复时间=\\frac{总维护时间}{总维护次数} $$ 换句话说，MTTR 是修复和恢复故障组件所需的平均时间。我们的目标是尽可能降低 MTTR 值。 可维护性和可靠性 可维护性是可靠性的一种更具体的表达。 它们之间的唯一区别是关注的变量不同。 可维护性是指 time-to-repair， 可靠性是指两者time-to-repair和time-to-failure。 对可维护性和可靠性分析可以帮助我们了解可用性、停机时间和正常运行时间。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-14 "},"非功能性系统特征/容错.html":{"url":"非功能性系统特征/容错.html","title":"容错","keywords":"","body":"容错 本节目标: 了解容错, 掌握衡量标准并理解其重要性。 什么是容错？ 现实世界中的大型应用程序运行着数百台服务器和数据库，以满足数十亿用户的请求,也承担着存储重要数据的任务。这些应用程序需要一种保证数据安全并通过避免单点故障来避免重新计算的计算密集型任务的机制。(也就是容错) 容错指即使一个或多个组件发生故障，系统也能持续执行的能力。相关组件可以是软件(常见的校验程序)或硬件(RAID0~9等)。构思一个百分百容错的系统实际上非常困难。 容错相关系统特性: 可用性侧重于 24*7 用户请求成功与否。 可靠性侧重于每个客户的请求与其响应结果。 容错技术 故障一般发生在 硬件 或 软件 级别, 并最终对数据造成影响 从系统结构的角度, 可以有很多方法实现容错. 接下来我们讨论一些通用的 容错技术. 复制 基于复制的容错 是应用最广泛的容错技术。使用这种技术，我们可以复制服务和数据,将故障节点替换为健康节点，将故障数据存储替换为其副本。大型服务可以在不影响最终客户的情况下透明地进行切换。 为单独的存储创建数据的多个副本也引入了新的技术挑战。 技术难点 当数据发生更新时，所有副本都需要定期更新以保持一致性。更新副本中的数据是一项具有挑战性的工作。当系统需要强一致性时，我们可以同步更新副本中的数据。但是，这会降低系统的可用性。 如果可以容忍最终一致性，我们可以异步更新副本中的数据，但这会导致读过时。 需要使用 CAP 定理 对系统进行灵活的设计 [!NOTE] 笔者的话: 实际项目中, 对应 各种中间件的主从备份 日志备份等 检查点 检查点是一种将系统某个稳定的一致的点 保存在稳定存储中的技术。 检查点可以按照一定的规则在多个时间点执行。主要目的是保存给定点的计算状态。当系统发生故障时，我们可以从上一个检查点获取最后计算的数据并从重新开始工作。 技术难点 检查点也有我们在复制中遇到的同样问题。 当系统必须执行检查点时，需要确保系统处于一致状态，这意味着所有修改系统状态的进程都将停止。这种类型的检查点称为同步检查点。 另一方面，不一致状态下的检查点会导致数据不一致问题。让我们看下图，了解一致状态和不一致状态之间的区别： Consistent state一致状态：上图显示系统执行检查点时进程之间没有通信。所有进程在检查点之前和之后都在发送或接收消息。系统的这种状态称为一致状态。 Inconsistent state不一致状态：上图还显示了当系统执行检查点时，进程通过消息进行通信。这表示不一致的状态，因为当我们得到一个先前保存的检查点时，进程 i有消息 m1，进程j将没有消息发送记录。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"粗略计算/粗略计算.html":{"url":"粗略计算/粗略计算.html","title":"粗略计算","keywords":"","body":"粗略计算 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"粗略计算/正确看待粗略的数字.html":{"url":"粗略计算/正确看待粗略的数字.html","title":"正确看待粗略的数字","keywords":"","body":"正确看待粗略的数字 本节目标: 学会在粗略计算中使用适当的数字评估系统规模 为什么我们使用粗略计算？ 分布式系统是 通过网络连接的各种各样的计算节点 组成 , 它们可以以多种不同的方式连接。粗略的计算帮助我们在系统设计的层面上忽略系统的细节, 从而关注更重要的方面。 粗略计算的维度(示例)： 服务器可以支持的并发 TCP 连接数。 Web、数据库或缓存服务器每秒可以处理的请求数 (RPS)。 服务的存储要求规模。 当进行估算时, 如果采用了错误的估算值, 可能会导致设计出现缺陷。因此,在设计问题中采用正确的估算值是非常重要的. 我们将在本课中详细讨论系统设计估算相关概念. 这些概念如下: 数据中心服务器的类型。 不同组件的实际访问延迟。 服务器可以处理的 RPS 估计值。 带宽、服务器和存储估算方式。 数据中心服务器的类型 数据中心没有单一类型的服务器。 企业应用使用商用硬件来节省成本并开发可扩展的解决方案。下面，我们将讨论数据中心内常用于处理不同工作负载的服务器类型。 网络服务器 为了保障可伸缩性，Web 服务器与应用程序服务器分离。 Web 服务器是负载均衡器之后的第一个关联点。数据中心的机架上布满了 Web 服务器，这些服务器通常处理来自客户端的 API 调用。 根据所提供的服务，网络服务器中的内存和存储资源可以是中小型的。 但是，此类服务器需要良好的计算资源。 例如，Facebook 使用了具有 32 GB RAM 和 500 GB 存储空间的 Web 服务器。但出于其高端计算需求，它与英特尔合作构建了定制的 16 核处理器。 [!NOTE] 本课中引用的许多数字是从 Facebook 于 2011 年开源的数据中心设计中获得的。由于 2004 年以来, 摩尔定律揭示的硬件性能下降，这些数字在今天依然适用。 应用服务器 应用服务器运行核心应用软件和业务逻辑。 Web 服务器和应用程序服务器之间的区别有些模糊。 应用程序服务器主要提供动态内容，而网络服务器主要向客户端（主要是网络浏览器）提供静态内容。 它们可能需要大量的计算和存储资源。存储资源可以是易失性的也可以是非易失性的。 Facebook 使用的应用程序服务器具有高达 256 GB 的 RAM, 并采用两种类型的存储——传统的旋转磁盘和闪存——容量高达 6.5 TB。 存储服务器 随着互联网用户的爆炸式增长，巨头服务存储的数据量成倍增长。 除此之外, 各种类型的数据被存储在不同的存储单元中。 例如，YouTube 使用以下数据存储方案： Blob 存储方案: 编码的视频流文件 临时处理队列存储方案: 容纳每天上传到 YouTube 进行处理的数百小时视频内容。 Bigtable 专业存储方案: 存储大量视频缩略图。 关系数据库管理系统 (RDBMS) 存储用户和视频元数据 Hadoop HDFS 存储用于分析的数据 存储服务器主要包括结构化（例如SQL）和非结构化（NoSQL）数据管理系统。 回到 Facebook 的例子，我们知道他们使用了存储容量高达 120 TB 的服务器。 凭借使用中的服务器数量，Facebook 能够容纳 EB 级的存储空间。一个艾字节(exbyte)是 10^18 字节。按照惯例，我们以 10 为基数而不是 2 为基数来测量存储和网络带宽。值得注意的是, 服务器的 RAM 只有 32GB。 注意：上述服务器并不是数据中心中唯一的服务器类型。数据中心还需要服务器来提供配置、监控、负载平衡、分析、会计、缓存等服务。 Facebook 开源的数字目前已经过时。在下表中，我们描述了可用于当今数据中心的服务器的功能： 典型服务器规格 成分 数数 插座数量 2个 处理器 英特尔至强X2686 芯数 36 核（72 线程） 内存 256GB 高速缓存 (L3) 45MB 存储容量 15 TB 上表所示数字来源于 亚马逊裸机服务器，但可能会有或多或少的强大机器支持更高的 RAM（高达 8 TB）、磁盘存储（最多 24 个磁盘，每个磁盘高达 20 TB，大约在 2021 年）和高速缓存（最多 120 MB）。 要记住的标准数字 一项服务的规划和实施需要付出很多努力。 如果对机器可以处理的工作负载类型没有任何基本了解, 则几乎不可能对服务部署进行规划。物理延迟在决定机器可以处理的工作量方面起着重要作用。 下表描述了系统设计人员在执行资源估算时应该知道的一些重要数字。 重要的延迟 成分 时间（纳秒） 一级缓存参考 0.9 二级缓存参考 2.8 L3缓存参考 12.9 主内存参考 100 使用 Snzip 压缩 1KB 3,000（3 微秒） 从内存中顺序读取 1 MB 9,000（9 微秒） 从 SSD 顺序读取 1 MB 200,000（200 微秒） 同一数据中心内的往返 500,000（500 微秒） 以 ~1GB/sec 的速度从 SSD 顺序读取 1 MB 1,000,000（1 毫秒） 磁盘寻道 4,000,000（4 毫秒） 从磁盘顺序读取 1 MB 2,000,000（2 毫秒） 发包SF->NYC 71,000,000（71 毫秒） 除了上面列出的延迟之外，还有以典型的单服务器数据存储可以处理的每秒查询数 (QPS) 吞吐量数字。 重要费率 MySQL处理的QPS 1000 键值存储处理的QPS 10,000 缓存服务器处理的QPS 100,000–1 百万 上面的数字是近似值，并且会因查询类型（点 和 范围）、机器规格、数据库设计、索引等多种原因而有很大差异。 [!NOTE] 点 : 查找单个项目称为点查询; eg: SELECT * FROM STUDENTS WHERE NAME = \"John\"; 为点查询, 其搜索的是单个值 \"John\" 范围 : 检索边界之间的信息/记录的查询; eg: SELECT * FROM STUDENTS WHERE age BETWEEN 15 AND 18; 请求估计 本节讨论典型服务器每秒可以处理的请求数。在服务器内，资源有限，根据客户端请求的类型，不同的资源可能成为瓶颈。 让我们了解两种类型的请求。 CPU 绑定请求：限制因素是 CPU 的请求类型。 内存限制请求：受机器内存量限制的请求类型。 让我们估算每种请求的 RPS。但在此之前，我们需要做出以下假设： 我们的服务器符合我们在上表中定义的典型服务器的规格。 操作系统和其他辅助进程总共消耗了 16 GB 的 RAM。 每个工作人员消耗 300 MB 的 RAM 存储空间来完成一个请求。 为简单起见，我们假设 CPU 从 RAM 中获取数据。因此，缓存系统可确保所有必需的内容都可用于服务，而无需访问存储层。 每个 CPU 绑定请求需要 200 毫秒，而内存绑定请求需要 50 毫秒才能完成。 让我们对每种类型的请求进行计算。 CPU 绑定：用于计算 CPU 绑定请求的 RPS 的简单公式是： $$ RPS(CPU) = Num(CPU) * \\frac{1}{Task(time)} $$ 在此计算中，相关术语意义如下： RPS(CPU): CPU绑定 RPS Num(CPU): CPU线程数, 也成为硬件线程 Task(time): 完成每项任务所需的时间 按照本公式, RPS(CPU) 值为: $$ RPS(CPU) = 72*\\frac{1}{200ms}=360RPS $$ 从抽象的角度看, 我们可以将一秒钟想象成一个盒子，计算大盒子里可以容纳多少个小盒子（任务）-- 即一秒内CPU可以完成的任务数量。 直观来看, 更多的CPU/线程可以得到更高的 RPS。 内存绑定请求：用于计算内存绑定请求的公式为: $$ RPS(memory)=\\frac{RAM(size)}{Worker(memory)}*\\frac{1}{Task(time)} $$ 相关术语含义如下： RPS(memory): 内存绑定 RPS RAM(size): RAM 总大小 Worker(memory): 单个请求任务消耗的时间 按照本公式, RPS(memory) 值为: $$ RPS(memory)=\\frac{240GB}{300MB}*\\frac{1}{50ms}=16000RPS $$ 服务接收 CPU 绑定和内存绑定的请求。假设一半请求受 CPU 限制 另一半受内存限制的情况，我们总共可以处理 $$ \\frac{360}{2}+\\frac{1600}{2}=8180RPS $$ 上述计算只是一个近似值，用于帮助您了解估算 RPS 所涉及的基本因素。 实际上，还有很多其他因素在起作用。 例如，如果数据在 RAM 中不可用，或者如果向数据库服务器发出请求，则执行磁盘查找需要延迟, 数据库查询需要延迟, 网络也存在延迟。 此外，查询的类型也很重要。 故障、代码错误、节点故障、停电、网络中断等等都是不可避免的因素。 正常的商业服务运行中, 各种类型的请求都会发生, 仅从 RAM 提供静态内容的服务器(前端)可能会处理多达 500k PRS 的数据. 另一方面 图像处理等计算密集型任务可能最多只允许 50RPS. 注意：实际上，容量估算是一个难题，社区多年来一直在学习如何改进它。 监控系统密切关注我们基础架构的所有部分，以便在服务器过载时向我们发出早期警告。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"粗略计算/资源估算示例.html":{"url":"粗略计算/资源估算示例.html","title":"资源估算示例","keywords":"","body":"资源估算示例 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"构建块/构建块.html":{"url":"构建块/构建块.html","title":"构建块","keywords":"","body":"构建块 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"构建块/现代系统设计构建块简介.html":{"url":"构建块/现代系统设计构建块简介.html","title":"现代系统设计构建块简介","keywords":"","body":"现代系统设计构建块简介 本节目标: 掌握如何像使用乐高积木一样, 使用系统设计制作更大/更迷人的艺术品。 现代系统设计的自下而上方法 尽管每个系统细节方面都有其独特性, 但更多的, 系统设计方法也是有迹可循的。本课程中, 我们提取了设计问题中有迹可循的/相似的部分, 并将其提炼为 构建块. 在第三部分实际系统设计模块, 我们会一次或多次的使用我们提炼的构建块. 基于 组件化 的构想, 我们把构建块单独摘出, 通过一次彻底的讨论完成其设计. 这意味着在之后的任何地方, 我们将直接使用它, 而不必再次了解它. 我们可以将构建块视为更有效/更有能力的系统基本组件. 我们讨论的许多构建块也可用于公共云中的实际使用，例如 Amazon Web Services (AWS)、Azure 和 Google Cloud Platform (GCP)。读者可以使用这样的结构来构建一个系统进一步巩固我们的理解。（我们不会在本课程中构建系统，但会将其作为练习留给感兴趣的学习者。） 我们将详细讨论以下构建块： 域名系统：本章着重于如何为通过不同 Internet 协议连接到 Internet 的计算机设计分层/分布式的命名系统。 负载均衡器： 本章着重于负载均衡器的设计，它用于在可用服务器池中公平分配传入的客户端请求, 同时减少负载并可以绕过发生故障的服务器。 数据库： 本章支持我们存储、检索、修改和删除等不同数据处理过程相关的数据。在本节，我们将讨论分布式数据库的数据库类型、复制、分区和分析方法等。 Key-Value 存储：本章是一种非关系型数据库，以键值对的形式存储数据。在本节，我们将深入了解键值存储的设计, 并掌握其实现 可扩展性/持久性/可配置性等概念的方法。 内容分发网络： 本章将设计一个内容分发网络 (CDN)，用于保存视频、图像、音频和网页等病毒式传播(存在无限复制且重复复制可能性) 的内容。保证其可以有效的向用户交付内容, 同时减少书籍中心的延迟与负担。 序列生成器： 本章将专注于唯一 ID 生成器的设计，主要关注于因果关系ID生成规则。涉及到生成唯一 ID 的三种不同方法。 服务监控： 监控系统在分布式系统中至关重要，其有助于开发人员分析系统并在出现问题时提醒相关人员。好的监控系统可以防患于未然，保证管理员可以在 问题/故障 传播或不可控之前采取行动,避免线上问题。本章我们将构建两个监控系统, 一个用于服务端, 一个用于客户端。 分布式缓存：本章将设计一个分布式缓存系统，由多个缓存服务器构成并协调存储经常访问的数据。 分布式消息队列： 本章将重点关注由多个服务器组成的队列的设计，并引入了称为生产者和消费者的交互实体。这两个概念有助于解耦生产者和消费者，实现独立的可扩展性，并增强可靠性。 发布-订阅系统：本章将重点关注称为发布-订阅系统的异步服务到服务通信方法的设计 。它广泛应用于无服务器、微服务架构和数据处理系统。 速率限制器：本章将设计一个系统，根据预定义的限制来限制传入的服务请求。通常用作服务的防御层，以免服务被过度使用 -- 无论是故意的还是不小心(( ‵▽′)ψ)。 Blob Store：本章专注于非结构化数据的存储解决方案——例如，多媒体文件和二进制可执行文件。 分布式搜索：搜索系统接受用户的查询并在几秒或更短时间内返回相关内容。本章侧重于搜索相关的三个不可或缺的组件：爬网、索引和搜索。 分布式日志记录：日志记录是一项耗时且缓慢的 I/O 密集型操作。在这里，我们将设计一个系统，允许分布式系统中的服务有效地记录它们的事件。该系统将具有可扩展性和可靠性。 分布式任务调度： 本章将设计一个在任务和资源之间进行调解的分布式任务调度系统。它智能地将资源分配给任务，以满足任务级和系统级目标。通常用于卸载异步完成的后台处理。 分片计数器：本章演示了一个高效的分布式计数系统，可处理数百万个并发读/写请求，例如对名人推文的点赞。 我们对构建块进行了拓扑排序，依赖于其他构建块的构建块较晚出现。 约定 为了更具体的描述构建块，在设计构建块/设计问题时，我们都会添加需求部分。需求部分将揭示我们期望从开发的设计中获得的可交付成果。需求将有两个子类别： 功能需求： 代表所设计系统的用户将能够使用的功能。例如，系统将允许用户使用搜索栏搜索内容。 非功能性需求 (NFR)：非功能性需求是系统用户认为系统可用所依据的标准。NFR 可能包括高可用性、低延迟、可扩展性等要求。 让我们从构建块开始。(^_^) Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-20 "},"域名系统/域名系统.html":{"url":"域名系统/域名系统.html","title":"域名系统","keywords":"","body":"域名系统 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"域名系统/域名系统DNS简介.html":{"url":"域名系统/域名系统DNS简介.html","title":"域名系统DNS简介","keywords":"","body":"域名系统(DNS)简介 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"域名系统/域名系统如何运作.html":{"url":"域名系统/域名系统如何运作.html","title":"域名系统如何运作","keywords":"","body":"域名系统如何运作 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"负载均衡器/负载均衡器.html":{"url":"负载均衡器/负载均衡器.html","title":"负载均衡器","keywords":"","body":"负载均衡器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"负载均衡器/负载均衡器简介.html":{"url":"负载均衡器/负载均衡器简介.html","title":"负载均衡器简介","keywords":"","body":"负载均衡器简介 了解负载均衡器的基础知识及其提供的服务。 我们将涵盖以下内容什么是负载均衡？放置负载平衡器负载均衡器提供的服务 什么是负载均衡？ 典型的数据中心每秒可能有数百万个请求到达。为了服务这些请求，数千（或十万）台服务器协同工作以分担传入请求的负载。 注意：在这里，重要的是我们要考虑传入请求将如何在所有可用服务器之间分配。 负载均衡器( LB )是问题的答案。负载均衡器的工作是在可用服务器池中公平地分配所有客户端的请求。负载平衡器执行此工作以避免服务器过载或崩溃。 负载平衡层是防火墙之后数据中心内的第一个联系点。如果服务每秒处理几百甚至几千个请求，则可能不需要负载平衡器。但是，为了增加客户端请求，负载均衡器提供以下功能： 可扩展性：通过添加服务器，可以无缝地增加应用程序/服务的容量。负载均衡器使这种放大或缩小对最终用户透明。 可用性：即使部分服务器宕机或出现故障，系统仍然可用。负载平衡器的工作之一是隐藏服务器的故障和故障。 性能：负载平衡器可以将请求转发到负载较小的服务器，因此用户可以获得更快的响应时间。这不仅可以提高性能，还可以提高资源利用率。 以下是负载均衡器工作原理的抽象描述： 放置负载均衡器 通常，LB 位于客户端和服务器之间。请求通过负载平衡层到达服务器并返回到客户端。但是，这并不是使用负载均衡器的唯一点。 让我们考虑三个众所周知的服务器组。即网络、应用程序和数据库服务器。为了在可用服务器之间分配流量负载，可以按以下方式在这三个服务的服务器实例之间使用负载平衡器： 在应用程序的最终用户和 Web 服务器/应用程序网关之间放置 LB。 将 LB 放置在运行业务/应用程序逻辑的 Web 服务器和应用程序服务器之间。 将 LB 放置在应用程序服务器和数据库服务器之间。 实际上，在系统设计中，负载均衡器可以潜在地用于具有多个实例的任意两个服务之间。 负载均衡器提供的服务 LB 不仅使服务具有可扩展性、可用性和高性能，它们还提供如下一些关键服务： 健康检查：负载均衡使用心跳协议来监控终端服务器的健康状况和可靠性。健康检查的另一个好处是改善了用户体验。 TLS 终止：LB 通过与客户端处理 TLS 终止来减轻终端服务器的负担。 预测分析：LB 可以通过对经过它们的流量执行分析或使用随时间推移获得的流量统计数据来预测流量模式。 减少人为干预：由于 LB 自动化，处理故障时需要减少系统管理工作。 服务发现：LB 的一个优点是通过查询 服务注册中心将客户端的请求转发到适当的托管服务器。 安全性：LB 还可以通过减轻OSI 模型不同层（第 3、4 和 7 层）的拒绝服务 (DoS)等攻击来提高安全性。 作为一个整体，负载均衡器 为系统的整体设计提供了灵活性、 可靠性、冗余性和效率。 深思熟虑 问题 如果负载均衡器发生故障怎么办？它们不是单点故障 (SPOF) 吗？ 隐藏答案 负载均衡器通常成对部署，作为灾难恢复的一种手段。如果一个负载平衡器发生故障，并且没有任何东西可以故障转移到，整个服务就会停止。通常，为了保持高可用性，企业使用负载均衡器集群，这些负载均衡器使用心跳通信来随时检查负载均衡器的健康状况。在主 LB 发生故障时，备份可以接管。但是，如果整个集群出现故障，也可以在紧急情况下进行手动重新路由。 在接下来的课程中，我们将了解如何在复杂的应用程序中使用负载均衡器，以及哪种类型的负载均衡器适用于哪种用例。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"负载均衡器/全局和本地负载均衡.html":{"url":"负载均衡器/全局和本地负载均衡.html","title":"全局和本地负载均衡","keywords":"","body":"全局和本地负载均衡 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"负载均衡器/负载均衡器的高级详细信息.html":{"url":"负载均衡器/负载均衡器的高级详细信息.html","title":"负载均衡器的高级详细信息","keywords":"","body":"负载均衡器的高级详细信息 了解负载均衡器及其在系统中的用法。 我们将涵盖以下内容负载均衡器的算法静态与动态算法有状态与无状态 LB状态负载均衡无状态负载均衡负载均衡器的类型负载均衡器部署Tier-0 和 Tier-1 LBTier-2 LBTier-3 LB实例负载均衡器的实现硬件负载平衡器软件负载平衡器云负载均衡器结论 本课将重点介绍本地负载均衡器中使用的一些著名算法。我们还将了解负载均衡器如何连接以形成层次结构，从而跨 LB 的不同层共享工作。 负载均衡算法 负载平衡器根据算法分配客户端请求。下面给出一些著名的算法： 循环调度：在该算法中，每个请求都以重复顺序的方式转发到池中的服务器。 Weighted round-robin：如果某些服务器具有更高的服务客户端请求的能力，那么最好使用加权循环算法。在加权循环算法中，每个节点都被分配了一个权重。LB 根据节点的权重转发客户端的请求。权重越高，分配的数量越多。 最少连接数：在某些情况下，即使所有服务器都具有相同的服务客户端的能力，某些服务器上的负载不均衡仍然是可能的。例如，一些客户可能有一个需要更长的服务时间的请求。或者某些客户端可能在同一连接上有后续请求。在这种情况下，我们可以使用像最少连接这样的算法，将较新到达的请求分配给现有连接较少的服务器。在这种情况下，LB 会保留现有连接的数量和映射状态。我们将在本课后面详细讨论状态维护。 Least response time：在性能敏感的服务中，需要用到least response time等算法。该算法确保请求响应时间最少的服务器为客户端提供服务。 IP 哈希：一些应用程序根据用户的 IP 地址向用户提供不同级别的服务。在这种情况下，对 IP 地址进行哈希处理以将用户的请求分配给服务器。 URL 哈希：应用程序中的某些服务可能仅由特定服务器提供。在这种情况下，从 URL 请求服务的客户端被分配到某个集群或一组服务器。URL 哈希算法用于这些场景。 还有其他算法，如随机或加权最小连接算法。 静态与动态算法 算法可以是静态的或动态的，具体取决于机器的状态。让我们分别看看每个类别： 静态算法不考虑服务器的变化状态。因此，任务分配是根据有关服务器配置的现有知识进行的。当然，这些算法并不复杂，它们在所有请求到达的单个路由器或商用机器中实现。 动态算法是考虑服务器当前或最近状态的算法。动态算法通过与服务器通信来维护状态，这增加了通信开销。状态维护使得算法的设计变得更加复杂。 动态算法需要不同的负载平衡服务器相互通信以交换信息。因此，动态算法可以是模块化的，因为没有一个实体会做决策。虽然这增加了动态算法的复杂性，但它会改进转发决策。最后，动态算法监控服务器的健康状况并仅将请求转发到活动服务器。 注意：在实践中，动态算法提供更好的结果，因为它们维护服务主机的状态，因此值得付出努力和复杂性。 有状态与无状态 LB 虽然需要静态和动态算法来考虑托管服务器的健康状况，但会维护一个状态以保存不同客户端与托管服务器的会话信息。 如果会话信息未保存在较低层（分布式缓存或数据库），则使用负载平衡器来保存会话信息。下面，我们将介绍两种通过 LB 处理会话维护的方式： 有状态的 无国籍 有状态负载均衡 顾名思义，有状态负载平衡涉及维护客户端和托管服务器之间建立的会话的状态。有状态 LB 将状态信息合并到其算法中以执行负载平衡。 本质上，有状态 LB 保留了一个将传入客户端映射到托管服务器的数据结构。有状态 LB 增加了复杂性并限制了可扩展性，因为所有客户端的会话信息都在所有负载均衡器中维护。也就是说，负载均衡器彼此共享它们的状态信息以做出转发决策。 无状态负载均衡 无状态负载平衡不维护任何状态，因此更快、更轻量级。无状态 LB 使用一致性哈希来做出转发决策。但是，如果基础架构发生变化（例如，新的应用程序服务器加入），无状态 LB 的弹性可能不如有状态 LB，因为单独的一致性哈希不足以将请求路由到正确的应用程序服务器。因此，可能仍然需要本地状态以及一致的散列。 因此，跨不同负载均衡器维护的状态被视为有状态负载均衡。然而，在负载均衡器中维护供内部使用的状态被假定为无状态负载均衡。 负载均衡器的类型 根据要求，可以在开放系统互连 (OSI) 层的网络/传输和应用层执行负载平衡。 第 4 层负载均衡器：第 4 层是指在 TCP 和 UDP 等传输协议的基础上执行的负载均衡。这些类型的 LB 维护与客户端的连接/会话，并确保相同的 (TCP/UDP) 通信最终被转发到相同的后端服务器。尽管 TLS 终止是在第 7 层 LB 执行的，但某些第 4 层 LB 也支持它。 第 7 层负载均衡器：第 7 层负载均衡器基于应用层协议的数据。可以根据 HTTP 标头、URL、cookie 和其他特定于应用程序的数据（例如，用户 ID）做出应用程序感知的转发决策。除了执行 TLS 终止外，这些 LB 还可以承担限速用户、HTTP 路由和标头重写等职责。 注意：第 7 层负载均衡器在检查方面很智能。然而，第 4 层负载均衡器在处理方面更快。 负载均衡器部署 我们讨论了在不同 OSI 层执行负载平衡的权衡。然而，在实践中，单层 LB 不足以满足大型数据中心的需求。事实上，多层负载平衡器协调以做出明智的转发决策。传统的数据中心可能有一个三层的负载均衡器，如下图： Tier-0 和 Tier-1 LB 如果可以将 DNS 视为第 0 层负载均衡器，则等价多路径 (ECMP) 路由器就是第 1 层 LB。从 ECMP 的名称可以看出，这一层根据 IP 或其他算法（如循环或加权循环）划分传入流量。Tier-1 LB 将跨不同路径平衡负载到更高层的负载均衡器。 ECMP 路由器在更高层 LB 的水平可扩展性中起着至关重要的作用。 Tier-2 LB 第二层 LB 包括第 4 层负载均衡器。第 2 层 LB 确保对于任何连接，所有传入数据包都转发到相同的第 3 层 LB。为实现此目标，可以使用一致性哈希等技术。但如果基础设施发生任何变化，一致性哈希可能还不够。因此，我们将在本课的后续部分中看到，我们必须维护本地或全局状态。 Tier-2 负载均衡器可以被视为 tier-1 和 tier-3 LB 之间的粘合剂。排除第 2 层 LB 可能会在 LB 发生故障或动态扩展时导致错误的转发决策。 Tier-3 LB 第 7 层 LB 在第 3 层提供服务。由于这些 LB 与后端服务器直接接触，因此它们在 HTTP 级别执行服务器的健康监控。该层通过在一组健康的后端服务器之间平均分配请求来实现可扩展性，并通过直接监控服务器的健康状况来提供高可用性。该层还通过处理TCP 拥塞控制协议、路径 MTU（最大传输单元）的发现等低级细节来减轻终端服务器的负担，客户端和后端服务器之间应用协议的差异等等。这个想法是将计算和数据服务留给应用程序服务器，并有效地利用负载平衡商用机器来完成琐碎的任务。在某些情况下，第 7 层 LB 与服务主机处于同一级别。 总而言之，第 1 层在负载平衡器本身之间平衡负载。第 2 层支持在发生故障时从第 1 层平滑过渡到第 3 层，而第 3 层在后端服务器之间进行实际负载平衡。每层执行其他任务以减轻终端服务器的负担。 实际例子 让我们看一个示例，其中来自客户端的请求根据客户端网络数据包中的应用程序数据进入并转发到不同的应用程序服务器。 请求 R1 被路由到幻灯片服务器 1的2 让我们按照以下步骤查看上图： �1个R1个的指示请求 1 来自 ECMP 路由器之一（第 1 层 LB）。 ECMP 路由器转发�1个R1个的使用循环算法分配给三个可用的第 2 层 LB 中的任何一个。第 2 层 LB 对源 IP 地址进行哈希处理（我��I P**C的) 并将数据包转发到下一层 LB。 第 3 层在收到数据包后，卸载 TLS 并读取 HTTP(S) 数据。通过观察请求的 URL，它将请求转发到处理 slides. �2个R2个的采用相同的路径但不同的终端服务器，因为请求的 URL 包含document而不是slides. Tier-3 LB 预先配置为根据应用程序数据将请求转发到应用程序服务器。例如，典型的HAProxy服务器在第 3 层 LB 中可以具有以下配置： 1个 2个 3个 4个 5个 mode HTTP //定义LB 将工作的模式，TCP 用于第 2 层 LB acl slidesApp path_end -i /presentation //如果路径以/pre sentation结尾则定义一个应用类别 use_backend slidesServers if slidesApp //如果slidesApp的请求到达，则使用一组后端服务器 后端 slidesServers // 列出 服务 slidesApp 的服务器 server slides1 192.168.12.1:80 //使用 slides1服务器为 slidesApp 提供服务。 第 7 层负载均衡器的 HAProxy 示例配置 测验 问题一 请求到达后端服务器后，响应是否应该通过负载均衡器的每一层路由回来？ 隐藏答案 不，服务器可以通过 tier-3 LB 将响应直接发送到路由器（tier-1 LB），路由器可以转发来自数据中心的响应。这种响应称为直接路由( DR ) 或直接服务器返回( DSR )。 1的4 负载均衡器的实现 根据传入请求的数量、组织和特定于应用程序的要求，可以实施不同类型的负载均衡器： 硬件负载均衡器 负载均衡器是在 1990 年代作为硬件设备引入的。硬件负载平衡器作为独立设备工作并且非常昂贵。尽管如此，它们具有性能优势并且能够处理大量并发用户。基于硬件的解决方案的配置存在问题，因为它需要额外的人力资源。因此，即使对于能够负担得起的大型企业来说，它们也不是首选解决方案。可用性可能是硬件负载平衡器的一个问题，因为在发生故障时需要额外的硬件来进行故障转移。最后，硬件 LB 可能具有更高的维护/运营成本和兼容性问题，从而降低它们的灵活性。更不用说硬件 LB 也有供应商锁。 软件负载平衡器 软件负载平衡器因其灵活性、可编程性和成本效益而变得越来越流行。这一切都是可能的，因为它们是在商用硬件上实现的。软件负载均衡随着需求的增长而扩展。可用性不会成为软件 LB 的问题，因为在商品硬件上实施影子负载均衡器需要少量的额外成本。此外，软件 LB 可以提供预测分析，帮助为未来的流量模式做好准备。 云负载均衡器 随着云计算领域的出现，负载均衡器即服务（LBaaS）被引入。这是云所有者提供负载平衡服务的地方。用户根据他们的使用情况或与云提供商的服务级别协议 (SLA) 付费。基于云的 LB 不一定会取代本地的本地负载平衡设施，但它们可以在不同区域之间执行全局流量管理。此类负载平衡器的主要优势包括易于使用、管理、计量成本、使用方面的灵活性、审计和监控服务以改进业务决策。下面给出了基于云的 LB 如何提供 GSLB 的示例： 注意：另一个有趣的负载均衡器实现是客户端负载均衡。客户端负载均衡适用于有大量服务的情况，每个服务都有很多实例（例如Twitter 中的负载均衡）。然而，我们的重点是传统的负载均衡器，因为大多数三层应用程序在其设计中都采用了这些。 结论 从以硬件形式出现以来，LB 已经走过了漫长的道路，成为云中提供的服务。它们是任何企业级服务的关键组成部分。托管服务器的横向可扩展性始终需要一个能够提供负载平衡、会话维护、TLS 卸载、服务发现等功能的良好负载平衡层。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-21 "},"数据库/数据库.html":{"url":"数据库/数据库.html","title":"数据库","keywords":"","body":"数据库 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"数据库/数据库简介.html":{"url":"数据库/数据库简介.html","title":"数据库简介","keywords":"","body":"数据库简介 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"数据库/数据库类型.html":{"url":"数据库/数据库类型.html","title":"数据库类型","keywords":"","body":"数据库类型 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"数据库/数据复制.html":{"url":"数据库/数据复制.html","title":"数据复制","keywords":"","body":"数据复制 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"数据库/数据分区.html":{"url":"数据库/数据分区.html","title":"数据分区","keywords":"","body":"数据分区 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"数据库/数据库权衡.html":{"url":"数据库/数据库权衡.html","title":"数据库权衡","keywords":"","body":"数据库权衡 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"键值存储/键值存储.html":{"url":"键值存储/键值存储.html","title":"键值存储","keywords":"","body":"键值存储 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"键值存储/系统设计 键值存储.html":{"url":"键值存储/系统设计 键值存储.html","title":"系统设计:键值存储","keywords":"","body":"系统设计:键值存储 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"键值存储/键值存储设计.html":{"url":"键值存储/键值存储设计.html","title":"键值存储设计","keywords":"","body":"键值存储设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"键值存储/确保可扩展性和复制性.html":{"url":"键值存储/确保可扩展性和复制性.html","title":"确保可扩展性和复制性","keywords":"","body":"确保可扩展性和复制性 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"键值存储/版本控制数据和实现可配置性.html":{"url":"键值存储/版本控制数据和实现可配置性.html","title":"版本控制数据和实现可配置性","keywords":"","body":"版本控制数据和实现可配置性 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"键值存储/启用容错和故障检测.html":{"url":"键值存储/启用容错和故障检测.html","title":"启用容错和故障检测","keywords":"","body":"启用容错和故障检测 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"内容分发网络/内容分发网络.html":{"url":"内容分发网络/内容分发网络.html","title":"内容分发网络(CDN)","keywords":"","body":"内容分发网络(CDN) Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"内容分发网络/系统设计 内容分发网络.html":{"url":"内容分发网络/系统设计 内容分发网络.html","title":"系统设计:内容分发网络(CDN)","keywords":"","body":"系统设计:内容分发网络(CDN) Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"内容分发网络/CDN简介.html":{"url":"内容分发网络/CDN简介.html","title":"CDN简介","keywords":"","body":"CDN简介 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"内容分发网络/CDN的设计.html":{"url":"内容分发网络/CDN的设计.html","title":"CDN的设计","keywords":"","body":"CDN的设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"内容分发网络/CDN深入调查 第1部分.html":{"url":"内容分发网络/CDN深入调查 第1部分.html","title":"CDN深入调查: 第1部分","keywords":"","body":"CDN深入调查: 第1部分 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"内容分发网络/CDN深入调查 第2部分.html":{"url":"内容分发网络/CDN深入调查 第2部分.html","title":"CDN深入调查: 第2部分","keywords":"","body":"CDN深入调查: 第2部分 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"内容分发网络/CDN设计评估.html":{"url":"内容分发网络/CDN设计评估.html","title":"CDN设计评估","keywords":"","body":"CDN设计评估 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"内容分发网络/CDN设计测验.html":{"url":"内容分发网络/CDN设计测验.html","title":"CDN设计测验","keywords":"","body":"CDN设计测验 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"定序器/定序器.html":{"url":"定序器/定序器.html","title":"序列生成器","keywords":"","body":"序列生成器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"定序器/系统设计 序列生成器.html":{"url":"定序器/系统设计 序列生成器.html","title":"系统设计:序列生成器","keywords":"","body":"系统设计:序列生成器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"定序器/唯一ID生成器设计.html":{"url":"定序器/唯一ID生成器设计.html","title":"唯一ID生成器设计","keywords":"","body":"唯一ID生成器设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"序列生成器/具有因果关系的唯一ID.html":{"url":"序列生成器/具有因果关系的唯一ID.html","title":"具有因果关系的唯一ID","keywords":"","body":"具有因果关系的唯一ID Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式监控/分布式监控.html":{"url":"分布式监控/分布式监控.html","title":"分布式监控","keywords":"","body":"分布式监控 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式监控/系统设计 分布式监控.html":{"url":"分布式监控/系统设计 分布式监控.html","title":"系统设计:分布式监控","keywords":"","body":"系统设计:分布式监控 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式监控/分布式监控简介.html":{"url":"分布式监控/分布式监控简介.html","title":"分布式监控简介","keywords":"","body":"分布式监控简介 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式监控/监控系统的先决条件.html":{"url":"分布式监控/监控系统的先决条件.html","title":"监控系统的先决条件","keywords":"","body":"监控系统的先决条件 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"监控系统/监控系统服务端错误.html":{"url":"监控系统/监控系统服务端错误.html","title":"监控系统: 服务端错误","keywords":"","body":"监控系统: 服务端错误 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"监控系统/监控系统设计.html":{"url":"监控系统/监控系统设计.html","title":"监控系统设计","keywords":"","body":"监控系统设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"监控系统/监控系统详细设计.html":{"url":"监控系统/监控系统详细设计.html","title":"监控系统详细设计","keywords":"","body":"监控系统详细设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"监控系统/可视化监控系统.html":{"url":"监控系统/可视化监控系统.html","title":"可视化监控系统","keywords":"","body":"可视化监控系统 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"监控系统/监控系统客户端错误.html":{"url":"监控系统/监控系统客户端错误.html","title":"监控系统:客户端错误","keywords":"","body":"监控系统:客户端错误 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"监控系统/关注监控系统中客户端错误.html":{"url":"监控系统/关注监控系统中客户端错误.html","title":"关注监控系统中的客户端错误","keywords":"","body":"关注监控系统中的客户端错误 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"监控系统/客户端监控系统设计.html":{"url":"监控系统/客户端监控系统设计.html","title":"客户端监控系统设计","keywords":"","body":"客户端监控系统设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式缓存/分布式缓存.html":{"url":"分布式缓存/分布式缓存.html","title":"分布式缓存","keywords":"","body":"分布式缓存 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式缓存/系统设计 分布式缓存.html":{"url":"分布式缓存/系统设计 分布式缓存.html","title":"系统设计:分布式缓存","keywords":"","body":"系统设计：分布式缓存 了解分布式缓存的基础知识。 问题陈述 一个典型的系统由以下组件组成： 它有一个请求服务的客户端。 它有一个或多个服务主机来处理客户请求。 它有一个数据库，供服务用于数据存储。 在正常情况下，这种抽象表现良好。但是，随着用户数量的增加，数据库查询也会增加。结果，服务提供商负担过重，导致性能下降。 在这种情况下，系统会添加缓存以应对性能下降。缓存是一种临时数据存储，可以通过将数据条目保存在内存中来更快地提供数据。缓存只存储最常访问的数据。当请求到达服务主机时，它会从缓存中检索数据（缓存命中）并为用户提供服务。但是，如果数据在缓存中不可用（缓存未命中），则会从数据库中查询数据。此外，缓存会填充新值以避免下次缓存未命中。 缓存是一种非持久性存储区域，用于保存重复读写的数据，为最终用户提供更低的延迟。因此，缓存必须提供来自存储组件的数据，该存储组件速度快、存储空间充足，并且在我们扩展缓存服务时在美元成本方面可以负担得起。下图突出显示了 RAM 作为缓存的原始构建块的适用性： 我们知道需要缓存和合适的存储硬件，但什么是分布式缓存？我们接下来讨论这个。 什么是分布式缓存？ 分布式缓存是一种缓存系统，其中多个缓存服务器协调存储频繁访问的数据。在单个缓存服务器不足以存储所有数据的环境中需要分布式缓存。同时，它具有可扩展性并保证了更高程度的可用性。 缓存通常很小，访问频繁，读取时间快的短期存储。缓存使用 局部引用原则。 一般来说，分布式缓存有以下几个好处： 它们通过预先计算结果和存储经常访问的数据来最大限度地减少用户感知的延迟。 他们从数据库中预先生成昂贵的查询。 它们临时存储用户会话数据。 即使数据存储暂时关闭，它们也会从临时存储中提供数据。 最后，它们通过从本地资源提供数据来降低网络成本。 为什么要分布式缓存？ 当缓存中所需数据的大小增加时，将整个数据存储在一个系统中是不切实际的。这是因为以下三个原因： 它可能是潜在的单点故障 (SPOF)。 系统是分层设计的，每一层都应该有自己的缓存机制，保证不同层敏感数据的解耦。 在不同位置缓存有助于减少该层的服务延迟。 在下表中，我们描述了如何通过使用各种技术来执行不同层的缓存。重要的是要注意键值存储组件在各个层中使用。 在系统的不同层缓存 系统层 使用中的技术 用法 网络 HTTP 缓存标头、Web 加速器、键值存储、CDN 等 加速静态 Web 内容的检索并管理会话 应用 本地缓存和键值数据存储 加速应用级计算和数据检索 数据库 数据库缓存、缓冲区和键值数据存储 减少数据检索延迟和数据库的 I/O 负载 除了上述三个系统层之外，缓存还在 DNS 和客户端技术（如浏览器或终端设备）中执行。 我们将如何设计分布式缓存？ 我们将设计和强化学习分布式缓存主要概念的任务分为五个课程： 分布式缓存的背景：在设计分布式缓存时，必须构建做出关键决策所需的背景知识。本课将重温一些基本但重要的概念。 分布式缓存的高级设计：我们将在本课中构建分布式缓存的高级设计。 分布式缓存的详细设计：我们将确定我们的高级设计的一些局限性，并致力于实现可扩展、价格合理且高性能的解决方案。 分布式缓存设计的评估：本课将评估我们的设计是否满足各种非功能性需求，例如可伸缩性、一致性、可用性等。 Memcached 与 Redis：我们将讨论著名的工业解决方案，即 Memcached 和 Redis。我们还将详细了解它们并比较它们的功能，以帮助我们了解它们的潜在用例以及它们与我们的设计的关系。 让我们在下一课开始探索分布式缓存的背景。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式缓存/分布式缓存的背景.html":{"url":"分布式缓存/分布式缓存的背景.html","title":"分布式缓存的背景","keywords":"","body":"分布式缓存的背景 了解设计分布式缓存的基础知识。 本章的主要目标是设计分布式缓存。为了实现这个目标，我们应该有丰富的背景知识，主要是不同的阅读和写作技巧。本课将帮助我们建立这些背景知识。让我们看看下表中本课的结构 本课结构 部分 动机 编写策略 数据写入缓存和数据库。数据写入发生的顺序对性能有影响。我们将讨论各种写入策略，以帮助确定哪种写入策略适合我们要设计的分布式缓存。 驱逐政策 由于缓存是建立在有限的存储空间 (RAM) 上的，因此理想情况下我们希望将最常访问的数据保留在缓存中。因此，我们将讨论不同的逐出策略，以用最常访问的数据替换不常访问的数据。 缓存失效 某些缓存数据可能会过时。在本节中，我们将讨论不同的失效方法，以从缓存中删除陈旧或过时的条目。 存储机制 分布式存储有很多服务器。我们将讨论重要的设计注意事项，例如哪个缓存条目应存储在哪个服务器中以及使用哪种数据结构进行存储。 缓存客户端 缓存服务器存储缓存条目，但缓存客户端调用缓存服务器请求数据。我们将在本节中讨论缓存客户端库的详细信息。 编写策略 通常，缓存存储数据的副本（或部分），该副本持久存储在数据存储中。当我们将数据存储到数据存储时，会出现一些重要的问题： 我们首先将数据存储在哪里？数据库还是缓存？ 每种策略对一致性模型的影响是什么？ 简短的回答是，这取决于应用要求。让我们看一下不同写入策略的细节，以更好地理解这个概念： 直写缓存：直写机制在缓存和数据库上写入。在两个存储上写入可以同时发生，也可以一个接一个地发生。这增加了写入延迟，但确保了数据库和缓存之间的强一致性。 Write-back cache：在write-back cache机制中，数据先写入缓存，再异步写入数据库。虽然缓存中有更新的数据，但在客户端从数据库中读取陈旧数据的场景下，不一致是不可避免的。但是，使用这种策略的系统会有很小的写入延迟。 Write-around cache：这种策略只涉及将数据写入数据库。稍后，当触发对数据的读取时，它会在缓存未命中后写入缓存。数据库会有更新的数据，但这样的策略不利于读取最近更新的数据。 # 测验 # 第一题 系统想要写入数据并立即将其读回。同时，我们希望缓存和数据库保持一致。哪种写入策略是最佳选择？ a) 直写缓存 b) 绕写高速缓存 c)回写缓存 # 第二题 关于性能，写入密集型系统应该避免什么？ a) 回写缓存 b) 直写缓存 c) 绕写告诉缓存 # 第三题 过时或陈旧的数据输入是哪个编写策略中的典型问题？ a) 直写式 b) 回写 c) 绕写 驱逐政策 高速缓存执行速度快的主要原因之一是它们很小。小缓存意味着存储容量有限。因此，我们需要一种逐出机制，将访问频率较低的数据从缓存中移除。 几种众所周知的策略用于从缓存中逐出数据。最著名的策略包括： 最近最少使用（LRU） 最近使用 (MRU) 最不常用 (LFU) 最常用 (MFU) 其他策略如先进先出 (FIFO) 也存在。这些算法中的每一个的选择取决于缓存被开发的系统。 数据温度 根据访问频率，数据可以分为三个温度区域： 热：这是高度访问的数据。 暖：这是访问频率较低的数据。 冷：这是很少访问的数据。 冷数据经常从缓存中被逐出，并被热数据或温数据取代。下图显示了数据温度的频谱： 缓存失效 除了逐出不常访问的数据外，缓存中的一些数据可能会随着时间的推移变得陈旧或过时。此类缓存条目无效，必须标记为删除。 这种情况需要一个问题：我们如何识别过时的条目？ 解决该问题需要存储与每个缓存条目对应的元数据。具体来说，维护一个生存时间 (TTL)值来处理过时的缓存项。 我们可以使用两种不同的方法来处理使用 TTL 的过期项目： 主动过期：此方法通过守护进程或线程主动检查缓存条目的 TTL。 被动过期：此方法在访问时检查缓存条目的 TTL。 每个过期的项目在发现后都会从缓存中删除。 存储机制 在缓存中存储数据并不像看起来那么简单，因为分布式缓存有多个缓存服务器。当我们使用多个缓存服务器时，需要回答以下设计问题： 我们应该将哪些数据存储在哪些缓存服务器中？ 我们应该使用什么数据结构来存储数据？ 以上两个问题是重要的设计问题，因为它们将决定我们分布式缓存的性能，这是我们最重要的需求。我们将使用以下技术来回答上述问题。 哈希函数 可以在两种不同的情况下使用散列： 识别分布式缓存中的缓存服务器以存储和检索数据。 在每个缓存服务器中找到缓存条目。 对于第一种情况，我们可以使用不同的哈希算法。然而，一致性哈希或其风格通常在分布式系统中表现良好，因为简单的哈希在崩溃或扩展的情况下并不是理想的。 在第二种情况下，我们可以使用典型的哈希函数来定位缓存条目以在缓存服务器内部进行读取或写入。然而，单独的散列函数只能定位缓存条目。它没有说明在缓存服务器中管理数据的任何内容。也就是说，它没有说明如何实施策略以从缓存服务器中逐出不常访问的数据。它也没有说明缓存服务器中使用什么数据结构来存储数据。这正是存储机制的第二个设计问题。接下来我们看一下数据结构。 链表 我们将使用双向链表。主要原因是它的广泛使用和简单性。此外，在我们的例子中，在双向链表中添加和删除数据将是一个常量时间操作。这是因为我们要么从链表的尾部逐出一个特定的条目，要么将一个条目重新定位到双向链表的头部。因此，不需要迭代。 注意： 布隆过滤器是一个有趣的选择，用于快速查找缓存服务器中是否不存在缓存条目。我们可以使用布隆过滤器来确定某个缓存条目肯定不存在于缓存服务器中，但它存在的可能性是概率性的。布隆过滤器在大型缓存或数据库系统中非常有用。 缓存集群中的分片 为了避免 SPOF 和单个缓存实例的高负载，我们引入了分片。分片涉及在多个缓存服务器之间拆分缓存数据。可以通过以下两种方式进行。 专用缓存服务器 在专用缓存服务器方法中，我们将应用程序和 Web 服务器与缓存服务器分开。 使用专用缓存服务器的优点如下： 每个功能的硬件选择都非常灵活。 可以分别扩展 Web/应用程序服务器和缓存服务器。 除了上述优势之外，作为独立的缓存服务工作还可以让其他微服务从中受益——例如，缓存即服务。在这种情况下，缓存系统必须了解不同的应用程序，以免它们的数据发生冲突。 并置缓存 并置缓存将缓存和服务功能嵌入到同一主机中。 该策略的主要优点是减少了 额外硬件的资本支出和运营支出。此外，随着一个服务的缩放，获得了另一个服务的自动缩放。但是，一台机器出现故障会导致两种服务同时丢失。 缓存客户端 我们讨论了散列函数应用于缓存服务器的选择。但是什么实体执行这些哈希计算？ 缓存客户端是驻留在托管服务器中的一段代码，这些代码执行（散列）计算以在缓存服务器中存储和检索数据。此外，缓存客户端可以与其他系统组件（如监控和配置服务）协调。所有缓存客户端都以相同的方式编程，以便来自不同客户端的相同PUT和GET操作返回相同的结果。缓存客户端的一些特征如下： 每个缓存客户端都知道所有的缓存服务器。 所有客户端都可以使用众所周知的传输协议（如 TCP 或 UDP）与缓存服务器通信。 指向思考 问题 如果其中一个缓存服务器死了，缓存客户端对访问请求的行为是什么？ 隐藏答案 由于缓存服务器中的数据将不再可用，缓存客户端会将访问请求标记为缓存未命中。 结论 在本课中，我们了解了分布式缓存是什么，并强调了它们在分布式系统中的重要性。我们还讨论了缓存的不同存储和驱逐机制。缓存对于任何分布式系统都至关重要，并且位于系统设计中的不同位置。了解如何将分布式缓存设计为大型系统的一部分非常重要。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式缓存/分布式缓存的高级设计.html":{"url":"分布式缓存/分布式缓存的高级设计.html","title":"分布式缓存的高级设计","keywords":"","body":"分布式缓存的高级设计 了解我们如何开发分布式缓存的高级设计。 在本课中，我们将学习设计分布式缓存。我们还将讨论在开发解决方案的过程中可能发生的权衡和设计选择。 要求 让我们首先了解我们的解决方案的要求。 功能 以下是功能要求： 插入数据：分布式缓存系统的用户必须能够向缓存中插入一个条目。 检索数据：用户应该能够检索与特定键对应的数据。 非功能性需求 我们将考虑以下非功能性需求： 高性能：缓存的主要原因是能够快速检索数据。因此，insert和retrieve操作都必须很快。 可扩展性：缓存系统应该水平扩展，在请求数量增加时不会出现瓶颈。 高可用性：缓存的不可用性会给数据库服务器带来额外的负担，它也可能在高峰负载间隔下降。我们还要求我们的系统能够承受组件和网络偶尔出现的故障以及断电。 一致性：存储在缓存服务器上的数据应该是一致的。例如，从不同缓存服务器（主要或次要）检索相同数据的不同缓存客户端应该是最新的。 可承受性：理想情况下，缓存系统应该从商品硬件而不是系统设计中昂贵的支持组件来设计。 API设计 这个问题的 API 设计非常简单，因为只有两个基本操作。 插入 执行插入的 API 调用应如下所示： insert(key, value) 范围 描述 key 这是一个唯一标识符。 value 这是针对唯一存储的数据key。 此函数返回描述服务器端问题的确认或错误。 检索 从缓存中检索数据的 API 调用应如下所示： retrieve(key) 范围 描述 key 这将返回针对key. 这个调用返回一个对象给调用者。 指向思考 问题 分布式缓存的 API 设计看起来与键值存储非常相似。键值存储和分布式缓存之间可能存在哪些区别？ 一些主要区别如下： 键值存储需要持久存储数据（持久性）。除了持久存储之外，还使用缓存来提高读取性能。 缓存提供来自 RAM 的数据。键值存储将数据写入非易失性存储。 键值存储是健壮的，应该能经受住失败。但是，缓存可能会崩溃并在恢复后从头开始填充。 设计注意事项 在设计分布式缓存系统之前，考虑一些设计选择很重要。这些选择中的每一个都将完全基于我们的应用程序要求。但是，我们可以在这里强调一些关键差异： 存储硬件 如果我们的数据很大，我们可能需要分片，因此使用分片服务器进行缓存分区。这些分片服务器应该是专用硬件还是商用硬件？专用硬件将具有良好的性能和存储容量，但成本更高。我们可以从商用服务器构建一个大型缓存。一般来说，分片服务器的数量取决于缓存的大小和访问频率。 此外，我们可以考虑将我们的数据存储在这些服务器的辅助存储上以实现持久性，同时我们仍然从 RAM 提供数据。二级存储可用于重启，缓存重建时间较长的情况。但是，如果存在专用的持久层（例如数据库），则缓存系统可能不需要持久性。 数据结构 设计的一个重要部分必须是访问数据的速度。哈希表是平均需要固定时间来存储和检索数据的数据结构。此外，我们需要另一种数据结构来对缓存数据执行逐出算法。特别是，链表是一个不错的选择（如上一课所述）。 另外，我们需要了解缓存可以存储什么样的数据结构。尽管我们在 API 设计部分讨论过为简单起见我们将使用字符串，但可以在缓存中存储不同的数据结构或格式，如哈希映射、数组、集合等。在下一课中，我们将看到此类缓存的实际示例。 缓存客户端 它是放置insert和retrieve调用的客户端进程或库。客户端进程的位置是一个设计问题。例如，如果缓存仅供内部使用，则可以将客户端进程放在服务主机中。否则，在缓存系统作为服务提供给外部使用的情况下，专用的缓存客户端可以将用户的请求发送到缓存服务器。 编写策略 缓存和数据库的写入策略具有一致性影响。一般来说，没有最佳选择，但根据我们的应用程序，写入策略的偏好非常重要。 驱逐政策 按照设计，缓存提供低延迟读取和写入。为实现这一点，数据通常由 RAM 内存提供。通常，由于与完整数据集相比缓存的大小有限，我们不能将所有数据都放入缓存中。因此，我们需要仔细决定缓存中保留的内容以及如何为新条目腾出空间。 随着新数据的添加，一些现有数据可能必须从缓存中逐出。但是，选择受害者条目取决于逐出策略。存在许多驱逐策略，但选择又取决于使用它的应用程序。例如，最近最少使用 (LRU) 可能是社交媒体服务的不错选择，因为最近上传的内容可能会获得最多的浏览量。 除了上述部分的详细信息外，优化生存时间 (TTL) 值可以在减少缓存未命中数方面发挥重要作用。 高层设计 下图描述了我们的高级设计： 此高级设计中的主要组件如下： 缓存客户端：该库驻留在服务应用程序服务器中。它包含有关缓存服务器的所有信息。insert缓存客户端将为每个传入和请求使用散列和搜索算法选择其中一个缓存服务器retrieve。所有缓存客户端都应该具有所有缓存服务器的一致视图。此外，将数据移入和移出缓存服务器的解析技术应该相同。否则，不同的客户端会向不同的服务器请求相同的数据。 缓存服务器：这些服务器维护数据的缓存。每个缓存服务器都可以被所有缓存客户端访问。每个服务器都连接到数据库以存储或检索数据。缓存客户端使用 TCP 或 UDP 协议与缓存服务器进行数据传输。但是，如果任何缓存服务器关闭，对这些服务器的请求将被缓存客户端解析为丢失的缓存。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式缓存/分布式缓存的详细设计.html":{"url":"分布式缓存/分布式缓存的详细设计.html","title":"分布式缓存的详细设计","keywords":"","body":"分布式缓存的详细设计 让我们了解分布式缓存的详细设计。 本课将找出分布式缓存高级设计的一些缺点，并改进设计以弥补这些不足。让我们开始吧。 查找并删除限制 在开始详细设计之前，我们需要了解并克服一些挑战： 缓存客户端无法感知缓存服务器的添加或失效。 该解决方案会遇到单点故障 (SPOF) 问题，因为我们为每组缓存数据设置了一个缓存服务器。不仅如此，如果任何一个缓存服务器上的某些数据被频繁访问（一般称为热键问题），那么我们的性能也会变慢。 我们的解决方案也没有突出缓存服务器的内部结构。也就是说，它会使用什么样的数据结构来存储，它会使用什么样的驱逐策略？ 维护缓存服务器列表 让我们从解决第一个问题开始。我们将采取渐进的步骤来寻求最佳解决方案。让我们看看下面的幻灯片，以了解下面描述的每个解决方案： 方案一: 在每个服务器维护一个缓存客户端可以使用的配置文件 方案二: 在集中位置维护配置文件 方案三: 使用配置服务监视缓存服务器并保持缓存客户端更新 解决方案 1：可以在缓存客户端所在的每个服务主机中都有一个配置文件。配置文件将包含缓存客户端有效利用缓存服务器所需的更新后的运行状况和元数据。配置服务的每个副本都可以通过任何 DevOps 工具的推送服务进行更新。这种策略的主要问题是配置文件必须通过一些 DevOps 工具手动更新和部署。 解决方案 2：我们可以将配置文件存储在一个集中位置，缓存客户端可以使用该位置来获取有关缓存服务器的更新信息。这解决了部署问题，但我们仍然需要手动更新配置文件并监控每个服务器的健康状况。 解决方案 3：一种自动处理该问题的方法是使用持续监控缓存服务器健康状况的配置服务。除此之外，当一个新的缓存服务器被添加到集群时，缓存客户端将得到通知。当我们使用这种策略时，如果出现故障或添加新节点，则不需要人为干预或监控。最后，缓存客户端从配置服务中获取缓存服务器列表。 配置服务的运营成本最高。同时，这是一个复杂的解决方案。但是，它是我们提供的所有解决方案中最强大的。 提高可用性 第二个问题与缓存服务器出现故障时缓存不可用有关。一个简单的解决方案是添加副本节点。我们可以从在缓存分片中添加一个主节点和两个备份节点开始。对于副本，总是存在不一致的可能性。如果我们的副本非常接近，则同步执行写入副本以避免分片副本之间的不一致。在分片之间划分缓存数据至关重要，这样既不会出现不可用问题，也不会浪费任何硬件。 该解决方案有两个主要优点： 在发生故障时提高了可用性。 热分片可以有多个节点（主要-次要）用于读取。 这样的解决方案不仅会提高可用性，还会增加性能。 缓存服务器的内部结构 每个缓存客户端应该使用三种机制来存储和从缓存服务器中逐出条目： 哈希映射：缓存服务器使用哈希映射来存储或定位缓存服务器 RAM 中的不同条目。下图显示映射包含指向每个缓存值的指针。 双向链表：如果我们必须从缓存中逐出数据，我们需要一个链表，以便我们可以根据访问频率对条目进行排序。下图描述了如何使用双向链表连接条目。 驱逐政策：驱逐政策取决于应用程序要求。在这里，我们假设最近最少使用 (LRU) 驱逐策略。 下面提供了分片集群以及节点数据结构的描述： 从上面的解释中可以明显看出我们不提供deleteAPI。这是因为驱逐（通过驱逐算法）和删除（通过 TTL 的过期条目）是在缓存服务器本地完成的。delete然而，可能会出现需要 API 的情况。例如，当我们从数据库中删除一个最近添加的条目时，为了一致性，它应该导致从缓存中删除项目。 详细设计 在解决了之前突出显示的三个问题中的每一个之后，我们现在准备好正式确定详细设计。看下面的详细设计： 让我们将建议的详细设计总结为几点： 客户端的请求通过缓存客户端所在的负载均衡器到达服务主机。 每个缓存客户端使用一致的哈希来标识缓存服务器。接下来，缓存客户端将请求转发给维护特定分片的缓存服务器。 每个缓存服务器都有主服务器和副本服务器。在内部，每个服务器都使用相同的机制来存储和清除缓存条目。 配置服务确保所有客户端看到缓存服务器的更新且一致的视图。 监控服务还可用于记录和报告缓存服务的不同指标。 注意：设计的一个重要方面是缓存条目是从 RAM 中存储和检索的。在上一课中，我们讨论了 RAM 是否适合设计缓存系统。 指向思考 问题 虽然一致性哈希是一个不错的选择，但它可能会导致数据分布不均，并且某些服务器可能会过载。我们如何解决这个问题？ 隐藏答案 随着时间的推移，已经提出了许多一致的散列算法风格。我们可以使用一种这样的风格（在这里使用）来均匀分布负载，甚至在不同的缓存服务器上制作相同数据的多个副本。每个缓存服务器内部都可以有虚拟服务器，一台机器中虚拟服务器的数量取决于机器的能力。这样可以更好地控制缓存服务器上的负载量。同时，它提高了可用性。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式缓存/分布式缓存设计的评估.html":{"url":"分布式缓存/分布式缓存设计的评估.html","title":"分布式缓存设计的评估","keywords":"","body":"分布式缓存设计的评估 让我们根据我们的要求评估我们的设计。 让我们根据设计要求评估我们提出的设计。 高性能 以下是我们做出的一些有助于提高整体性能的设计选择： 我们使用了一致性哈希。在该算法下查找key需要时间复杂度为O(log(N))，其中N代表缓存分片的个数。 在缓存服务器内部，使用平均需要恒定时间的哈希表来定位键。 LRU 逐出方法使用恒定时间访问和更新双向链表中的缓存条目。 缓存客户端和服务器之间的通信是通过TCP和UDP协议完成的，速度也非常快。 由于我们添加了更多的副本，这些可以减少我们在单台机器上有高请求负载时必须面对的性能损失。 该设计的一个重要特性是从 RAM 添加、检索和提供数据。因此，执行这些操作的延迟非常低。 注意：高性能的一个关键参数是驱逐算法的选择，因为缓存命中和未命中的数量取决于它。缓存命中率越高，性能越好。 为了了解驱逐算法的重要性，我们假设如下： 缓存命中服务时间 (99.9吨�99. 9th _百分位数）：5 毫秒 缓存未命中服务时间（99.9吨�99. 9th _百分位数：30 毫秒（这包括从数据库获取数据和设置缓存的时间） 假设使用最常用 (MFU) 算法的缓存未命中率为 10%，而使用 LRU 算法的缓存未命中率为 5%。然后，我们使用以下公式： 乙�吨EAT _ _=��吨我��我吨比率**_ _ _ 嗨的X吨我米电子�我吨时间**_ 嗨的 ++ ��吨我�米我秒秒比率**_ _ _ 小姐的X吨我米电子米我秒秒时间**_ 小姐的 在这里，这意味着以下内容： 乙�吨EAT _ _：有效访问时间。 ��吨我��我吨比率**_ _ _ 嗨的：发生缓存命中的次数百分比。 ��吨我�米我秒秒比率**_ _ _ 小姐的：发生高速缓存未命中的次数百分比。 吨我米电子�我吨时间**_ 嗨的：服务缓存命中所需的时间。 吨我米电子米我秒秒时间**_ 小姐的：服务缓存未命中所需的时间。 对于 MFU，我们看到以下内容： EAT = 0.90 x 5 milliseconds + 0.10 x 30 milliseconds = 0.0045 + 0.003 = 0.0075 = 7.5 milliseconds 对于 LRU，我们看到以下内容： EAT = 0.95 x 5 milliseconds + 0.05 x 30 milliseconds = 0.00475 + 0.0015 = 0.00625 = 6.25 milliseconds. 上面的数字突出了驱逐算法对提高缓存命中率的重要性。每个应用程序都应进行实证研究，以确定为特定工作负载提供更好结果的驱逐算法。 以上内容原文(参考后删除即可) 可扩展性 我们可以根据需求和不断变化的服务器负载创建分片。当我们向集群添加新的缓存服务器时，由于一致性哈希，我们还必须进行有限数量的重新哈希计算。 添加副本可以减少热分片上的负载。处理热键问题的另一种方法是在这些键的范围内进行进一步的分片。虽然单个键成为热键的情况很少见，但缓存客户端有可能设计解决方案来避免单个热键争用问题。例如，缓存客户端可以智能地避免单个键成为瓶颈的情况，或者我们可以对特定键使用动态复制，等等。尽管如此，解决方案很复杂，超出了本课的范围。 高可用性 我们通过冗余缓存服务器提高了可用性。冗余为我们的设计增加了一层可靠性和容错能力。我们还使用了leader-follower 算法来方便地管理集群分片。但是，我们还没有实现高可用性，因为我们有两个分片副本，目前，我们假设副本位于数据中心内。 通过将领导服务器和跟随服务器分配到不同的数据中心，可以实现更高的可用性。但这种高可用性是以一致性为代价的。我们假设在同一个数据中心内进行同步写入。但是在不同数据中心同步写入强一致性会严重影响性能，这在缓存系统中是不受欢迎的。我们通常使用跨数据中心的异步复制。 对于数据中心内的复制，我们可以获得强一致性和良好的性能。我们可以妥协跨数据中心复制的强一致性以实现更好的可用性（参见 CAP 和 PACELC 定理）。 一致性 可以以同步或异步模式将数据写入缓存服务器。在缓存的情况下，异步模式有利于提高性能。因此，我们的缓存系统存在不一致问题。或者，强一致性来自同步写入，但这会增加整体延迟，并且性能会受到影响。 不一致也可能由错误的配置文件和服务引起。想象这样一个场景，缓存服务器在写入操作期间宕机，并且在其恢复后立即对其执行读取操作。我们可以通过在合理确定它是最新的之前不允许它为请求提供服务来避免任何加入或重新加入服务器的这种情况。 负担能力 我们提出的设计成本低，因为使用商品硬件创建这样的系统是可行且实用的。 思考要点 # 测验 # 问题一 如果领导者节点在领导者-跟随者协议中失败会怎样？ 在这种情况下可以使用两种可能的解决方案： 使用领导者选举算法从一组可用的追随者中选出一个新的领导者。 使用单独的分布式配置管理服务来监控和选择领导者。 # 问题二: 向缓存服务器引入同步复制是个好主意吗？ 缓存集群上的同步复制会带来性能损失，因为将相同数据复制到所有缓存服务器需要时间。因此，在异步复制和同步复制的使用中分别需要在性能和一致性之间进行权衡。 答案取决于用例。对于缓存服务器，如果复制服务器与主服务器非常接近，同步复制是一个不错的选择。 # 问题三: 假设大量并发请求被转发到单个分片服务器。如果服务器使用 LRU 算法，有些请求会导致缓存未命中并向缓存写入新条目，而有些请求会导致缓存命中并最终从服务器读取。这些并发请求可能相互竞争。因此，可能需要一些锁定机制。但是，为所有读写操作锁定整个数据结构将大大降低性能。您认为将如何处理这样的问题？ 隐藏答案 通常，对于共享数据的并发访问，信号量、监视器、互斥锁等一些锁定机制是不错的选择。但是随着用户数量（缓存命中时读取器或缓存未命中时写入器）的增长，锁定整个数据结构并不是一个合适的解决方案。在这种情况下，我们可以考虑以下选项： 有限锁定：在这种策略中，只有整个数据结构的特定部分才会被锁定。虽然一些线程或进程可以同时读取数据结构，但一些线程可能会暂时阻止对数据结构的特定部分的访问。 离线驱逐：离线驱逐可能是一种可能性，而不是对数据结构进行实际更改，只有在执行不同操作时才会记录所需的更改，直到有必要提交更改。如果高速缓存命中率很高，则此解决方案是理想且简单的，因为发生高速缓存未命中时可能需要更改数据结构。 无锁实现：已经提出了多种解决方案，表明双向链表的同时读写是可行的，可以支持大量并发读写。 摘要 我们研究了缓存的基础知识，并设计了具有良好可用性、高性能、高可扩展性和低成本的分布式缓存。我们的机制使用副本维持高可用性，但如果所有副本都在一个数据中心，这样的方案将无法解决整个数据中心的故障。现在我们已经了解了设计的基础知识，让我们探索流行的开源框架，如 Memcached 和 Redis。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式缓存/Memcached 与 Redis.html":{"url":"分布式缓存/Memcached 与 Redis.html","title":"Memcached 与 Redis","keywords":"","body":"Memcached 与 Redis 让我们比较一下 Memcached 和 Redis。 简介 本课将讨论一些广泛采用的分布式缓存的实际实现。我们的重点将放在两个著名的开源框架上：Memcached 和 Redis。它们是高度可扩展、高性能和强大的缓存工具。这两种技术都遵循客户端-服务器模型并实现亚毫秒级延迟。让我们讨论它们中的每一个，然后比较它们的用处。 内存缓存 Memcached于 2003 年推出。它是一种键值存储分布式缓存，旨在非常快速地存储对象。Memcached 以键值对的形式存储数据。键和值都是字符串。这意味着任何已存储的数据都必须序列化。所以，Memcached 不支持也不能操作不同的数据结构。 Memcached 有一个客户端和服务器组件，每个组件都是运行系统所必需的。该系统的设计方式是一半逻辑包含在服务器中，而另一半在客户端中。但是，每个服务器都遵循无共享架构。在这种架构中，服务器之间相互不知情，服务器之间没有同步、数据共享和通信。 由于断开连接的设计，Memcached 能够实现几乎确定性的查询速度(欧(1个))( O ( 1 ))使用高端系统每秒提供数百万个密钥。因此，Memcached 提供了高吞吐量和低延迟。 从典型 Memcached 集群的设计可以明显看出，Memcached 可以很好地水平扩展。客户端进程通常由服务主机维护，服务主机也与权威存储（后端数据库）进行交互。 Facebook 和 Memcached Facebook 中的数据访问模式需要频繁读取和更新，因为视图是动态呈现给用户的，而不是提前生成的。因为 Memcached 很简单，所以很容易选择解决方案，因为 Memcached 是 2003 年开始开发的，而 Facebook 是 2004 年开发的。事实上，在某些情况下，Facebook 和 Memcached 团队合作寻找解决方案。 雷迪斯(笔者: 其实就是 redis 直接ctrl+F 搜索 全文替换为 redis即可)呢？ Redis 是 2009 年开发的。因此，当时 Facebook 不可能使用 Redis。 Memcached 的一些简单命令包括： get ... set ... delete [] ... 在 Facebook，Memcached 位于 MySQL 数据库和 Web 层之间，该层使用分布在 800 多台服务器上的大约 28 TB 的 RAM（截至 2013 年）。通过近似最近最少使用 (LRU) 逐出策略，Facebook 能够实现 95% 的缓存命中率。 下图显示了 Facebook 缓存架构的高级设计。正如我们所看到的，在 Web 层发出的总共 5000 万个请求中，只有 250 万个请求到达了持久层。 雷迪斯 Redis是一种数据结构存储，可用作缓存、数据库和消息代理。它以额外的复杂性为代价提供了丰富的特性。它具有以下特点： 数据结构存储：Redis 了解它存储的不同数据结构。我们不必从中检索数据结构，操作它们，然后将它们存储回去。我们可以进行内部更改，从而节省时间和精力。 数据库：它可以将所有内存中的 blob 保存在辅助存储上。 消息代理：异步通信是分布式系统中的一项重要要求。Redis 每秒可以将数百万条消息从系统中的一个组件翻译到另一个组件。 Redis 提供了内置的复制机制、自动故障转移和不同级别的持久性。除此之外，Redis 理解 Memcached 协议，因此，使用 Memcached 的解决方案可以转化为 Redis。Redis 的一个特别好的方面是它将数据访问与集群管理分开。它解耦数据并控制平面。这会提高可靠性和性能。最后，由于使用异步复制，Redis 不提供强一致性。 Redis集群 Redis 具有提供高可用性的内置集群支持。这称为 Redis 哨兵。一个集群有一个或多个使用多线程代理查询的 Redis 数据库。Redis 集群执行自动分片，其中每个分片都有主节点和辅助节点。但是，数据库或节点中的分片数量是可配置的，以满足应用程序的期望和要求。 每个 Redis 集群都由集群管理器维护，其工作是检测故障并执行自动故障转移。管理层由监控和配置软件组件组成。 Redis 中的流水线 由于 Redis 使用客户端-服务器模型，每个请求都会阻塞客户端，直到服务器收到结果。希望发送后续请求的 Redis 客户端必须等待服务器响应第一个请求。因此，整体延迟会更高。 Redis 使用流水线来加速这个过程。流水线是在不等待服务器响应的情况下组合来自客户端的多个请求的过程。因此，它减少了多个请求的RTT跨度数。 流水线化过程通过 RTT 减少了延迟，减少了进行套接字级 I/O 的时间。此外，通过操作系统中的系统调用进行模式切换是一项昂贵的操作，通过流水线操作可以显着减少这种操作。从客户端流水线化命令对服务器如何处理这些请求没有影响。 例如，客户端通过管道传输的两个请求到达服务器，而服务器无法处理第二个请求。服务器为第一个提供结果并为第二个返回错误。客户端独立地将类似的命令批处理在一起以实现最大吞吐量。 注意：如果客户端和服务器都在同一台机器上，流水线将延迟至少提高了五倍。该请求在环回地址 ( ) 上发送127.0.0.1。在将请求发送到远程机器的系统中，流水线的真正威力得到了突显。 Memcached 与 Redis 尽管 Memcached 和 Redis 都属于 NoSQL 家族，但它们有一些微妙的区别： 简单性： Memcached 很简单，但是它将管理集群的大部分工作留给了集群的开发人员。然而，这意味着使用 Memcached 可以更好地控制。另一方面，Redis 自动执行大部分可扩展性和数据划分任务。 持久性： Redis 通过仅附加文件 (AOF) 和 Redis 数据库 (RDB) 快照等属性提供持久性。Memcached 中没有持久性支持。但是这个限制可以通过使用第三方工具来解决。 数据类型：Memcached 存储对象，而 Redis 支持字符串、排序集、哈希映射、位图和超级日志。但是，最大键或值大小是可配置的。 内存使用：这两种工具都允许我们为缓存设置最大内存大小。Memcached 使用 slab 分配方法来减少碎片。但是，当我们更新现有条目的大小时或存储许多小对象时，可能会浪费内存。尽管如此，还是有一些配置解决方法可以解决此类问题。 多线程： Redis 使用一个内核作为单个进程运行，而 Memcached 可以通过多线程技术有效地使用多核系统。我们可以争辩说，Redis 被设计为单线程进程，降低了多线程系统的复杂性。尽管如此，可以并发执行多个 Redis 进程。与此同时，Redis 多年来通过调整其性能得到了改进。因此，Redis 可以高效地存储小数据项。Memcached 可能是文件大小超过 100 K 的正确选择。 复制：如前所述，Redis 通过几个命令自动执行复制过程，而 Memcached 中的复制再次受制于第三方工具的使用。在架构上，Memcached 由于其简单性可以很好地水平扩展。Redis 通过相当复杂的集群提供可伸缩性。 下表总结了 Memcached 和 Redis 之间的一些主要区别和共同特征： Memcached 和 Redis 提供的功能 特征 内存缓存 雷迪斯 低延迟 是的 是的 坚持 可以通过第三方工具 多种选择 多语言支持 是的 是的 数据分片 可以通过第三方工具 内置解决方案 使用方便 是的 是的 多线程支持 是的 不 支持数据结构 对象 多种数据结构 支持交易 不 是的 驱逐政策 LRU 多种算法 Lua 脚本支持 不 是的 地理空间支持 不 是的 总而言之，Memcached 更适用于更小、更简单的读取密集型系统，而 Redis 适用于复杂且读取和写入密集型的系统。 # 测验 # 问题一 从实现细节来看，这两个框架（Memcached 或 Redis）中的哪一个与我们在上一课中设计的分布式缓存具有惊人的相似性？ 答案是内存缓存。原因如下： 客户端软件选择使用散列算法的缓存服务器。 服务器软件使用内部哈希表存储每个键的值。 最近最少使用（LRU）被用作驱逐策略。 不同的缓存服务器之间没有通信。 # 问题二 为什么存在用于持久化 Memcached 数据的第三方工具？ 这是因为有大量的数据被读取和写入到缓存服务器，它们可能偶尔会因为某种原因而崩溃。重新启动后，在特定情况下从头开始构建缓存可能需要长达数小时的时间，最终会降低系统性能。因此，缓存数据可能会持久保存到磁盘，以便在重启时加载。 #问题三 与仅存储字符串相比，存储不同的数据结构有什么优势？ 主要优点是Redis可以就地修改数据，不会因为下载和上传而浪费网络带宽。它节省了网络带宽，但也通过避免数据的序列化和反序列化来节省时间和精力。 结论 无法想象不使用缓存系统的高速大规模解决方案。在本章中，我们介绍了对缓存系统的需求及其基本细节，并编排了一个基本的分布式缓存系统。我们还熟悉了两个最著名的缓存框架的设计和功能。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式消息队列/分布式消息队列.html":{"url":"分布式消息队列/分布式消息队列.html","title":"分布式消息队列","keywords":"","body":"分布式消息队列 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式消息队列/系统设计 分布式消息队列.html":{"url":"分布式消息队列/系统设计 分布式消息队列.html","title":"系统设计:分布式消息队列","keywords":"","body":"系统设计：分布式消息队列 了解消息队列、我们使用它的原因以及重要的用例。 我们将涵盖以下内容什么是消息队列？动机消息队列用例我们如何设计分布式消息队列？ 什么是消息队列？ 消息队列是称为生产者和消费者的交互实体之间的中间组件。生产者生产消息并将它们放入队列，而消费者从队列**中**检索消息并处理它们。可能有多个生产者和消费者同时与队列交互。 下面是两个应用程序通过单个消息队列进行交互的图示： 动机 消息队列有几个优点和用例。 改进的性能：改进的性能：消息队列支持两个交互实体（生产者和消费者）之间的异步通信，并消除了它们的相对速度差异。生产者在不等待消费者的情况下将消息放入队列。同样，消费者在消息可用时对其进行处理。此外，队列通常用于将较慢的操作与关键路径分开，因此有助于减少客户感知的延迟。例如，生产者进程不是等待需要很长时间才能完成的特定任务，而是为所需任务发送一条消息，如果有多个请求，该消息将保存在队列中并继续其操作。消费者可以使用另一个队列通知我们处理的结果，无论是成功还是失败。 更好的可靠性：通过消息队列将交互实体分离，使系统具有更高的容错能力。例如，生产者或消费者可以在不影响其他人的情况下独立失败并稍后重新启动。此外，在多台服务器上复制消息队列可确保在一台或多台服务器停机时系统的可用性。 粒度可扩展性：异步通信使系统更具可扩展性。例如，许多进程可以通过消息队列进行通信。此外，当请求数量增加时，我们将工作负载分配给多个消费者。因此，应用程序可以完全控制根据其当前需要调整生产者或消费者进程的数量。 轻松解耦：消息队列解耦系统中不同实体之间的依赖关系。交互实体通过消息进行通信，并且不知道彼此的内部工作机制。 速率限制：消息队列还有助于吸收任何负载峰值并防止服务过载，在需要避免丢弃任何传入请求时充当速率限制的基本形式。 优先级队列：可以使用多个队列来实现不同的优先级，比如每个优先级一个队列，给更高优先级的队列更多的服务时间。 消息队列用例 消息队列在单服务器和分布式环境中都有很多用例。例如，它可用于一个操作系统内的进程间通信。它还支持分布式环境中进程之间的通信。下面讨论消息队列的一些用例。 发送大量电子邮件：电子邮件用于多种目的，例如共享信息、帐户验证、重置密码、营销活动等。所有这些为不同目的而写的电子邮件都不需要立即处理，因此，它们不会干扰系统的核心功能。在这种情况下，消息队列可以帮助协调不同发件人和收件人之间的大量电子邮件。 数据后处理：许多多媒体应用程序需要处理内容以满足不同的观众需求，例如在手机和智能电视上的消费。通常，应用程序将内容上传到商店并使用消息队列对内容进行离线后处理。这样做可以大大减少客户端感知的延迟，并使服务能够在某个适当的时间安排离线工作——可能是在计算能力不那么繁忙的深夜。 推荐系统： 一些平台使用推荐系统向用户提供首选内容或信息。推荐系统获取用户的历史数据，对其进行处理，并预测相关内容或信息。由于这是一项耗时的任务，因此可以在推荐系统和请求流程之间加入一个消息队列，以提高和加快性能。 我们如何设计分布式消息队列？ 我们将分布式消息队列的设计分为以下五课： 需求：在这里，我们关注设计分布式消息队列的功能和非功能需求。我们还将在本课中讨论单服务器消息队列及其缺点。 设计注意事项：在本课中，我们将讨论一些可能影响分布式消息队列设计的重要因素——例如，将消息放入队列的顺序、它们的提取、它们在队列中的可见性以及传入消息的并发性. 设计： 在本课中，我们将详细讨论分布式消息队列的设计。我们还描述了队列复制的过程以及设计中涉及的各种构建块之间的交互。 评估：在本课中，我们根据功能和非功能需求评估分布式消息队列的设计。 测验：在本章末尾，我们通过测验评估对分布式消息队列设计的理解。 让我们首先了解设计分布式消息队列的要求。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-19 "},"分布式消息队列/分布式消息队列设计要求.html":{"url":"分布式消息队列/分布式消息队列设计要求.html","title":"分布式消息队列:设计要求","keywords":"","body":"分布式消息队列的设计要求 了解使用稻草人解决方案设计分布式消息队列的要求。 我们将涵盖以下内容要求功能要求非功能性需求单服务器消息队列我们将使用的积木 要求 在分布式消息队列中，数据驻留在多台机器上。我们的目标是设计一个具有以下功能和非功能需求的分布式消息队列。 功能需求 下面列出了客户端应该能够执行的操作： 队列创建：客户端应该能够创建队列并设置一些参数——例如，队列名称、队列大小和 最大消息大小。 发送消息：生产者实体应该能够将消息发送到为他们准备的队列。 接收消息：消费者实体应该能够从各自的队列中接收消息。 删除消息：消费者进程应该能够在成功处理消息后从队列中删除消息。 队列删除：客户端应该能够删除特定队列。 非功能性需求 我们的分布式消息队列设计应遵循以下非功能性要求： 持久性：系统接收到的数据应该是持久的，不应该丢失。生产者和消费者可以独立发生故障，具有数据持久性的队列对于使整个系统正常工作至关重要，因为其他实体都依赖于队列。 可扩展性：系统需要可扩展，并能够处理增加的负载、队列、生产者、消费者和消息数量。同样，当负载减少时，系统应该能够相应地缩减资源。 可用性：系统在接收和发送消息时应该是高度可用的。它应该继续不间断地运行，即使在其一个或多个组件发生故障后也是如此。 性能：系统应提供高吞吐量和低延迟。 单服务器消息队列 在我们开始设计分布式消息队列的旅程之前，我们应该回顾一下队列是如何在单个服务器中使用的，其中生产者和消费者进程也在同一节点上。生产者或消费者可以通过获取锁机制来访问单服务器队列，避免数据不一致。队列被认为是一个关键部分，其中一次只有一个实体（生产者或消费者）可以访问数据。 然而，有几个方面限制了我们在当今的分布式系统范例中使用单服务器消息队列。例如，在硬件或网络故障的情况下，协作进程、生产者和消费者将无法使用它。此外，随着对锁的争用增加，性能会受到重大打击。此外，它既不可扩展也不可持久。 指向思考 问题 我们可以将单服务器消息队列的设计扩展到分布式消息队列吗？ 隐藏答案 单服务器消息队列有以下缺点：高延迟：与单服务器消息队列的情况一样，生产者或消费者获取锁以访问队列。因此，当许多进程试图访问队列时，这种机制就会成为瓶颈。这会增加服务的延迟。低可用性：由于缺少消息队列的复制，生产者和消费者进程可能无法在发生故障时访问队列。这降低了系统的可用性和可靠性。缺乏持久性：由于没有复制，队列中的数据可能会在系统发生故障时丢失。可扩展性：单服务器消息队列可以处理有限数量的消息、生产者和消费者。因此，它不可扩展。要将单服务器消息队列的设计扩展到分布式消息队列，我们需要付出大量努力来消除上述缺点。 我们将使用的积木 分布式消息队列的设计利用了以下构建块： 需要数据库来存储队列和用户的元数据。 缓存对于保留频繁访问的数据很重要，无论是与用户相关的数据还是队列元数据。 负载平衡器用于将传入请求定向到存储元数据的服务器。 在我们关于消息队列的讨论中，我们专注于它们的功能和非功能需求。在继续设计分布式消息队列之前，我们有必要讨论一些可能影响设计的关键考虑因素和挑战。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-19 "},"分布式消息队列/分布式消息队列的注意事项.html":{"url":"分布式消息队列/分布式消息队列的注意事项.html","title":"分布式消息队列:设计注意事项","keywords":"","body":"分布式消息队列设计的注意事项 了解影响消息传递队列设计的因素。 我们将涵盖以下内容消息排序尽力而为排序严格排序排序对性能的影响管理并发 在开始设计分布式消息队列之前，让我们讨论一些可能对设计产生重大影响的主要因素。其中包括消息的顺序、顺序对性能的影响以及对队列并发访问的管理。我们将在下面详细讨论这些因素中的每一个。 消息排序 消息队列用于接收来自生产者的消息。这些消息由消费者按照自己的节奏消费。一些操作很关键，因为它们需要由队列中的消息驱动的任务执行的严格排序。例如，在与朋友通过消息应用程序聊天时，消息应该按顺序传递；否则，至少可以说，这种交流可能会造成混淆。类似地，一个用户从不同用户收到的电子邮件可能不需要严格排序。因此，在某些情况下，队列中传入消息的严格顺序是必不可少的，而许多用例可以容忍一些重新排序。 让我们讨论以下两类在队列中排序的消息： 尽力而为排序 严格排序 消息的顺序如何关联？ 在队列中，消息的顺序与传入消息隐式关联。将消息放入队列后，这些消息的消费和处理将遵循相同的顺序。 对于将消息放入同一个队列的并发生产者，在生产者提供订单信息（例如，时间戳或序列号）之前，订单并没有很好地定义。在没有任何排序信息的情况下，队列会按照消息到达服务的顺序将消息放入队列中。 对于从同一队列中获取消息的并发消费者，排序可能再次成为一个复杂的问题。虽然队列可以按照消息进入队列的相同顺序一个接一个地移交消息，但几乎同时处理两条消息的两个消费者可能需要特定于应用程序的排序机制。在从队列分发消息时，队列可能会通过标记消息的排序信息、序列号或时间戳来提供帮助。 尽力而为的排序 使用尽力而为排序方法，系统按照接收消息的相同顺序将消息放入指定队列。 例如，如下图所示，生产者按照图示顺序发送A、B、C、D 4条消息。由于网络拥塞等原因，B消息是在D消息之后收到的，因此在接收端消息的顺序是A、C、D、B。因此，在这种方法中，消息将按照它们接收到的相同顺序放入队列中，而不是按照它们在客户端生成的顺序。 严格排序 严格排序技术更严格地保留消息的排序。通过这种方法，消息将按照它们的生成顺序放置在队列中。 在以正确的顺序将消息放入队列之前，必须有一种机制来识别在客户端生成消息的顺序。通常，唯一标识符或时间戳用于在生成消息时对其进行标记。 指向思考 问题 谁负责提供序列号？ 隐藏答案 系统向客户端提供必要的库或 API，以便为客户端生成的消息提供序列号。 以下三种方法之一可用于对传入消息进行排序： 单调递增的数字： 一种对传入消息进行排序的方法是在服务器端为消息分配单调递增的数字。当第一条消息到达时，系统会为其分配一个编号，例如 1。然后它会为第二条消息分配编号 2，依此类推。 然而，这种方法有潜在的缺点。首先，当收到大量请求时，它会成为影响系统性能的瓶颈，因为系统必须按照指定的顺序为一条消息分配一个 ID，而其他消息则等待轮到它们。 其次，它仍然没有解决在客户端较早生成的消息之前收到消息时出现的问题。因此，它不能保证它会为客户端生成的消息生成正确的顺序。 服务器端基于因果关系的排序： 考虑到使用单调递增数字的缺点，另一种可用于时间戳和传入消息排序的方法是基于因果关系的排序。在这种方法中，消息根据在客户端生成的时间戳进行排序，并相应地放入队列中。这种方法的主要缺点是对于多个客户端会话，服务无法根据挂钟时间确定顺序。 使用基于同步时钟的时间戳：为了解决上述两种方法出现的潜在问题，我们可以使用另一种适当的方法为基于同步时钟的消息分配时间戳。在这种方法中，通过同步时钟提供给每条消息的时间戳 (ID) 是唯一的，并且按照正确的消息生成顺序。我们可以用时间戳标记一个唯一的进程标识符，使整个消息标识符唯一，并解决两个并发会话同时请求时间戳的情况。而且，通过这种方法，服务器可以很容易地根据时间戳识别延迟消息并等待延迟消息。 正如我们在有关定序器构建块的部分中所讨论的那样，我们可以获得序列号，它可以作为序列号和全局同步的挂钟时间戳来履行双重职责。使用这种方法，我们的服务也可以跨客户端会话全局排序消息。 总而言之，在上述三种方法中，为传入消息提供唯一 ID 或时间戳的最合适机制涉及使用同步时钟。 排序 服务器端收到消息后，我们需要根据时间戳对它们进行排序。因此，我们 为此目的使用适当的在线排序算法。 指向思考 问题 假设较早发送的消息由于网络延迟而延迟到达。处理这种情况的正确方法是什么？ 隐藏答案 在这种情况下，简单的解决方案是重新排序队列。由此可以产生两种情况。首先，重新排序会将消息按正确的顺序排列。其次，我们已经向消费者发出了更新的信息。如果在我们已经分发了一条新消息时出现一条旧消息，我们会将其放入一个特殊的队列中，客户端会处理这种情况。如果它是一个尽力而为的队列，我们可以将这样的消息放在队列的头部。 对性能的影响 队列主要是为先进先出（FIFO）操作而设计的；。先进先出操作表明进入队列的第一条消息总是最先发出。然而，在分布式系统中维护这种严格的顺序并不容易。由于消息 A 在消息 B 之前生成，因此仍然不确定消息 A 是否会在消息 B 之前被使用。使用单调递增的消息标识符或因果关系承载标识符可在将消息放入队列时提供高吞吐量。尽管需要在线排序以提供严格的顺序，但在消息准备好提取之前需要一些时间。为了最大限度地减少在线排序造成的延迟，我们使用 时间窗口方法。 同样，对于接收端的严格排序，我们需要将所有的请求序列化，一条一条地发出消息。如果不需要，我们在接收端有更好的吞吐量和更低的延迟。 由于上述原因，许多分布式消息队列解决方案要么不能保证严格的顺序，要么对吞吐量有限制。正如我们之前看到的，队列必须执行许多额外的验证和协调操作来维持顺序。 管理并发 并发队列访问需要适当的管理。并发可以发生在以下阶段： 当多个消息同时到达时。 当多个消费者同时请求一条消息时。 第一个解决方案是使用锁定机制。当一个进程或线程请求一条消息时，它应该获取一个锁来放置或使用队列中的消息。然而，如前所述，这种方法有几个缺点。它既不是可扩展的也不是高性能的。 另一种解决方案是使用队列两端的系统缓冲区对请求进行序列化，以便传入消息按顺序放置，并且消费者进程也按到达顺序接收消息。这是一个更可行的解决方案，因为它可以帮助我们避免竞争条件的发生。 应用程序可能会使用具有专用生产者和消费者的多个队列来控制每个队列的排序成本，尽管这是以更复杂的应用程序逻辑为代价的。 在本课中，我们讨论了消息队列设计过程中的一些关键考虑因素和挑战，并回答了以下问题： 为什么消息的顺序很重要，我们如何执行该顺序？ 排序如何影响性能？我们如何在访问队列时处理并发？ 现在，我们准备开始设计分布式消息队列。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-19 "},"分布式消息队列/分布式消息队列设计 第一节.html":{"url":"分布式消息队列/分布式消息队列设计 第一节.html","title":"分布式消息队列设计:第一节","keywords":"","body":"分布式消息队列的设计：第 1 部分 了解消息传递队列的高级设计以及如何扩展队列的元数据。 我们将涵盖以下内容分布式消息队列高层设计负载均衡器前端服务元数据服务 到目前为止，我们已经讨论了分布式消息队列的要求和设计注意事项。现在，让我们开始了解分布式消息队列的高级设计。 分布式消息队列 与单服务器消息队列不同，分布式消息队列驻留在多台服务器上。分布式消息队列有其自身的挑战。但是，如果设计得当，它可以解决单服务器消息队列的缺点。 以下部分通过向我们介绍消息队列的容错体系结构，重点介绍设计分布式消息队列的可伸缩性、可用性和持久性问题。 高层设计 在深入研究设计之前，让我们假设以下几点以使讨论更加简单易懂。在接下来的材料中，我们将讨论以下假设如何使我们能够消除消息队列的单服务器解决方案中的问题。 队列数据使用集群内的主从系统或类似仲裁的系统进行复制（阅读数据复制课程以获取更多详细信息）。如果队列太长而无法容纳在服务器上，我们的服务可以使用数据分区。为此，我们可以使用一致的类似散列的方案，或者我们可以使用键值存储，其中键可能是消息的序列号。在这种情况下，每个分片都会被适当地复制（有关这方面的更多详细信息，请参阅分区课程）。 我们还假设我们的系统可以根据优化利用资源的需要自动扩展和自动收缩资源。 下图演示了由多个组件组成的分布式消息队列的高级设计。 下面详细描述了我们设计的基本组成部分。 负载均衡器 负载均衡器层接收来自生产者和消费者的请求，这些请求被转发到其中一个前端服务器。该层由许多负载平衡器组成。因此，请求以最小的延迟被接受并提供高可用性。 前端服务 前端服务包括分布在数据中心的无状态机器。前端提供以下服务： 请求验证：这确保请求的有效性并检查它是否包含所有必要的信息。 身份验证和授权：此服务检查请求者是否是有效用户，以及这些服务是否已授权请求者使用。 缓存：在前端缓存中，存储与常用队列相关的元数据信息。与此同时，与用户相关的数据也缓存在这里，以减少对身份验证和授权服务的请求时间。 请求调度： 前端还负责调用另外两个服务，即后端和元数据存储。区分对这两种服务的调用是前端的职责之一。 请求重复数据删除：前端还跟踪与所有请求相关的信息，因此，它还可以防止将相同的请求放入队列中。决定如何处理重复项可能就像在商店中搜索哈希键一样简单。如果在商店中发现了某些东西，这意味着重复并且可以拒绝该消息。 使用数据收集：这是指收集可用于审计目的的实时数据。 元数据服务 该组件负责在元数据存储 和缓存中存储、检索和更新队列的元数据。每当创建或删除队列时，元数据存储和缓存都会相应更新。元数据服务充当前端服务器和数据层之间的中间件。由于队列的元数据保存在缓存中，因此前端服务器首先检查缓存以获取与接收请求相关的任何相关信息。如果发生缓存未命中，则会从元数据存储中检索信息并相应地更新缓存。 有两种不同的方法来组织元数据缓存集群： 如果需要存储的元数据很小并且可以驻留在一台机器上，那么它会被复制到每个集群服务器上。随后，可以从任何随机服务器提供请求。在这种方法中，还可以在前端服务器和元数据服务之间引入负载平衡器。 如果需要存储的元数据过多，则可以采用以下方式之一： 第一种策略是使用分片方法将数据分成不同的分片。分片可以基于一些分区键或散列技术来执行，正如在数据库分区课程中所讨论的那样。每个分片都存储在集群中的不同主机上。此外，每个分片也被复制到不同的主机上以增强可用性。在这种集群组织方式中，前端服务器有一个分片和主机之间的映射表。因此，前端服务器负责将请求重定向到存储数据的主机。 第二种方法类似于第一种方法。但是，这种方法中的映射表存储在每个主机上，而不仅仅是前端服务器上。正因为如此，任何随机主机都可以接收请求并将其转发给数据所在的主机。此技术适用于读取密集型应用程序。 在我们关于分布式消息队列的讨论中，我们专注于此类队列的高层设计。此外，我们探索了高级设计中的每个组件，包括以下内容： 前端服务器及其平稳运行所需的服务。 负载平衡器。 元数据服务。 元数据集群及其组织。 设计的一个重要部分是在后端组织服务器，用于队列创建、删除和其他此类操作。下一课的重点是后端服务器的组织和队列的管理，以及与消息传递和检索相关的其他重要操作。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-19 "},"分布式消息队列/分布式消息队列设计 第二节.html":{"url":"分布式消息队列/分布式消息队列设计 第二节.html","title":"分布式消息队列设计:第二节","keywords":"","body":"分布式消息队列的设计：第 2 部分 了解消息队列的详细设计及其在后端服务器的管理。 我们将涵盖以下内容后台服务小学-中学模型独立主机集群 在上一课中，我们讨论了前端服务器和元数据服务的职责。在本课中，我们将重点关注存储队列和消息的设计的主要部分：后端服务。 后端服务 这是发生主要活动的体系结构的核心部分。当前端收到消息时，它会参考元数据服务来确定消息需要发送到的主机。然后将消息转发到主机并在相关主机上复制以克服可能的可用性问题。可以使用以下两种模型之一执行集群中不同主机上的消息复制： 小学-中学模型 独立主机集群 在深入研究这些模型的细节之前，让我们讨论一下负责队列管理的两种类型的集群管理器：内部和外部集群管理器。下表显示了这两个集群管理器之间的差异。 内部与外部集群管理器 内部集群管理器 外部集群管理器 它管理集群内队列的分配。 它管理跨集群的队列分配。 它了解集群中的每个节点。 它知道每个集群。但是，它并没有关于集群中存在的每台主机的信息。 它监听来自每个节点的心跳。 它监控每个独立集群的健康状况。 它管理主机故障、实例添加和从集群中删除。 它管理和使用集群。 它将队列分成几个部分，每个部分都有一个主服务器。 它可以将一个队列拆分到多个集群中，以便同一队列的消息在多个集群之间平均分配。 主次模型 在主从模型中，每个节点都被视为队列集合的主要主机。主主机的职责是接收对特定队列的请求，并全面负责数据复制。请求由前端接收，然后与元数据服务通信以确定请求的主要主机。 例如，假设我们有两个队列，标识为 101 和 102，分别驻留在 A、B、C 和 D 四个不同的主机上。在本例中，实例 B 是队列 101 的主主机，队列 101 所在的辅助主机复制的是 A 和 C。当前端接收消息请求时，它通过元数据服务从内部集群管理器识别主服务器。消息是从主实例中检索的，主实例还负责在使用时删除原始消息及其所有副本。 如下图所示，内部集群管理器是负责主主机、从主机和队列之间映射的组件。此外，它还有助于主要主机的选择。因此，它需要可靠、可扩展和高性能。 独立主机集群 在涉及独立主机集群的方法中，我们有几个分布在数据中心的多个独立主机集群。当前端接收到消息时，它通过来自外部集群管理器的元数据服务确定相应的集群。然后消息被转发到集群中的随机主机，该主机在存储队列的其他主机中复制消息。 指向思考 问题 集群中的随机主机如何在同一集群中其他主机的队列中复制数据（即消息）？ 隐藏答案 每个主机都包含队列和集群内主机之间的映射，使复制更容易。假设我们有一个集群，比如说 Y，有主机 A、B 和 C。这个集群有两个 ID 为 101 和 103 的队列存储在不同的主机上，如下表所示。该表存储在集群 Y 内的每个主机上。当随机主机（例如主机 C）收到 ID 为 103 的队列的消息时，主机 C 将此消息复制到存储队列 103 的其他主机，即节点A 和节点 B。 应用相同的过程来接收来自消费者的消息请求。与第一种方法类似，随机选择的主机负责消息的传递和消息处理成功后的清理。 此外，还引入了另一个称为外部集群管理器的组件，它负责维护队列和集群之间的映射，如下图所示。外部集群管理器还负责队列管理和对特定队列的集群分配。 下图说明了独立主机的集群。有两个集群，A 和 B，它们由几个节点组成。外部集群管理器具有队列与其对应集群之间的映射表。每当前端收到对队列的请求时，它会为该队列确定相应的集群，并将该请求转发给该队列所在的集群。该集群中的节点负责相应地存储和发送消息。 指向思考 问题 在其他主机上复制消息时会出现什么样的异常？ 隐藏答案 有两种方法可以复制驻留在多台主机上的队列中的消息。同步复制异步复制在同步复制中，主要主机负责复制其他主机上所有相关队列中的消息。在从辅助主机确认后，主要主机然后通知客户端有关消息的接收。在这种方法中，消息在所有队列副本中保持一致；但是，这会导致额外的通信延迟，并导致部分可用性或无法使用，而选举正在进行中以将次要节点提升为主要节点。在异步复制中，一旦主主机收到消息，它就会确认客户端，并在下一步中开始在其他主机中复制消息。这种方法会带来其他问题，例如复制滞后和一致性问题。根据应用程序的需要，我们可以选择一个或另一个。 我们已经完成了分布式消息队列的设计，并讨论了组织后端服务器的两种模型。我们还描述了队列的管理过程以及后端如何处理消息。此外，我们还讨论了如何通过不同的集群管理器管理后端服务器。 在下一课中，我们将讨论我们的系统如何满足本章前面描述的功能和非功能需求。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-19 "},"分布式消息队列/分布式消息队列设计 评估.html":{"url":"分布式消息队列/分布式消息队列设计 评估.html","title":"分布式消息队列设计:评估","keywords":"","body":"分布式消息队列设计的评估 根据分布式消息队列的功能和非功能要求评估建议的系统。 我们将涵盖以下内容功能要求非功能性需求结论 我们完成了分布式消息队列的设计过程。现在，让我们分析一下设计是否满足分布式消息队列的功能和非功能需求。 功能需求 队列创建和删除： 当前端收到队列请求时，在经过一些基本检查后，将使用客户端提供的所有必要详细信息创建队列。相应的集群管理器将服务器分配给新创建的队列，并通过元数据服务更新元数据存储和缓存中的信息。 同样，当客户端不再需要队列时，队列将被删除。负责的集群管理器释放队列占用的空间，并因此从所有元数据存储和缓存中删除数据。 指向思考 问题 我们如何处理在消费者进行最大处理尝试后无法处理的消息（这里指的是已消费）？ 隐藏答案 可以提供一种特殊类型的队列，称为死信队列，以处理在消费者进行了最大处理尝试次数后未被消费的消息。这种类型的队列也用于保留由于以下因素而无法成功处理的消息：用于不再存在的队列的消息。超出了队列长度限制，尽管在我们当前的设计中这种情况很少发生。由于每条消息的生存时间 (TTL)，消息会过期。死信队列对于确定故障原因和识别系统中的故障也很重要。 发送和接收消息： 生产者可以在创建消息后将消息传递到特定队列。在后端，接收消息根据时间戳进行排序以保持其顺序并放入队列中。同样，消费者可以从指定的队列中检索消息。 当从特定队列的生产者接收到消息时，前端根据队列所在的复制模型识别主要主机或集群。然后将请求转发给相应的实体并放入队列中。 消息删除：主要有两个选项用于从队列中删除消息。 第一个选项是在消费消息后不删除消息。但是，在这种情况下，消费者负责跟踪消费的内容。为此，我们需要维护队列中消息的顺序并跟踪队列中的消息。当满足到期条件时，作业可以删除消息。Apache Kafka 主要使用这种想法，多个进程可以使用一条消息。 第二种方法在消费消息后也不会删除消息。但是，它会通过属性在一段时间内不可见，例如visibility_timeout. 这样，其他消费者就无法获取已经被消费的消息。然后消费者通过 API 调用删除该消息。 在这两种情况下，消费者检索的消息仅被消费者删除。这背后的原因是为了在消费者由于某些故障而无法处理消息时提供高持久性。在这种情况下，如果没有删除调用，消费者可以在消息返回时再次检索消息。 此外，这种方法还提供至少一次传递语义。例如，当一个 worker 处理消息失败时，另一个 worker 可以在消息在队列中可见后检索该消息。 指向思考 问题 当特定消息的可见性超时到期而消费者仍在忙于处理消息时会发生什么？ 隐藏答案 消息变得可见，另一个工作人员可以接收消息，从而重复处理。为避免这种情况，我们确保应用程序为可见性超时设置安全阈值。 非功能性需求 持久性：为了实现持久性，队列的元数据被复制到不同的节点上。同样，当收到一条消息时，它会被复制到驻留在不同节点上的队列中。因此，如果一个节点发生故障，可以使用其他节点来传递或检索消息。 可扩展性：我们的设计组件，如前端服务器、元数据服务器、缓存、后端集群等，都是可水平扩展的。我们可以增加或减少他们的能力以满足我们的需要。可扩展性可以分为两个维度： 消息数量增加：当消息数量达到特定限制（例如 80%）时，指定队列将被扩展。同样，当消息数量低于特定阈值时，队列会收缩。 队列数量增加：随着队列数量的增加，对更多服务器的需求也随之增加，在这种情况下，集群管理器负责添加额外的服务器。我们委托节点，以便不同队列之间存在性能隔离。一个队列上增加的负载不应影响其他队列。 可用性：我们的数据组件、元数据和实际消息在数据中心内部或外部被正确复制，负载均衡器在故障节点周围路由流量。这些机制共同确保我们的系统在故障情况下仍可用于服务。 性能：为了获得更好的性能，我们使用缓存、数据复制和分区来减少数据读写时间。此外，用于消息排序的最佳排序策略可用于在必要时提高吞吐量并降低延迟。在严格排序的情况下，我们还建议基于时间窗口的排序以潜在地减少延迟。 结论 我们讨论了在分布式环境中设计 FIFO 队列的许多微妙之处。我们看到在严格的消息生产、消息提取顺序以及可实现的吞吐量和延迟之间存在权衡。宽松的排序为我们提供了更高的吞吐量和更低的延迟。要求严格排序会迫使系统做额外的工作来强制执行挂钟或基于因果关系的排序。我们使用具有适当复制和分区的不同数据存储来扩展数据。这个设计练习强调了一个构造，一个生产者-消费者队列，在基于单一操作系统的系统中很容易实现，但在分布式环境中变得更加困难。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-19 "},"分布式消息队列/分布式消息队列设计 测验.html":{"url":"分布式消息队列/分布式消息队列设计 测验.html","title":"分布式消息队列设计:测验","keywords":"","body":"分布式消息队列设计小测验 通过测验评估您对分布式消息队列相关概念的理解。 # 一 死信队列包含什么样的消息？ 一个） 消费成功的消息。 乙) 消费失败且已达到最大尝试次数限制的消息数。 丙） 由现在已死的进程产生的消息。 丁） 以上都不是 # 二 在多个服务器上复制队列的目的是为了增强系统的________。 一个） 安全 乙) 一致性 丙） 可用性 丁） 以上都不是 # 三 在独立主机集群模型中，哪个组件负责在其他节点中复制消息？ 一个） 前端服务器 乙) 集群管理器 丙） 集群中的任何随机主机 丁） 以上都不是 # 四 元数据服务的目的是________。 一个） 将消息连同它们的元数据一起存储在队列中 乙) 在元数据存储和缓存中存储、检索和更新队列的元数据 丙） 在访问队列时提供安全功能 丁） 以上都不是 # 五 以下哪项负责对队列进行分区并为每个分区分配一个主节点？ 一个） 内部集群管理器 乙) 外部集群管理器 丙） 主节点 丁） 二级节点之一 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-19 "},"发布订阅/发布订阅.html":{"url":"发布订阅/发布订阅.html","title":"发布-订阅","keywords":"","body":"发布-订阅 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"发布订阅/系统设计 发布-订阅抽象.html":{"url":"发布订阅/系统设计 发布-订阅抽象.html","title":"系统设计:发布-订阅抽象","keywords":"","body":"系统设计:发布-订阅抽象 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"发布订阅/发布订阅简介.html":{"url":"发布订阅/发布订阅简介.html","title":"发布-订阅简介","keywords":"","body":"发布-订阅简介 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"发布订阅/发布订阅系统设计.html":{"url":"发布订阅/发布订阅系统设计.html","title":"发布-订阅系统设计","keywords":"","body":"发布-订阅系统设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"限速器/限速器.html":{"url":"限速器/限速器.html","title":"限速器","keywords":"","body":"限速器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"限速器/系统设计 速率限制器.html":{"url":"限速器/系统设计 速率限制器.html","title":"系统设计:速率限制器","keywords":"","body":"系统设计:速率限制器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"限速器/速率限制器 设计要求.html":{"url":"限速器/速率限制器 设计要求.html","title":"速率限制器: 设计要求","keywords":"","body":"速率限制器: 设计要求 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"限速器/速率限制器 设计.html":{"url":"限速器/速率限制器 设计.html","title":"速率限制器: 设计","keywords":"","body":"速率限制器: 设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"限速器/速率限制器 算法.html":{"url":"限速器/速率限制器 算法.html","title":"速率限制器: 算法","keywords":"","body":"速率限制器: 算法 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"限速器/速率限制器 测验.html":{"url":"限速器/速率限制器 测验.html","title":"速率限制器:测验","keywords":"","body":"速率限制器:测验 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"Blob商店/Blob商店.html":{"url":"Blob商店/Blob商店.html","title":"Blob Store","keywords":"","body":"Blob Store Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"Blob商店/系统设计 BlobStore.html":{"url":"Blob商店/系统设计 BlobStore.html","title":"系统设计:Blob Store","keywords":"","body":"系统设计:Blob Store Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"Blob商店/BlobStore 设计要求.html":{"url":"Blob商店/BlobStore 设计要求.html","title":"Blob Store:设计要求","keywords":"","body":"Blob Store:设计要求 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"Blob商店/BlobStore 设计.html":{"url":"Blob商店/BlobStore 设计.html","title":"Blob Store:设计","keywords":"","body":"Blob Store:设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"Blob商店/Blob存储设计.html":{"url":"Blob商店/Blob存储设计.html","title":"Blob 存储设计","keywords":"","body":"Blob 存储设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"Blob商店/Blob Store设计.html":{"url":"Blob商店/Blob Store设计.html","title":"Blob Store 设计","keywords":"","body":"Blob Store 设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式搜索/分布式搜索.html":{"url":"分布式搜索/分布式搜索.html","title":"分布式搜索","keywords":"","body":"分布式搜索 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式搜索/系统设计 分布式搜索.html":{"url":"分布式搜索/系统设计 分布式搜索.html","title":"系统设计:分布式搜索","keywords":"","body":"系统设计：分布式搜索 了解搜索系统的工作原理并了解我们设计分布式搜索系统的高级计划。 为什么我们需要搜索系统？ 如今，我们几乎在每个网站上都能看到搜索栏。我们使用该搜索栏从该网站上可用的大量内容中挑选出相关内容。搜索栏使我们能够快速找到我们正在寻找的内容。例如，教育网站上有很多课程。如果我们没有搜索功能，用户将不得不滚动浏览许多页面并阅读每门课程的名称才能找到他们正在寻找的课程。 让我们再举一个例子。YouTube 上上传和存储了数十亿个视频。想象一下，如果 YouTube 没有为我们提供搜索栏。我们如何从多年来发布在 YouTube 上的数百万个视频中找到特定的视频？浏览所有这些视频并找到我们需要的视频需要几个月的时间。用户发现仅仅通过四处滚动就很难找到他们正在寻找的东西。 搜索引擎是一个更大的例子。我们在 Internet 上拥有数十亿个网站。每个网站都有很多网页，每个网页上都有很多内容。内容如此之多，如果没有搜索引擎，互联网几乎毫无用处，用户最终会迷失在无关数据的海洋中。搜索引擎本质上是对大量可用数据的过滤器。它们让用户快速获取真正感兴趣的信息，而无需筛选过多不必要的网页。 每个搜索栏的背后都有一个搜索系统。 什么是搜索系统？ 搜索系统是一种从用户那里获取一些文本输入（搜索查询）并在几秒或更短时间内返回相关内容的系统。搜索系统包含三个主要组件，即： 抓取内容并创建文档的爬虫。 一个索引器，它构建一个可搜索的索引。 搜索器，它通过在*索引器创建的索引*上运行搜索查询来响应搜索查询。 注意：我们有单独的章节专门对爬虫组件进行讲解。在本章中，我们将重点关注索引。 我们将如何设计分布式搜索系统？ 我们将分布式搜索系统的设计分为五课： 需求：在本课中，我们列出了分布式搜索系统的功能和非功能需求。我们还估算了我们系统的资源，例如服务器、存储和处理大量查询所需的带宽。 索引：本课通过示例为我们提供了有关索引过程的背景知识。在讨论了索引之后，我们还研究了分布式搜索系统的集中式架构。 初始设计：本课包括我们系统的高级设计、API 以及索引和搜索过程的细节。 最终设计：在本课中，我们将评估之前的设计并对其进行改造以使其更具可扩展性。 评估：本课解释了我们设计的分布式搜索系统如何满足其要求。 让我们首先了解设计分布式搜索系统的要求。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式搜索/分布式搜索 设计要求.html":{"url":"分布式搜索/分布式搜索 设计要求.html","title":"分布式搜索:设计要求","keywords":"","body":"分布式搜索系统设计要求 让我们确定分布式搜索系统的要求并概述我们需要的资源。 我们将涵盖以下内容要求功能要求非功能性需求资源估算服务器数量估计存储估算带宽估计我们将使用的积木 要求 让我们了解分布式搜索系统的功能和非功能需求。 功能需求 以下是一个分布式搜索系统的功能需求： 搜索：用户应该根据他们的搜索查询获得相关内容。 分布式搜索系统的功能需求 非功能性需求 以下是分布式搜索系统的非功能性需求： 可用性：系统应该对用户高度可用。 可扩展性：系统应该能够随着数据量的增加而扩展。换句话说，它应该能够索引大量数据。 大数据快速搜索：无论搜索多少内容，用户都应该快速获得结果。 降低成本：构建搜索系统的总体成本应该更低。 资源估算 我们来估算分布式搜索系统所需的服务器、存储和带宽的总数。我们将使用 YouTube 搜索示例来计算这些数字。 服务器数量估计 要估算服务器数量，我们需要知道每天有多少活跃用户在使用 YouTube 上的搜索功能，以及我们的单个服务器每秒可以处理多少请求。我们假设以下数字： 使用搜索功能的每日活跃用户数为 300 万。 单个服务器可以处理的请求数为 1,000。 使用以下公式计算所需的服务器数量： $$ \\frac{Number of active users}{queries handled per server} = 3K servers $$ 如果三百万用户并发搜索，则同时产生三百万搜索请求。单个服务器一次处理 1,000 个请求。将 300 万除以 1,000 得到 3,000 台服务器。 存储估算 每个视频的元数据都存储在一个单独的 JSON 文档中。每个文档都由视频 ID 唯一标识。此元数据包含视频的标题、描述、频道名称和文字记录。我们假设以下数字来估算索引一个视频所需的存储空间： 单个 JSON 文档的大小为 200 KB。 从单个 JSON 文档中提取的唯一术语或键的数量为 1,000。 向索引表中添加一个术语所需的存储空间量为 100 字节。 以下公式用于计算索引一个视频所需的存储空间： $$ Total(storage/video)=Storage/doc +(Terms/doc*Storage/term) $$ 在 YouTube 上索引一个视频所需的总存储空间 每个 JSON 文档的存储量 (KB) 每个文档的条款数量 每学期存储（字节） 每个视频的总存储量 (KB) 200 1000 100 300 在上表中，我们计算了索引一个视频所需的存储空间。我们已经看到每个视频所需的总存储空间为 300 KB。假设平均每天在 YouTube 上上传的视频数量为 6,000，我们来计算索引每天上传的视频所需的总存储空间。以下公式用于计算将一天内上传到 YouTube 的视频编入索引所需的存储空间： $$ Total(storage/day)=No.ofvideos/day×Total(storage/video) $$ 每天在 YouTube 上索引视频所需的总存储空间 每天的视频数量 每个视频的总存储量 (KB) 每天总存储量(GB) 6000 300 1.8 将每天上传到 YouTube 的 6,000 个视频编入索引所需的总存储空间为 1.8 GB。此存储要求只是 YouTube 的估计值。如果我们将分布式搜索系统作为服务提供给多个租户，存储需求将会增加。 总结分布式搜索系统对每天上传到 YouTube 的视频的存储需求 带宽估计 每次搜索请求时，数据都会在用户和服务器之间传输。我们估计服务器上传入流量和服务器传出流量所需的带宽。以下是计算所需带宽的公式： $$ Total (bandwidth)=Total (requests_second)×Total(query_size)​ $$ 传入流量 为了估计传入流量带宽，我们假设以下数字： 每天的搜索请求数为 1.5 亿。 搜索查询大小为 100 字节。 我们可以使用上面给出的公式来计算传入流量所需的带宽。 每秒传入搜索查询所需的带宽 每秒请求数 查询大小（字节） 带宽 (Mb/s) 1736.11 100 F1.39 传出流量 传出流量是服务器根据搜索请求返回给用户的响应。我们假设针对搜索查询的建议视频数量为 80，并且一个建议的大小为 50 字节。建议由视频 ID 的有序列表组成。 为了估计传出流量带宽，我们假设以下数字： 每天的搜索请求数为 1.5 亿。 响应大小为 4,000 字节。 我们可以使用相同的公式来计算传出流量所需的带宽。 每秒传出流量所需的带宽 每秒请求数查询大小（字节）带宽 (Mb/s)1736.114000F55.56 注意：带宽要求相对适中，因为我们假设的是文本结果。许多搜索服务可以返回小缩略图和其他媒体来增强搜索页面。每页的带宽需求有意设置得较低，以便该服务可以向客户端提供近乎实时的结果。 我们将使用的积木 我们的设计需要分布式存储。因此，我们可以使用之前讨论过的构建块blob store该索引之后添加来存储要索引的数据和索引本身。我们将使用通用术语，即“分布式存储”，而不是特定术语“blob 存储”。 最后，我们解释了搜索系统的要求。我们进行了资源估算。最后，我们提到了我们将在分布式搜索系统设计中使用的构建块。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式搜索/分布式搜索 索引.html":{"url":"分布式搜索/分布式搜索 索引.html","title":"分布式搜索: 索引","keywords":"","body":"分布式搜索中的索引 了解索引及其在分布式搜索中的使用。 我们将首先描述什么是索引，然后我们将着手在许多节点上分布索引。 索引 索引是为了促进快速准确的信息检索而对数据进行的组织和操作。 建立一个可搜索的索引 构建可搜索索引的最简单方法是为每个文档分配一个唯一 ID，并将其存储在数据库表中，如下表所示。表中的第一列是文本的 ID，第二列包含每个文档中的文本。 简单文档索引 ID 文件内容 1个 Elasticsearch 是基于 REST API 的分布式分析引擎。 2个 Elasticsearch 是一个基于 Lucene 库的搜索引擎。 3个 Elasticsearch 是一个基于 Apache Lucene 的分布式搜索和分析引擎。 上面给出的表格的大小会有所不同，具体取决于我们拥有的文档数量和这些文档的大小。上表只是一个示例，每个文档的内容仅由一两个句子组成。举一个真实的例子，表中每个文档的内容都可能有几页那么长。这将使我们的表非常大。在上面给出的文档级索引上运行搜索查询并不是一个快速的过程。在每个搜索请求中，我们必须遍历所有文档并计算每个文档中搜索字符串的出现次数。 注意：对于模糊搜索，我们还必须执行不同的模式匹配查询。文档中的许多字符串会以某种方式匹配搜索到的字符串。首先，我们必须通过遍历所有文档来找到唯一的候选字符串。然后，我们必须从这些字符串中挑出最接近匹配的字符串。我们还必须找到每个文档中最匹配的字符串的出现。这意味着每个搜索查询都需要很长时间。 搜索查询的响应时间取决于几个因素： 数据库中的数据组织策略。 数据的大小。 用于构建索引和处理搜索查询的机器的处理速度和 RAM。 对文档级索引的数十亿文档运行搜索查询将是一个缓慢的过程，可能需要几分钟甚至几小时。让我们看看另一种有助于减少搜索时间的数据组织和处理技术。 倒排索引 倒排索引是一种类似于 HashMap 的数据结构，它使用文档术语矩阵。它不是按原样存储完整的文档，而是将文档拆分为单个单词。在此之后，文档-术语矩阵识别独特的词并丢弃频繁出现的词，如“to”、“they”、“the”、“is”等。像这样经常出现的词被称为术语。文档术语矩阵通过识别唯一单词和删除不必要的术语来维护术语级索引。 对于每个术语，索引计算以下信息： 出现该术语的文档列表。 术语在每个文档中出现的频率。 术语在每个文档中的位置。 倒排索引 学期 测绘**( [文档], [频率], [[位置])** 弹性搜索 ( [1, 2, 3], [1, 1, 1], [[1], [1], [1]] ) 分散式 ( [1, 3], [1, 1], [[4], [4]] ) 宁静的 ( [1], [1], [[5]] ) 搜索 ( [1, 2, 3], [1, 1, 1], [[6], [4], [5]] ) 分析 ( [1, 3], [1, 1], [[8], [7]] ) 引擎 ( [1, 2, 3], [1, 1, 1], [[9], [5], [8]] ) 心 ( [1], [1], [[12]] ) 松紧带 ( [1], [1], [[15]] ) 堆 ( [1], [1], [[16]] ) lucene ( [2, 3], [1, 1], [[9], [12]] ) 图书馆 ( [2], [1], [[10]] ) 阿帕奇 ( [3], [1], [[11]] ) 在上表中，“术语”列包含从所有文档中提取的所有唯一术语。“映射”列中的每个条目都包含三个列表： 出现该术语的文档列表。 一个列表，用于计算术语在每个文档中出现的频率。 一个二维列表，用于精确定位术语在每个文档中的位置。一个术语可以在单个文档中出现多次，这就是使用二维列表的原因。 注意：除了列表，映射也可以采用元组的形式——例如 doc、freq 和 loc。 倒排索引是文档检索中最流行的索引机制之一。它可以有效地实现boolean、extended boolean、proximity、relevance和许多其他类型的搜索算法。 使用倒排索引的优点 倒排索引有助于全文搜索。 倒排索引减少了在运行时计算每个文档中单词出现的时间，因为我们有针对每个术语的映射。 使用倒排索引的缺点 将倒排索引与实际文档一起维护会产生存储开销。但是，我们减少了搜索时间。 添加、更新或删除文档的维护成本（处理）。要添加文档，我们从文档中提取术语。然后，对于每个提取的术语，我们要么在倒排索引中添加一个新行，要么更新现有的行（如果该术语在倒排索引中已经有一个条目）。类似地，对于删除文档，我们进行处理以在倒排索引中查找已删除文档术语的条目，并相应地更新倒排索引。 从倒排索引中搜索 当我们搜索单词“搜索引擎”时，考虑一个具有以下映射的系统： 学期 测绘 搜索 ( [1, 2, 3], [1, 1, 1], [[6], [4], [5]] ) 引擎 ( [1, 2, 3], [1, 1, 1], [[9], [5], [8]] ) 这两个词都在文档 1、2 和 3 中找到。这两个词在每个文档中出现一次。 单词“search”在文档 1 中位于位置 6，在文档 2 中位于位置 4，在文档 3 中位于位置 5。 “engine”一词在文档1中位于第9位，在文档2中位于第5位，在文档3中位于第8位。 一个术语可以出现在数百万个文档中。因此，针对搜索查询返回的文档列表可能会很长。 问题 当针对单个术语找到太多文档时，此技术是否有效？ 隐藏答案 返回所有找到的文档可能行不通。相反，我们应该根据与搜索查询的相关性对它们进行排序。应该将排名靠前的结果返回给用户，而不是返回所有文档。 索引设计因素 以下是我们在设计索引时应牢记的一些因素： 索引大小：保留索引需要多少计算机内存和 RAM。我们将索引保存在 RAM 中以支持搜索的低延迟。 搜索速度：我们可以多快从倒排索引中找到一个词。 索引的维护：如果我们添加或删除文档，索引的更新效率如何。 容错性：服务保持可靠的重要性。应对索引损坏、支持无效数据是否可以隔离处理、处理有缺陷的硬件、分区和复制都是这里要考虑的问题。 弹性：系统对试图玩弄系统并防范搜索引擎优化 (SEO) 方案的人的弹性有多大，因为我们只返回少数相关搜索结果。 鉴于上面列出的设计因素，让我们看一下在中心化系统上构建索引的一些问题。 在集中式系统上建立索引 在集中式搜索系统中，所有搜索系统组件都在一个节点上运行，该节点在计算能力上非常强大。集中搜索系统的架构如下图所示： 索引过程将文档作为输入并将它们转换为倒排索引，以二进制文件的形式存储。 查询处理或搜索过程解释包含倒排索引的二进制文件。它还计算给定查询的倒排列表的交集，以返回针对该查询的搜索结果。 这些是中心化搜索系统架构带来的问题： SPOF（单点故障） 服务器过载 索引量大 SPOF：集中式系统是单点故障。如果它死了，则无法执行任何搜索操作。 服务器过载：如果查询用户多，查询复杂，对服务器（节点）造成压力。 大索引：倒排索引的大小随着文档数量的增加而增加，对单个服务器提出了资源需求。计算机系统越大，管理它的成本和复杂性就越高。 注意：对于分布式系统，使用低成本的计算机系统，总体上具有成本效益。 添加文档或运行搜索查询时，需要将倒排索引加载到主内存中。为了提高效率，倒排索引的很大一部分必须装入机器的 RAM 中。 根据谷歌分析，2022 年，网页数量达数千亿个，总大小约为 100 PB。如果我们为万维网做一个搜索系统，倒排索引的大小也将以 PB 为单位。这意味着我们必须将 PB 级的数据加载到 RAM 中。增加单台机器的资源来索引十亿页而不是转移到分布式系统并利用并行化的力量是不切实际且低效的。在单个大型倒排索引上运行搜索查询会导致响应时间变慢。 注意：从拥有一百本书的书架中搜索一本书比从拥有一百万本书的书架中搜索一本书更容易。搜索时间随着我们搜索的数据量的增加而增加。 对集中式索引的攻击比对分布式索引系统的攻击具有更大的影响。此外，分布式索引中出现瓶颈的几率（可能出现在服务器带宽或 RAM 中）也较低。 在本课中，我们学习了索引，并研究了集中式系统上的索引问题。下一课介绍索引的分发解决方案。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式搜索/分布式搜索 设计.html":{"url":"分布式搜索/分布式搜索 设计.html","title":"分布式搜索:设计","keywords":"","body":"分布式搜索的设计 概述每秒管理大量查询的分布式搜索系统的设计。 高层设计 在进入详细讨论之前，让我们塑造分布式搜索系统的总体设计。这种系统有两个阶段，如下图所示。离线阶段\\涉及数据爬取和索引，用户无需执行任何操作。在线阶段\\包括根据用户的搜索查询搜索结果。 爬虫从目标资源中收集内容。例如，如果我们为 YouTube 应用程序构建搜索，爬虫将爬取 YouTube 上的所有视频并提取每个视频的文本内容。内容可以是视频的标题、描述、频道名称，甚至可以是视频的注释，以便不仅可以根据标题和描述，还可以根据视频的内容进行智能搜索。爬虫将提取的每个视频的内容格式化为 JSON 文档，并将这些 JSON 文档存储在分布式存储中。 索引器从分布式存储中获取文档并使用MapReduce对这些文档进行索引，MapReduce 在商用机器的分布式集群上运行。索引器使用像 MapReduce 这样的分布式数据处理系统进行并行和分布式索引构建。构建的索引表存储在分布式存储中。 分布式存储用于存储文档和索引。 用户在搜索栏中输入包含多个单词的搜索字符串。 搜索器解析搜索字符串，从存储在分布式存储中的索引中搜索映射，并将最匹配的结果返回给用户。搜索器智能地将搜索字符串中拼写错误的单词映射到最接近的词汇表单词。它还会查找包含所有单词的文档并对它们进行排序。 API设计 由于用户只发送字符串形式的请求，API设计相当简单。 搜索：该search函数在用户查询系统以查找某些内容时运行。 search(query) 范围 描述 query 这是用户在搜索栏中输入的文本查询，基于它找到结果。 详细讨论 由于索引器是搜索系统的核心组件，我们在上一课中讨论了索引技术以及与集中索引相关的问题。在本课中，我们考虑用于索引和搜索的分布式解决方案。 分布式索引和搜索 让我们看看如何开发分布式索引和搜索系统。我们知道索引系统的输入是我们在抓取过程中创建的文档。为了以分布式方式开发索引，我们使用大量低成本机器（节点）并根据它们拥有的资源对文档进行分区或划分。所有节点都已连接。一组节点称为集群。 提示 为了执行分布式索引，集群中的机器通常具有运行 Linux 的双处理器 x86 处理器，每台机器具有 2-4 GB 的内存。不必所有机器都具有相同的规格，尽管它们应该具有一定的可比性。MapReduce 框架非常智能，可以为更强大的机器提供更多工作。 我们使用大量的小节点进行索引以实现成本效益。这个过程需要我们在这些节点之间划分或拆分输入数据（文档）。但是，需要解决一个关键问题：我们如何执行此分区？ 分布式索引中用于数据分区的两种最常用技术如下： 文档划分：在文档划分中，网络爬虫收集的所有文档被划分为文档的子集。然后每个节点对分配给它的文档子集执行索引。 术语划分：所有术语的字典被划分成子集，每个子集驻留在一个节点上。例如，文档子集由包含术语“搜索”的节点处理和索引。 在术语划分中，搜索查询被发送到与查询术语对应的节点。这提供了更多的并发性，因为具有不同查询词的搜索查询流将由不同的节点提供服务。然而，术语划分在实践中被证明是一项艰巨的任务。多词查询需要在节点组之间发送长映射列表以进行合并，这可能比增加并发性带来的好处更昂贵。 在文档分区中，每个查询分布在所有节点上，这些节点的结果在显示给用户之前被合并。这种分区方法需要较少的节点间通信。在我们的设计中，我们使用文档分区。 在文档分区之后，让我们看一下用于索引构建和查询的分布式设计，如下图所示。我们使用一个由许多低成本节点和一个集群管理器组成的集群。集群管理器使用 MapReduce 编程模型来并行化每个分区上的索引计算。MapReduce 可以处理难以由单个大型服务器处理的大得多的数据集。 上述系统的工作原理如下： 索引 我们有一个已被爬虫收集的文档集。 集群管理器将输入文档集拆分为否否分区数，其中否否在上图中等于三。每个分区的大小由集群管理器根据数据大小、计算、内存限制和集群中的节点数量决定。由于各种原因，所有节点可能都不可用。集群管理器通过定期心跳监测每个节点的健康状况。将文档分配给其中一个否否分区，可以使用散列函数。 分区后，集群管理器为所有分区运行索引算法否否同时分区否否集群中的节点数。每个索引过程都会产生一个微小的倒排索引，该索引存储在节点的本地存储中。这样，我们生产否否微小的倒排索引而不是一个大的倒排索引。 搜索中 在搜索阶段，当用户查询出现时，我们对存储在节点本地存储中的每个微小倒排索引运行并行搜索，生成 N 个查询。 每个反向微型索引的搜索结果是一个针对查询词的映射列表（我们假设单个词/词用户查询）。合并聚合了这些映射列表。 聚合映射列表后，合并器根据术语在每个文档中的频率对聚合映射列表中的文档列表进行排序。 排序后的文档列表作为搜索结果返回给用户。文档按排序（升序）顺序显示给用户。 注意：我们设计了一个搜索系统，我们利用分布式系统并并行化了索引和搜索过程。这有助于我们通过处理较小的文档分区来处理大型数据集。应该注意的是，搜索和索引都是在同一个节点上执行的。我们将这个想法称为托管。 提议的设计可行，我们可以在全球各个数据中心复制它，以方便所有用户。因此，我们可以获得以下优势： 我们的设计不会受到单点故障 (SPOF) 的影响。 所有用户的延迟将保持很小。 个别数据中心的维护和升级将成为可能。 我们系统的可扩展性（每秒服务更多用户）将得到改善。 复制 我们制作索引节点的副本，为分配的分区生成倒排索引。我们可以用副本回答来自几组节点的查询。整体概念很简单。我们继续使用与以前相同的架构，但我们不再只有一组节点，而是�R节点组来回答用户查询。�R是副本的数量。副本的数量可以根据请求的数量扩展或收缩，并且每组节点都具有回答每个查询所需的所有分区。 每组节点都托管在不同的可用性区域，以便在数据中心出现故障时提高系统的性能和可用性。 注意：需要一个负载平衡器组件来将查询分散到不同的节点组，并在出现任何错误时重试。 复制因子和副本分布 通常，复制因子为 3 就足够了。复制因子为三意味着三个节点托管相同的分区并生成索引。三个节点之一成为主节点，而另外两个节点是副本。这些节点中的每一个都以相同的顺序生成索引以收敛于相同的状态。 为了说明，让我们将数据（文档集）分成四个分区。由于复制因子为三，一个分区将由三个节点托管。我们假设有两个可用区（��1个一个**Z1个的和��2个一个**Z2个的). 在每个可用区中，我们有两个节点。每个节点仅作为一个分区的主节点（例如，节点 1 在��1个一个**Z1个的是分区的主节点�1个P1个的). 分区的三个副本（粉色、蓝色和紫色）在两者之间共享��一个**Z实例，以便两个副本位于一个区域中，第三个副本位于另一个区域中。三种颜色代表每个分区的三个副本。例如，下面的分区是正确的�4个P4个的: 第一个副本，用粉红色表示，放置在节点 2 中��2个一个**Z2个的 第二个副本，用蓝色表示，放置在节点 1 中��2个一个**Z2个的 第三个副本，由紫色表示，放置在节点 2 中��1个一个**Z1个的 下图中的每个组都包含来自所有四个分区的一个副本（�1个P1个的,�2个P2个的,�3个P3个的,�4个P4个的) 在上图中，主副本为�1个P1个的 由深紫色表示，主要副本为�2个P2个的 由深蓝色表示，主副本为�3个P3个的和�4个P4个的 由深粉色表示。 现在我们已经完成了复制，让我们看看如何在这些副本中执行索引和搜索。 用副本索引 从上图中，我们假设每个分区都被转发到每个副本以进行索引计算。让我们看一下我们要索引分区的示例�1个P1个的. 这意味着同一个分区将被转发到两个可用区中的所有三个副本。因此，每个节点将同时计算索引并达到相同的状态。 这种策略的优点是如果主节点发生故障，索引操作不会受到影响。 用副本搜索 我们有每个分区索引的三个副本。负载均衡器选择每个分区的三个副本之一来执行查询。副本数量的增加提高了系统的可扩展性和可用性。现在，系统可以在相同的时间内处理三倍多的查询。 摘要 在本课中，我们学习了如何使用这些策略处理大量数据和大量查询： 并行索引和搜索，其中这两个进程都位于相同的节点上。 复制每个分区，这意味着我们也复制索引和搜索过程。 我们成功地设计了一个系统，该系统可通过在同一节点上并置的读取（搜索）和写入（索引）操作进行扩展。但是，这种缩放方法带来了一些缺点。我们将在下一课中研究缺点及其解决方案。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式搜索/扩展搜索和索引.html":{"url":"分布式搜索/扩展搜索和索引.html","title":"扩展搜索和索引","keywords":"","body":"扩展搜索和索引 了解在搜索系统中扩展索引和搜索的有效方法。 建议设计的问题 尽管上一课中提出的设计看似合理，但仍然存在一些严重的缺陷。我们将在下面讨论这些缺点： 并置索引和搜索：我们创建了一个系统，可以在同一节点上并置索引和搜索。虽然这看起来是对资源的有效利用，但它也有其缺点。搜索和索引都是资源密集型操作。两种操作都会影响彼此的性能。此外，这种共置设计无法随着时间的推移随着索引和搜索操作的变化而有效扩展。在同一台机器上同时执行这两个操作可能会导致不平衡，并导致可伸缩性问题。 索引重新计算：我们假设每个副本都会单独计算索引，这会导致资源使用效率低下。此外，索引计算是一项资源密集型任务，可能包含数百个流水线操作阶段。因此，在不同的副本上重新计算相同的索引需要强大的机器。相反，合乎逻辑的方法是计算一次索引并将其复制到可用区域。 由于这些关键原因，我们将研究分布式索引和搜索的替代方法。 解决方案 我们不是在每个副本上重新计算索引，而是只在主节点上计算倒排索引。接下来，我们将倒排索引（二进制 blob/文件）传递给副本。这种方法的主要好处是它避免使用重复数量的 CPU 和内存来对副本进行索引。 指向思考 问题 上述解决方案的缺点是什么？ 隐藏答案 由于倒排索引将被传输到副本，这将引入复制倒排索引文件的传输延迟，因为索引文件的大小可能非常大。当主节点接收到新的索引操作时，倒排索引文件发生变化。在一定数量的索引操作达到定义的阈值后，每个副本都需要获取文件的最新版本。 分离索引和搜索 随着网络和虚拟化技术的出现，云计算已成为一项成功的技术。在这种技术中，我们可以访问大量带宽（高达 100 Gbps）和可扩展的分布式存储。这些进步允许在索引和搜索之间进行强有力的分离，而不会产生索引延迟的负面影响。由于这种隔离，索引不会影响搜索可扩展性，反之亦然。此外，我们可以只复制索引文件，而不是在副本节点上重新计算索引，这会浪费资源。 我们将使用这些技术来重新设计我们的分布式索引和搜索系统。此搜索系统设计涉及三个组件： 索引器：它由一组计算索引的节点组成。 分布式存储：该系统用于存储分区和计算索引。 搜索器：它由许多执行搜索的节点组成。 下图描述了索引器和搜索器节点之间倒排索引的生成和传输： 在上图中，为每个索引和搜索操作显示了一个节点。但实际上，会有一个否否索引阶段的节点数，每个分区（一组文档）一个节点，产生倒排索引。倒排索引以二进制文件的形式存储在节点的本地存储中。缓存这些 blob 文件将提高性能。这些二进制文件也被推送到分布式存储。在硬件故障的情况下，添加新的搜索器或索引器机器，并从分布式存储中检索数据的副本。 上传完成后，搜索器节点下载索引文件。根据用户搜索模式，搜索节点将维护一个常见查询的缓存并从 RAM 提供数据。用户搜索查询将扩展到所有搜索器节点，这些节点将根据各自的索引生成响应。前端服务器中的合并节点将合并所有搜索结果并将它们呈现给用户。 一旦新文档可用，索引过程就会对其进行索引。同时，搜索器节点获取更新的索引以提供改进的搜索结果。 索引解释 到目前为止，我们已经解释了使用低成本节点开发高度可扩展和高性能的设计。但是，我们不知道索引节点的内部结构。在本节中，我们将了解如何使用 MapReduce 分布式模型和并行处理框架执行索引。 MapReduce框架是在集群管理器和一组分类为 Mappers 和 Reducers 的工作节点的帮助下实现的。顾名思义，MapReduce 由两个阶段组成： 映射阶段 还原阶段 此外，MapReduce 的输入是多个分区或文档集，而其输出是聚合倒排索引。 让我们了解一下上述组件的用途： 集群管理器：管理器通过将一组分区分配给映射器来启动该过程。Mappers 完成后，集群管理器将 Mappers 的输出分配给 Reducers。 映射器：该组件从集群管理器分配给它的分区中提取和过滤术语。这些机器并行输出倒排索引，作为 Reducers 的输入。 Reducers：reducer 组合各种术语的映射以生成汇总索引。 集群管理器确保所有工作节点在集群中得到有效利用。MapReduce 是为在部分故障下工作而构建的。如果一个节点出现故障，它会重新安排另一个节点上的工作。 请注意，只要 Mappers 正在工作，Reducers 就无法启动。这意味着集群管理器可以使用与 Mapper 和 Reducer 相同的节点。 下面的幻灯片描述了如何使用 MapReduce 生成倒排索引的简化设置： 集群管理器和文档分区 映射阶段开始,集群管理器将文档分区分配给集群中的空闲节点.我们称这些节点为映射器 映射器从分配的文档中提取术语并生成N个较小的倒排索引 Reduce阶段开始，集群管理器识别出运行Reduce功能的空闲节点，并将工作分配给Reducers reducer 将来自所有映射器的分配术语中的相似术语组合在一起，并将术语的所有条目放在分布式存储中 为了简单起见，我们在上图中只为每个术语显示了两个指标：该术语出现的文档列表和该术语在每个文档中的频率列表（详见索引）。 注意：上面的 MapReduce 设置是实际情况的简化版本。需要 MapReduce 框架的复杂管道来管理现实世界搜索引擎的复杂性。但是，基本原则与我们在此介绍的相同。 摘要 在本课中，我们通过使用专用节点进行索引和搜索，解决了可扩展性（由于共置索引和搜索）和资源浪费（由于索引重新计算）这两个关键问题。这两种操作都依赖于分布式存储。此外，我们还提供了 MapReduce 框架的简化描述，以并行化索引过程。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式搜索/分布式搜索设计 评估.html":{"url":"分布式搜索/分布式搜索设计 评估.html","title":"分布式搜索设计:评估","keywords":"","body":"分布式搜索设计的评估 分析我们的设计如何满足要求。 可用性 我们利用分布式存储来存储这些项目： 索引器抓取的文档。 索引节点生成的倒排索引。 数据在分布式存储中跨多个区域复制，使索引和搜索的跨区域部署更加容易。索引和搜索节点组只需要在不同的可用性区域中进行复制。因此，我们将索引和搜索节点集群部署在不同的可用性区域。因此，如果一个地方发生故障，我们可以处理来自另一个集群的请求。多组索引和搜索节点有助于实现高索引和搜索可用性。此外，在每个集群中，如果一个节点死亡，另一个节点可以取而代之。 索引是离线执行的，而不是在用户的关键路径上。我们不需要同步复制索引操作。没有必要用刚刚添加到索引中的最新数据来响应用户搜索查询。因此，我们不必等待新索引的复制来响应搜索查询。这使得搜索对用户可用。 注意：一旦我们复制了所有索引节点组中的最新数据并且搜索节点已经下载了它，那么搜索查询就会对最新数据执行。 可扩展性 分区是扩展搜索系统的重要组成部分。当我们增加分区数量并向索引和搜索集群添加更多节点时，我们可以在数据索引和查询方面进行扩展。 索引和搜索过程的强隔离有助于索引和搜索独立和动态地扩展。 大数据快速搜索 我们使用了多个节点，每个节点在较小的倒排索引上并行执行搜索查询。然后合并每个搜索节点的结果并返回给用户。 降低成本 我们使用更便宜的机器来计算索引和执行搜索。如果一个节点发生故障，我们不必重新计算完整的索引。相反，一些文档需要重新编入索引。 结论 几乎每个应用程序都需要一个搜索系统。我们已经看到，开发一个可以在单个节点上运行的搜索系统是不可能的。我们利用并行计算框架和低成本机器构建了一个可用、可扩展且高性能的搜索系统。 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-17 "},"分布式日志记录/分布式日志记录.html":{"url":"分布式日志记录/分布式日志记录.html","title":"分布式日志记录","keywords":"","body":"分布式日志记录 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式日志记录/系统设计 分布式日志记录.html":{"url":"分布式日志记录/系统设计 分布式日志记录.html","title":"系统设计:分布式日志记录","keywords":"","body":"系统设计:分布式日志记录 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式日志记录/分布式日志简介.html":{"url":"分布式日志记录/分布式日志简介.html","title":"分布式日志简介","keywords":"","body":"分布式日志简介 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式日志记录/分布式日志记录 设计.html":{"url":"分布式日志记录/分布式日志记录 设计.html","title":"分布式日志记录:设计","keywords":"","body":"分布式日志记录:设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式任务调度器/分布式任务调度器.html":{"url":"分布式任务调度器/分布式任务调度器.html","title":"分布式任务调度器","keywords":"","body":"分布式任务调度器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式任务调度器/系统设计 分布式任务调度器.html":{"url":"分布式任务调度器/系统设计 分布式任务调度器.html","title":"系统设计:分布式任务调度器","keywords":"","body":"系统设计:分布式任务调度器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式任务调度器/分布式任务调度器 设计要求.html":{"url":"分布式任务调度器/分布式任务调度器 设计要求.html","title":"分布式任务调度器:设计要求","keywords":"","body":"分布式任务调度器:设计要求 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式任务调度器/分布式任务调度器 设计.html":{"url":"分布式任务调度器/分布式任务调度器 设计.html","title":"分布式任务调度器:设计","keywords":"","body":"分布式任务调度器:设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式任务调度器/分布式任务调度器 设计注意事项.html":{"url":"分布式任务调度器/分布式任务调度器 设计注意事项.html","title":"分布式任务调度器:设计注意事项","keywords":"","body":"分布式任务调度器:设计注意事项 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分布式任务调度器/分布式任务调度器 设计评估.html":{"url":"分布式任务调度器/分布式任务调度器 设计评估.html","title":"分布式任务调度器:设计评估","keywords":"","body":"分布式任务调度器:设计评估 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分片计数器/分片计数器.html":{"url":"分片计数器/分片计数器.html","title":"分片计数器","keywords":"","body":"分片计数器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分片计数器/系统设计 分片计数器.html":{"url":"分片计数器/系统设计 分片计数器.html","title":"系统设计:分片计数器","keywords":"","body":"系统设计:分片计数器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分片计数器/分片计数器 高层设计.html":{"url":"分片计数器/分片计数器 高层设计.html","title":"分片计数器:高层设计","keywords":"","body":"分片计数器:高层设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分片计数器/分片计数器 详细设计.html":{"url":"分片计数器/分片计数器 详细设计.html","title":"分片计数器:详细设计","keywords":"","body":"分片计数器:详细设计 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"分片计数器/分片计数器 测验.html":{"url":"分片计数器/分片计数器 测验.html","title":"分片计数器:测验","keywords":"","body":"分片计数器:测验 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"构建块模块结语/构建块模块结语.html":{"url":"构建块模块结语/构建块模块结语.html","title":"构建块模块结语","keywords":"","body":"构建块模块结语 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"构建块模块结语/构建块模块总结.html":{"url":"构建块模块结语/构建块模块总结.html","title":"构建块模块总结","keywords":"","body":"构建块模块总结 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"构建块模块结语/系统设计 RESHADED方法.html":{"url":"构建块模块结语/系统设计 RESHADED方法.html","title":"系统设计:RESHADED方法","keywords":"","body":"系统设计:RESHADED方法 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-16 "},"设计TinyURL/设计TinyURL.html":{"url":"设计TinyURL/设计TinyURL.html","title":"设计一个URL缩短服务/TinyURL","keywords":"","body":"设计一个URL缩短服务/TinyURL Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"设计TinyURL/系统设计:TinyURL.html":{"url":"设计TinyURL/系统设计:TinyURL.html","title":"系统设计:TinyURL","keywords":"","body":"系统设计:TinyURL Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-13 "},"设计TinyURL/TinyURL的设计要求.html":{"url":"设计TinyURL/TinyURL的设计要求.html","title":"TinyURL的设计要求","keywords":"","body":"TinyURL的设计要求 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"设计TinyURL/TinyURL的设计与部署.html":{"url":"设计TinyURL/TinyURL的设计与部署.html","title":"TinyURL的设计与部署","keywords":"","body":"TinyURL的设计与部署 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"设计TinyURL/TinyURL的编码器.html":{"url":"设计TinyURL/TinyURL的编码器.html","title":"TinyURL的编码器","keywords":"","body":"TinyURL的编码器 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"设计TinyURL/TinyURL设计评估.html":{"url":"设计TinyURL/TinyURL设计评估.html","title":"TinyURL设计评估","keywords":"","body":"TinyURL设计评估 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "},"设计TinyURL/TinyURL设计测验.html":{"url":"设计TinyURL/TinyURL设计测验.html","title":"TinyURL设计测验","keywords":"","body":"TinyURL设计测验 Copyright © IT小菜鸡搬运社 2023 all right reserved，powered by Gitbook文章修订时间： 2023-02-09 "}}